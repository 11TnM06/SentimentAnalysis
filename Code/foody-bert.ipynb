{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-12T14:42:29.682227Z","iopub.status.busy":"2022-12-12T14:42:29.681789Z","iopub.status.idle":"2022-12-12T14:42:32.092912Z","shell.execute_reply":"2022-12-12T14:42:32.091742Z","shell.execute_reply.started":"2022-12-12T14:42:29.682143Z"},"id":"GihLmzCaXlMK","outputId":"9c5031cc-b998-4afc-e553-b4617a23c068","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["__notebook_source__.ipynb\n","/kaggle/working\n"]}],"source":["\n","import os\n","#os.chdir(\"/kaggle/input/trainfoodjson\")\n","!ls\n","!pwd\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:42:34.367864Z","iopub.status.busy":"2022-12-12T14:42:34.367459Z","iopub.status.idle":"2022-12-12T14:43:30.212857Z","shell.execute_reply":"2022-12-12T14:43:30.211658Z","shell.execute_reply.started":"2022-12-12T14:42:34.367829Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting fastBPE\n","  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=746411 sha256=9b7fce002e19265063b5db21680364d6201e0485f5299e193dd8b0b51fcd2f8e\n","  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting fairseq\n","  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.11.0)\n","Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.11.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fairseq) (4.64.0)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from fairseq) (2021.11.10)\n","Requirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.15.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.21.6)\n","Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.29.32)\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Collecting bitarray\n","  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.8.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (4.1.1)\n","Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (6.0)\n","Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.5)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.8.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=e043279ae32d9b2442bd34f487b31d7b57d473b21e4774417b6cd91581905bd5\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, sacrebleu, omegaconf, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 sacrebleu-2.3.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting vncorenlp\n","  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vncorenlp) (2.28.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (3.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2.1.0)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=f6281ca6d7c91ca3b86313fbd0ccbc3e377aeb691f30c87c101aff49c0bf311d\n","  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["\n","!pip install transformers\n","!pip install fastBPE\n","!pip install fairseq\n","!pip install vncorenlp"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:43:42.658914Z","iopub.status.busy":"2022-12-12T14:43:42.658466Z","iopub.status.idle":"2022-12-12T14:43:43.639911Z","shell.execute_reply":"2022-12-12T14:43:43.638789Z","shell.execute_reply.started":"2022-12-12T14:43:42.658869Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["__notebook_source__.ipynb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:43:46.588069Z","iopub.status.busy":"2022-12-12T14:43:46.587585Z","iopub.status.idle":"2022-12-12T14:43:56.041477Z","shell.execute_reply":"2022-12-12T14:43:56.040410Z","shell.execute_reply.started":"2022-12-12T14:43:46.588022Z"},"trusted":true},"outputs":[],"source":["from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","import argparse\n","from tqdm import tqdm\n","import json\n","from vncorenlp import VnCoreNLP\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch\n","from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n","import random\n","from tqdm import tqdm_notebook\n","from sklearn.metrics import roc_auc_score\n","import pandas as pd\n","\n","\n","#rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-12T12:56:21.190433Z","iopub.status.idle":"2022-12-12T12:56:21.190759Z","shell.execute_reply":"2022-12-12T12:56:21.190615Z","shell.execute_reply.started":"2022-12-12T12:56:21.190599Z"},"id":"1rDQ-iIiYZJ0","outputId":"81ef5628-1504-4a0a-a179-62d3cabdaef4","trusted":true},"outputs":[],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"zXeuwp_WZ2IM"},"source":["**Deploy PhoBert**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:44:01.729371Z","iopub.status.busy":"2022-12-12T14:44:01.728708Z","iopub.status.idle":"2022-12-12T14:44:16.015821Z","shell.execute_reply":"2022-12-12T14:44:16.014146Z","shell.execute_reply.started":"2022-12-12T14:44:01.729330Z"},"id":"O9QCWW8pb-Q6","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-12-12 14:44:03--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27412575 (26M) [application/octet-stream]\n","Saving to: ‘VnCoreNLP-1.1.1.jar’\n","\n","VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  --.-KB/s    in 0.1s    \n","\n","2022-12-12 14:44:03 (220 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n","\n","--2022-12-12 14:44:04--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 526544 (514K) [application/octet-stream]\n","Saving to: ‘vi-vocab’\n","\n","vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.03s   \n","\n","2022-12-12 14:44:04 (19.5 MB/s) - ‘vi-vocab’ saved [526544/526544]\n","\n","--2022-12-12 14:44:06--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 128508 (125K) [text/plain]\n","Saving to: ‘wordsegmenter.rdr’\n","\n","wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.01s   \n","\n","2022-12-12 14:44:06 (8.25 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n","\n","__notebook_source__.ipynb  vncorenlp\n"]}],"source":["# Install the vncorenlp python wrapper\n","# !pip install vncorenlp\n","\n","# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n","!mkdir -p vncorenlp/models/wordsegmenter\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n","!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n","!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n","!mv vi-vocab vncorenlp/models/wordsegmenter/\n","!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n","!ls\n","rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:44:33.378037Z","iopub.status.busy":"2022-12-12T14:44:33.376906Z","iopub.status.idle":"2022-12-12T14:44:33.424463Z","shell.execute_reply":"2022-12-12T14:44:33.423501Z","shell.execute_reply.started":"2022-12-12T14:44:33.377997Z"},"id":"P6vVcoSgcWr4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[['Đại_học', 'Quốc_gia', 'Hà_Nội', '.']]\n"]}],"source":["text = \"Đại học Quốc gia Hà Nội.\"\n","word_segmented_text = rdrsegmenter.tokenize(text) \n","print(word_segmented_text)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:44:37.172678Z","iopub.status.busy":"2022-12-12T14:44:37.172250Z","iopub.status.idle":"2022-12-12T14:45:31.443342Z","shell.execute_reply":"2022-12-12T14:45:31.442169Z","shell.execute_reply.started":"2022-12-12T14:44:37.172644Z"},"id":"eIcv4BS5df7R","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-12-12 14:44:38--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 54.230.31.74, 54.230.31.76, 54.230.31.108, ...\n","Connecting to public.vinai.io (public.vinai.io)|54.230.31.74|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1243308020 (1.2G) [application/x-tar]\n","Saving to: ‘PhoBERT_base_fairseq.tar.gz’\n","\n","PhoBERT_base_fairse 100%[===================>]   1.16G  52.5MB/s    in 23s     \n","\n","2022-12-12 14:45:01 (51.2 MB/s) - ‘PhoBERT_base_fairseq.tar.gz’ saved [1243308020/1243308020]\n","\n","PhoBERT_base_fairseq/\n","PhoBERT_base_fairseq/bpe.codes\n","PhoBERT_base_fairseq/model.pt\n","PhoBERT_base_fairseq/dict.txt\n","--2022-12-12 14:45:17--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 54.230.31.104, 54.230.31.76, 54.230.31.74, ...\n","Connecting to public.vinai.io (public.vinai.io)|54.230.31.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 322405979 (307M) [application/x-tar]\n","Saving to: ‘PhoBERT_base_transformers.tar.gz’\n","\n","PhoBERT_base_transf 100%[===================>] 307.47M  52.2MB/s    in 6.2s    \n","\n","2022-12-12 14:45:24 (49.5 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n","\n","PhoBERT_base_transformers/\n","PhoBERT_base_transformers/config.json\n","PhoBERT_base_transformers/bpe.codes\n","PhoBERT_base_transformers/model.bin\n","PhoBERT_base_transformers/dict.txt\n"]}],"source":["!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n","!tar -xzvf PhoBERT_base_fairseq.tar.gz\n","!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","!tar -xzvf PhoBERT_base_transformers.tar.gz\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:46:17.764652Z","iopub.status.busy":"2022-12-12T14:46:17.764244Z","iopub.status.idle":"2022-12-12T14:46:18.706716Z","shell.execute_reply":"2022-12-12T14:46:18.705588Z","shell.execute_reply.started":"2022-12-12T14:46:17.764619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PhoBERT_base_fairseq\t     PhoBERT_base_transformers.tar.gz\n","PhoBERT_base_fairseq.tar.gz  __notebook_source__.ipynb\n","PhoBERT_base_transformers    vncorenlp\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-12T14:46:24.449600Z","iopub.status.busy":"2022-12-12T14:46:24.449211Z","iopub.status.idle":"2022-12-12T14:47:22.458148Z","shell.execute_reply":"2022-12-12T14:47:22.456706Z","shell.execute_reply.started":"2022-12-12T14:46:24.449566Z"},"id":"81NybLVke31Z","outputId":"f7a02f05-35a7-4d4c-9855-d4b6c1d7dcb7","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading codes from ./PhoBERT_base_transformers/bpe.codes ...\n","Read 64000 codes from the codes file.\n","100%|██████████| 9071/9071 [00:57<00:00, 157.83it/s]\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Partition 1\n","Number of positive label in train data: 6423/8163\n","Number of positive label in train data: 724/908\n","#\n","Partition 2\n","Number of positive label in train data: 6433/8164\n","Number of positive label in train data: 714/907\n","#\n","Partition 3\n","Number of positive label in train data: 6450/8164\n","Number of positive label in train data: 697/907\n","#\n","Partition 4\n","Number of positive label in train data: 6430/8164\n","Number of positive label in train data: 717/907\n","#\n","Partition 5\n","Number of positive label in train data: 6453/8164\n","Number of positive label in train data: 694/907\n","#\n","Partition 6\n","Number of positive label in train data: 6407/8164\n","Number of positive label in train data: 740/907\n","#\n","Partition 7\n","Number of positive label in train data: 6429/8164\n","Number of positive label in train data: 718/907\n","#\n","Partition 8\n","Number of positive label in train data: 6424/8164\n","Number of positive label in train data: 723/907\n","#\n","Partition 9\n","Number of positive label in train data: 6441/8164\n","Number of positive label in train data: 706/907\n","#\n","Partition 10\n","Number of positive label in train data: 6433/8164\n","Number of positive label in train data: 714/907\n","#\n"]}],"source":["#Build Train\n","MAX_LEN = 256\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--bpe-codes', \n","    default=\"./PhoBERT_base_transformers/bpe.codes\",\n","    required=False,\n","    type=str,\n","    help='path to fastBPE BPE'\n",")\n","args, unknown = parser.parse_known_args()\n","bpe = fastBPE(args)\n","\n","# Load the dictionary\n","vocab = Dictionary()\n","vocab.add_from_file(\"./PhoBERT_base_transformers/dict.txt\")\n","\n","train_path = '/kaggle/input/trainfoodjson/train.json'\n","full_dataset = []\n","\n","with open(train_path, 'r') as f:\n","    datasets = json.load(f)\n","# \n","\n","for sample in tqdm(datasets):\n","    label = int(sample['Rating'] >= 6)\n","    comment = str(sample['Comment'])\n","    comment = rdrsegmenter.tokenize(comment)\n","    comment = ' '.join([' '.join(x) for x in comment])\n","    subwords = '<s> ' + bpe.encode(comment) + ' </s>'\n","    encoded_comment = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    ids = pad_sequences([encoded_comment], maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","    ids = ids[0]\n","    mask = [int(token_id > 0) for token_id in ids]\n","    full_dataset.append([ids, mask, label])\n","    # if cnt == 15:\n","    #     break\n","    # cnt += 1\n","full_dataset = np.array(full_dataset)\n","kf = KFold(n_splits=10, shuffle=True)\n","print()\n","\n","partition = 1\n","for tid, vid in kf.split(full_dataset):\n","    print(f\"Partition {partition}\")\n","    train_set = full_dataset[tid]\n","    train_positive = sum(pos[2] for pos in train_set)\n","    val_set = full_dataset[vid]\n","    val_positive = sum(pos[2] for pos in val_set)\n","    print(f\"Number of positive label in train data: {train_positive}/{len(train_set)}\")\n","    print(f\"Number of positive label in train data: {val_positive}/{len(val_set)}\")\n","    partition += 1\n","    print(\"#\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:48:43.476858Z","iopub.status.busy":"2022-12-12T14:48:43.476485Z","iopub.status.idle":"2022-12-12T14:48:43.485259Z","shell.execute_reply":"2022-12-12T14:48:43.484162Z","shell.execute_reply.started":"2022-12-12T14:48:43.476819Z"},"id":"AkZ3KzlYSadi","trusted":true},"outputs":[],"source":["#Build Loader\n","def build_loader(dataset, train_id, val_id):\n","    train_set = dataset[train_id]\n","    val_set = dataset[val_id]\n","    train_inputs = torch.tensor([s[0] for s in train_set])\n","    val_inputs = torch.tensor([s[0] for s in val_set])\n","    train_targets = torch.tensor([s[2] for s in train_set])\n","    val_targets = torch.tensor([s[2] for s in val_set])\n","    train_masks = torch.tensor([s[1] for s in train_set])\n","    val_masks = torch.tensor([s[1] for s in val_set])\n","\n","    train_data = TensorDataset(train_inputs, train_masks, train_targets)\n","    train_sampler = SequentialSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n","\n","    val_data = TensorDataset(val_inputs, val_masks, val_targets)\n","    val_sampler = SequentialSampler(val_data)\n","    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)\n","    return train_dataloader, val_dataloader"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-12T14:47:30.251869Z","iopub.status.busy":"2022-12-12T14:47:30.251514Z","iopub.status.idle":"2022-12-12T14:47:58.793588Z","shell.execute_reply":"2022-12-12T14:47:58.792640Z","shell.execute_reply.started":"2022-12-12T14:47:30.251839Z"},"id":"9TXgcdOK7INX","outputId":"594f816a-3e71-454d-e2e7-7c1a94f395ca","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5103/5103 [00:28<00:00, 182.25it/s]\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n"]}],"source":["#Build Test\n","df = pd.read_csv(\"/kaggle/input/dataset/test.csv\")\n","test_datasets = []\n","for _, row in df[[\"RevId\", \"Comment\"]].iterrows():\n","    test_datasets.append([row[\"RevId\"], row[\"Comment\"]])\n","test_set = []\n","for sample in tqdm(test_datasets):\n","    comment = str(sample[1])\n","    comment = rdrsegmenter.tokenize(comment)\n","    comment = ' '.join([' '.join(x) for x in comment])\n","    subwords = '<s> ' + bpe.encode(comment) + ' </s>'\n","    encoded_comment = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n","    ids = pad_sequences([encoded_comment], maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","    ids = ids[0]\n","    mask = [int(token_id > 0) for token_id in ids]\n","    test_set.append([sample[0], ids, mask])\n","test_revid = torch.tensor([s[0] for s in test_set])\n","test_inputs = torch.tensor([s[1] for s in test_set])\n","test_masks = torch.tensor([s[2] for s in test_set])\n","\n","test_data = TensorDataset(test_revid, test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"AjZ2lVn59uXw"},"source":["**Load Model**"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-12T14:48:46.999207Z","iopub.status.busy":"2022-12-12T14:48:46.998019Z","iopub.status.idle":"2022-12-12T14:48:48.857878Z","shell.execute_reply":"2022-12-12T14:48:48.857024Z","shell.execute_reply.started":"2022-12-12T14:48:46.999163Z"},"id":"37l9P1Fa7u_e","outputId":"37acfd0d-bee8-46cf-b374-9b8348cd8639","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at ./PhoBERT_base_transformers/model.bin were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./PhoBERT_base_transformers/model.bin and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["config = RobertaConfig.from_pretrained(\n","    \"./PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 1, output_hidden_states=False,\n",")\n","BERT_SA = RobertaForSequenceClassification.from_pretrained(\n","    \"./PhoBERT_base_transformers/model.bin\",\n","    config=config\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:48:53.263544Z","iopub.status.busy":"2022-12-12T14:48:53.262858Z","iopub.status.idle":"2022-12-12T14:48:53.272159Z","shell.execute_reply":"2022-12-12T14:48:53.271045Z","shell.execute_reply.started":"2022-12-12T14:48:53.263508Z"},"id":"XkqzbO3CBd-s","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","\n","def sigmoid_focal_loss(\n","    inputs: torch.Tensor,\n","    targets: torch.Tensor,\n","    alpha: float = 0.25,\n","    gamma: float = 2,\n","    reduction: str = \"mean\",\n","):\n","    p = torch.sigmoid(inputs)\n","    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n","    p_t = p * targets + (1 - p) * (1 - targets)\n","    loss = ce_loss * ((1 - p_t) ** gamma)\n","\n","    if alpha >= 0:\n","        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n","        loss = alpha_t * loss\n","\n","    if reduction == \"mean\":\n","        loss = loss.mean()\n","    elif reduction == \"sum\":\n","        loss = loss.sum()\n","\n","    return loss\n","\n","def np_sigmoid(x):\n","    return 1/(1 + np.exp(-x))"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T14:48:58.422512Z","iopub.status.busy":"2022-12-12T14:48:58.422155Z","iopub.status.idle":"2022-12-12T14:48:58.427673Z","shell.execute_reply":"2022-12-12T14:48:58.426561Z","shell.execute_reply.started":"2022-12-12T14:48:58.422482Z"},"trusted":true},"outputs":[],"source":["def save_model(model, optimizer, path):\n","    state_dict = {\n","        \"optimizer\": optimizer.state_dict(),\n","        \"model\": model.state_dict()\n","    }\n","    torch.save(state_dict, path)"]},{"cell_type":"markdown","metadata":{"id":"uIuPoeN690ld"},"source":["**TRAINING**"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2022-12-12T15:17:23.617394Z","iopub.status.busy":"2022-12-12T15:17:23.617009Z","iopub.status.idle":"2022-12-12T15:57:27.245444Z","shell.execute_reply":"2022-12-12T15:57:27.244227Z","shell.execute_reply.started":"2022-12-12T15:17:23.617359Z"},"id":"gxdScIKc9xJL","outputId":"3e2954cc-7d23-4277-bc88-96eccf0e8f70","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Done\n","======== Partition 1 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9706\n","Average training loss: 0.0191\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(908,)\n","[1.6, 8.3, 8.1, 7.9, 8.1, 7.4, 8.0, 8.2, 7.8, 8.0, 7.9, 7.9, 8.0, 1.0, 7.6, 8.3, 7.4, 8.4, 7.8, 8.1, 8.3, 7.9, 8.1, 8.0, 1.1, 7.6, 8.5, 2.8, 8.3, 8.1, 7.7, 1.8, 8.3, 8.0, 1.1, 8.1, 8.3, 1.2, 5.8, 6.1, 1.4, 7.2, 7.8, 1.5, 6.1, 8.5, 6.3, 7.9, 7.3, 8.0, 7.5, 7.5, 1.0, 8.1, 7.3, 1.0, 8.3, 1.0, 3.5, 1.8, 7.5, 1.1, 8.1, 7.9, 8.1, 8.3, 8.1, 8.0, 7.7, 7.8, 8.7, 8.1, 7.7, 1.9, 8.3, 6.8, 1.1, 7.6, 8.2, 7.8, 1.9, 8.4, 8.0, 7.8, 6.8, 8.5, 7.0, 7.6, 7.9, 7.4, 8.3, 6.1, 6.4, 7.5, 7.7, 7.1, 8.1, 8.4, 7.8, 8.3, 3.1, 5.7, 1.0, 8.2, 7.5, 5.6, 1.5, 8.6, 8.4, 6.5, 7.8, 7.9, 8.4, 1.6, 8.0, 7.9, 7.1, 7.9, 8.2, 8.4, 8.0, 7.5, 8.3, 2.0, 8.0, 2.2, 7.4, 8.3, 8.0, 8.3, 8.1, 7.8, 6.9, 8.3, 7.4, 7.2, 1.1, 7.9, 2.5, 8.0, 8.1, 7.8, 1.0, 7.9, 8.0, 1.2, 8.1, 1.6, 8.3, 1.4, 7.6, 1.4, 8.4, 1.0, 5.3, 6.9, 7.8, 8.2, 1.0, 1.3, 2.2, 1.0, 6.4, 7.1, 8.4, 7.9, 7.7, 8.0, 2.1, 8.6, 8.2, 6.6, 7.7, 7.6, 8.1, 8.0, 7.3, 5.2, 7.9, 8.3, 1.1, 1.2, 8.4, 8.3, 8.3, 0.9, 8.1, 1.0, 7.2, 8.0, 7.8, 2.8, 8.4, 7.6, 7.9, 8.3, 7.2, 7.9, 8.2, 7.9, 8.6, 6.3, 7.0, 8.0, 8.1, 1.0, 8.2, 8.2, 1.2, 8.0, 7.2, 8.3, 7.8, 8.1, 8.0, 7.7, 3.0, 6.1, 7.8, 8.3, 6.1, 7.9, 8.2, 7.4, 7.8, 7.9, 7.9, 8.3, 6.0, 5.1, 1.6, 7.7, 8.0, 7.4, 1.6, 8.1, 2.1, 1.9, 1.3, 8.4, 8.1, 8.0, 8.2, 8.3, 6.8, 8.4, 8.1, 8.4, 7.9, 8.4, 2.0, 7.2, 7.3, 7.4, 7.1, 1.1, 7.5, 8.2, 3.7, 7.8, 7.4, 6.1, 0.9, 3.7, 7.7, 1.0, 6.8, 1.1, 1.1, 8.0, 8.1, 8.4, 8.2, 6.0, 7.8, 8.0, 7.9, 5.5, 2.3, 7.7, 7.8, 8.0, 8.3, 8.1, 7.3, 1.1, 8.1, 1.6, 8.2, 8.3, 1.4, 8.0, 8.1, 8.2, 8.3, 1.0, 7.7, 8.1, 7.8, 7.8, 7.6, 7.3, 8.5, 8.0, 8.1, 7.9, 8.3, 7.6, 7.0, 8.1, 8.0, 8.4, 0.9, 1.0, 0.9, 1.3, 8.3, 8.1, 1.9, 7.8, 7.0, 8.3, 8.3, 7.7, 8.3, 7.4, 8.3, 1.7, 7.1, 7.9, 7.9, 8.3, 8.0, 8.3, 1.1, 8.4, 7.2, 8.5, 8.2, 8.1, 8.3, 1.1, 8.1, 1.0, 1.0, 7.9, 1.1, 8.0, 4.5, 8.1, 0.9, 8.2, 1.0, 3.1, 7.3, 8.3, 1.4, 7.6, 8.3, 7.0, 7.7, 5.5, 5.3, 3.5, 6.1, 8.4, 8.5, 8.2, 8.2, 8.3, 6.8, 8.1, 8.3, 1.0, 8.2, 7.5, 6.7, 5.6, 7.4, 7.8, 1.5, 8.4, 8.4, 1.1, 8.0, 8.1, 7.9, 5.6, 7.2, 1.6, 1.3, 3.2, 1.1, 7.2, 7.9, 8.3, 7.7, 8.0, 8.1, 3.3, 7.6, 7.9, 8.5, 8.1, 7.8, 1.6, 7.3, 6.5, 4.2, 8.4, 6.5, 7.4, 1.3, 3.3, 7.0, 1.3, 0.9, 8.2, 8.1, 5.9, 7.9, 8.6, 8.2, 1.0, 8.0, 1.1, 8.0, 6.4, 7.3, 8.2, 7.8, 7.7, 8.0, 8.4, 8.0, 8.0, 8.2, 1.1, 4.9, 7.4, 5.9, 4.5, 7.6, 7.3, 7.8, 6.6, 0.9, 7.8, 8.4, 8.3, 8.1, 7.7, 8.2, 8.0, 8.0, 7.9, 0.9, 7.8, 7.7, 1.2, 2.2, 4.2, 5.3, 8.1, 7.5, 1.1, 8.4, 1.1, 1.6, 2.9, 8.0, 8.3, 8.0, 7.7, 1.3, 1.3, 8.3, 8.1, 7.5, 8.1, 8.4, 7.6, 7.8, 8.4, 8.2, 8.3, 8.6, 5.8, 1.9, 7.8, 8.0, 7.6, 6.3, 8.2, 8.3, 8.2, 8.1, 6.7, 2.1, 7.7, 8.1, 8.4, 8.0, 7.7, 7.8, 8.2, 7.5, 8.3, 7.7, 8.4, 7.2, 7.6, 8.4, 7.3, 5.8, 6.8, 1.0, 1.1, 1.0, 7.3, 7.9, 6.7, 8.6, 7.8, 8.3, 7.9, 6.9, 8.3, 6.4, 7.9, 8.1, 7.0, 7.7, 8.2, 8.1, 8.0, 7.6, 6.6, 6.9, 1.4, 7.6, 8.5, 8.2, 7.3, 7.6, 8.3, 7.4, 7.6, 8.3, 1.0, 8.0, 8.4, 7.9, 2.7, 7.6, 7.1, 8.2, 8.4, 7.9, 1.1, 8.2, 7.7, 7.9, 7.4, 7.1, 8.1, 3.3, 8.3, 7.5, 8.4, 8.0, 7.3, 2.0, 1.3, 8.0, 8.2, 7.7, 8.1, 7.7, 8.3, 7.2, 8.0, 7.9, 1.0, 8.4, 1.1, 8.0, 8.1, 8.1, 7.8, 8.3, 8.3, 2.2, 3.4, 6.4, 8.2, 8.1, 6.8, 8.1, 8.4, 8.0, 6.8, 8.0, 7.2, 8.3, 8.2, 8.4, 7.9, 7.1, 7.8, 8.3, 8.2, 7.7, 3.9, 7.9, 8.2, 2.1, 4.2, 7.7, 7.1, 7.9, 7.0, 7.6, 7.3, 2.2, 8.4, 2.7, 1.4, 6.9, 8.2, 8.2, 8.3, 7.5, 8.3, 5.6, 1.1, 8.5, 8.2, 7.8, 7.8, 8.4, 1.1, 8.0, 1.0, 7.9, 8.0, 6.2, 7.0, 7.4, 1.4, 7.8, 8.1, 8.0, 8.4, 7.9, 7.7, 8.0, 8.2, 8.3, 8.0, 7.9, 2.1, 8.3, 8.3, 8.3, 7.1, 8.2, 7.6, 7.7, 8.2, 8.5, 6.8, 8.2, 7.9, 1.5, 7.2, 7.8, 5.8, 8.3, 1.8, 1.0, 8.2, 2.3, 7.2, 8.0, 8.2, 7.1, 1.0, 7.8, 8.2, 8.0, 6.4, 1.5, 7.1, 8.3, 6.5, 7.6, 1.0, 7.3, 7.9, 8.1, 7.2, 8.6, 7.4, 7.5, 1.1, 6.1, 2.2, 7.2, 1.1, 5.7, 8.2, 8.4, 1.2, 8.4, 8.1, 8.5, 8.3, 8.1, 8.1, 7.4, 1.4, 1.1, 4.5, 8.1, 7.5, 8.2, 1.1, 8.0, 8.2, 8.1, 6.6, 8.3, 6.8, 8.1, 8.1, 4.9, 8.2, 7.7, 8.2, 8.1, 8.4, 8.0, 8.0, 8.4, 8.0, 1.0, 8.1, 1.6, 7.5, 8.3, 5.0, 8.0, 6.4, 8.0, 7.6, 7.2, 8.5, 6.8, 1.3, 3.8, 7.9, 1.4, 1.4, 3.2, 7.5, 1.4, 8.0, 7.8, 7.6, 8.0, 8.1, 3.5, 8.2, 7.5, 8.3, 7.8, 1.0, 7.6, 6.2, 7.2, 6.2, 8.3, 7.9, 1.9, 8.3, 4.8, 6.9, 1.1, 6.8, 1.0, 8.3, 6.5, 7.1, 7.3, 8.0, 8.1, 8.2, 1.2, 1.4, 7.7, 8.2, 7.2, 7.9, 8.0, 3.0, 8.1, 7.0, 7.6, 8.4, 7.4, 8.4, 7.6, 8.0, 8.2, 8.6, 6.2, 6.7, 8.3, 5.7, 8.0, 7.4, 8.4, 8.4, 8.1, 7.4, 6.3, 8.0, 7.7, 8.4, 8.5, 7.4, 1.9, 7.2, 1.0, 1.4, 8.5, 1.0, 1.2, 8.4, 6.7, 8.3, 4.2, 1.9, 7.2, 7.9, 1.1, 7.8, 7.7, 7.4, 7.9, 7.9, 8.4, 1.1, 7.7, 1.1, 7.5, 7.6, 8.3, 1.0, 5.4, 1.1, 6.1, 7.0, 0.9, 7.3, 7.8, 7.8, 7.8, 8.2, 6.2, 8.3, 8.4, 8.2, 8.1, 7.8, 7.3, 0.9, 5.7, 6.9, 5.6, 6.9, 8.3, 8.3, 8.4, 8.2, 4.0, 7.2, 7.0, 7.2, 7.0, 3.9, 2.1, 1.1, 8.2, 8.2, 7.0, 7.1, 3.5, 7.5, 4.8, 6.5, 7.4, 7.9, 7.4, 6.8, 2.3, 7.0]\n","ROC-AUC score: 0.9866\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 2 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9882\n","Average training loss: 0.0117\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[8.9, 1.0, 8.2, 8.8, 8.9, 8.7, 0.9, 0.9, 8.5, 8.9, 8.8, 6.8, 9.1, 8.8, 0.9, 8.9, 8.7, 8.8, 8.7, 7.6, 8.9, 8.8, 8.9, 0.8, 8.2, 0.9, 0.8, 7.8, 5.9, 8.9, 8.4, 8.7, 7.9, 9.1, 8.9, 8.7, 1.1, 1.2, 0.9, 6.4, 3.6, 7.0, 9.0, 7.5, 5.4, 6.1, 8.0, 8.9, 7.9, 0.9, 8.6, 1.2, 0.8, 8.5, 8.8, 8.8, 8.7, 8.0, 8.8, 8.9, 8.2, 1.1, 0.8, 0.9, 7.9, 8.4, 0.8, 0.8, 8.6, 1.1, 8.7, 8.9, 0.8, 8.0, 0.9, 7.8, 7.7, 0.9, 8.8, 8.6, 0.8, 8.7, 9.0, 0.8, 8.0, 8.0, 8.6, 7.8, 7.5, 0.9, 0.8, 8.1, 8.8, 0.8, 8.4, 8.6, 5.0, 6.0, 9.1, 8.3, 8.7, 8.7, 8.8, 7.8, 8.7, 8.1, 8.4, 8.8, 1.0, 8.5, 8.8, 7.6, 0.9, 9.0, 8.7, 8.8, 8.7, 8.9, 8.4, 8.5, 8.8, 8.8, 8.9, 9.0, 0.9, 6.7, 7.9, 8.9, 8.4, 8.4, 8.7, 8.2, 8.8, 7.9, 8.5, 0.9, 9.1, 8.3, 8.4, 8.9, 8.6, 0.8, 8.6, 7.8, 8.2, 8.7, 1.6, 0.9, 8.7, 1.2, 8.1, 8.8, 8.1, 8.3, 1.2, 7.5, 7.9, 8.9, 8.5, 8.1, 8.8, 8.9, 8.7, 1.9, 9.0, 8.3, 8.9, 0.8, 2.8, 8.4, 8.1, 2.7, 7.0, 1.1, 9.0, 8.6, 1.4, 8.4, 8.5, 7.6, 0.8, 7.1, 0.8, 8.9, 8.6, 0.8, 8.7, 1.0, 1.1, 8.5, 8.2, 8.2, 8.8, 1.0, 7.4, 7.5, 8.3, 1.4, 8.4, 7.9, 8.9, 8.9, 1.1, 8.6, 1.0, 8.3, 8.8, 8.9, 8.6, 8.9, 7.8, 0.9, 8.6, 8.6, 9.0, 8.5, 7.0, 1.5, 8.4, 8.0, 8.7, 8.4, 0.8, 8.8, 7.8, 7.9, 8.5, 8.6, 8.9, 8.8, 7.8, 9.0, 7.9, 8.1, 1.0, 6.5, 8.2, 1.0, 1.0, 8.9, 8.7, 1.0, 6.4, 8.6, 8.4, 0.8, 8.8, 8.6, 8.8, 7.9, 8.7, 8.5, 8.4, 8.7, 8.8, 8.6, 1.5, 8.7, 8.6, 8.3, 7.5, 7.7, 8.2, 8.7, 8.7, 8.2, 8.7, 8.7, 8.7, 4.0, 5.3, 7.7, 9.0, 1.4, 8.5, 8.8, 8.0, 7.3, 7.9, 8.7, 8.2, 8.7, 8.6, 8.7, 8.7, 8.9, 3.8, 8.2, 9.0, 0.8, 1.3, 0.8, 8.9, 8.7, 8.7, 8.9, 8.5, 8.0, 8.7, 1.0, 8.8, 0.8, 8.4, 8.4, 7.6, 1.2, 8.6, 8.7, 8.1, 1.0, 8.2, 8.8, 7.4, 8.8, 8.8, 8.6, 8.4, 8.2, 8.1, 7.8, 0.8, 5.6, 7.9, 8.4, 8.6, 8.4, 8.7, 8.7, 8.9, 8.5, 1.4, 8.2, 0.8, 8.5, 1.6, 2.3, 8.2, 8.7, 1.4, 0.8, 8.6, 8.7, 8.6, 9.0, 8.9, 8.3, 8.3, 1.1, 8.7, 8.6, 7.5, 8.8, 1.0, 7.8, 8.5, 8.9, 8.8, 8.0, 2.4, 8.9, 0.8, 8.3, 8.9, 8.9, 7.8, 7.1, 8.8, 1.5, 8.7, 8.7, 8.9, 7.8, 7.8, 8.9, 0.8, 1.0, 8.7, 8.5, 8.7, 8.8, 8.8, 8.9, 8.3, 7.1, 8.6, 1.3, 0.8, 7.0, 8.9, 8.8, 1.2, 8.0, 8.4, 8.9, 1.6, 0.7, 0.8, 8.8, 9.0, 7.8, 9.0, 7.3, 0.9, 1.0, 8.5, 7.4, 8.5, 8.8, 8.2, 7.9, 0.9, 8.5, 9.0, 9.0, 8.9, 8.7, 0.9, 8.1, 8.5, 8.1, 8.9, 8.6, 1.1, 4.2, 0.8, 0.8, 0.9, 9.0, 3.6, 8.7, 8.7, 7.8, 1.1, 1.3, 8.9, 8.9, 8.6, 8.2, 8.3, 8.7, 8.9, 9.0, 8.4, 8.4, 0.8, 8.6, 8.3, 8.8, 8.9, 8.7, 9.0, 8.7, 8.7, 0.9, 0.8, 8.7, 2.9, 8.5, 1.2, 8.2, 8.6, 8.7, 1.1, 9.0, 7.7, 7.4, 7.9, 1.0, 8.4, 8.1, 8.5, 2.8, 8.3, 8.3, 8.9, 7.4, 8.8, 0.9, 8.7, 8.9, 8.7, 6.6, 7.4, 8.7, 0.9, 1.0, 8.9, 7.7, 8.6, 8.9, 7.8, 1.7, 8.7, 8.8, 7.6, 1.1, 0.9, 8.4, 8.0, 8.2, 8.7, 8.6, 8.6, 8.8, 0.9, 8.8, 0.9, 1.1, 0.8, 8.8, 1.0, 9.0, 9.1, 8.7, 8.8, 8.2, 0.9, 1.0, 8.5, 8.1, 8.4, 1.1, 8.9, 1.1, 8.3, 6.1, 8.1, 8.3, 8.2, 0.9, 8.9, 1.4, 8.5, 8.3, 1.0, 8.8, 2.8, 1.0, 0.8, 0.9, 8.5, 8.4, 1.1, 0.9, 7.5, 9.0, 0.8, 1.3, 8.5, 8.7, 8.8, 8.6, 8.9, 8.5, 8.8, 8.2, 8.7, 0.8, 8.7, 8.7, 8.9, 8.5, 8.5, 9.0, 4.7, 8.4, 8.9, 5.8, 9.1, 8.2, 8.0, 8.7, 9.0, 8.9, 8.5, 8.5, 8.9, 7.1, 7.5, 8.9, 7.1, 8.4, 1.1, 4.2, 7.6, 8.5, 8.8, 8.8, 6.8, 0.9, 4.7, 9.0, 8.8, 7.8, 8.0, 0.9, 8.1, 1.0, 1.7, 8.5, 7.4, 1.4, 1.4, 1.1, 8.7, 8.6, 8.8, 8.8, 4.2, 7.9, 1.0, 8.9, 8.8, 8.0, 8.6, 8.9, 8.6, 8.9, 8.5, 7.3, 8.8, 7.6, 8.6, 8.7, 8.7, 8.7, 8.2, 8.6, 3.1, 8.6, 7.9, 7.4, 0.9, 8.5, 8.6, 8.5, 7.4, 8.9, 1.6, 8.7, 1.8, 8.6, 1.0, 8.9, 7.8, 8.3, 8.5, 8.8, 8.7, 2.1, 5.5, 3.9, 8.3, 8.9, 8.1, 7.9, 8.9, 7.0, 8.1, 1.3, 8.2, 1.2, 7.8, 8.8, 8.5, 8.8, 8.7, 8.2, 8.0, 8.7, 8.0, 8.5, 1.1, 6.9, 8.7, 5.8, 7.8, 1.7, 8.6, 7.3, 1.6, 8.9, 8.8, 8.5, 8.6, 1.0, 0.8, 8.9, 2.2, 8.8, 9.0, 8.6, 1.1, 0.9, 7.3, 7.0, 7.5, 8.9, 7.6, 0.9, 8.1, 8.7, 6.1, 8.9, 8.9, 9.0, 8.9, 8.8, 8.6, 8.7, 8.0, 0.7, 8.2, 8.6, 8.7, 8.4, 8.9, 5.1, 0.9, 8.9, 7.9, 8.2, 8.9, 8.7, 8.9, 7.5, 9.0, 6.6, 8.6, 1.1, 8.6, 8.5, 8.9, 8.0, 8.3, 9.0, 9.0, 8.6, 9.0, 1.9, 8.1, 0.8, 1.1, 8.7, 8.3, 6.9, 1.2, 0.9, 9.0, 8.9, 1.0, 6.8, 8.9, 8.4, 1.1, 9.0, 8.9, 0.9, 0.9, 8.8, 8.8, 2.0, 8.1, 8.4, 2.7, 8.5, 0.9, 8.1, 8.8, 8.1, 8.9, 8.2, 7.4, 8.7, 8.3, 1.0, 8.1, 9.0, 3.2, 9.0, 8.7, 8.4, 8.3, 1.0, 1.0, 8.2, 8.7, 8.5, 8.1, 8.9, 0.8, 0.9, 8.6, 0.8, 8.9, 7.7, 8.9, 0.8, 1.2, 6.6, 8.6, 8.5, 4.9, 7.7, 8.4, 0.8, 8.6, 8.4, 8.1, 0.9, 8.5, 8.5, 9.0, 7.6, 9.1, 9.0, 3.0, 4.3, 8.7, 8.3, 8.8, 8.9, 9.1, 2.9, 1.1, 8.8, 9.0, 9.0, 1.2, 8.5, 8.6, 0.8, 8.3, 1.2, 8.9, 8.8, 1.5, 0.9, 3.6, 8.8, 8.6, 8.7, 1.5, 5.9, 0.8, 8.3, 8.9, 8.6, 1.4, 8.7, 0.9, 9.0, 5.6, 8.7, 0.9, 8.8, 7.7, 5.7, 8.0, 8.5, 8.9, 8.9, 8.7, 8.4, 0.8, 8.4, 4.9, 0.8, 8.7, 8.8, 7.0, 9.0, 8.8, 8.8, 0.7, 4.8, 1.0, 6.2, 8.6, 8.6, 6.9, 9.0, 8.8, 8.1, 8.1, 8.6, 8.8, 0.9, 1.2, 9.0, 5.4, 1.1, 8.4, 8.9, 1.0, 4.7, 0.8, 1.2, 7.7, 4.2, 5.3, 3.9, 0.8, 7.9, 1.2, 8.5, 8.8]\n","ROC-AUC score: 0.9922\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 3 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9949\n","Average training loss: 0.0078\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[0.7, 7.7, 9.4, 9.2, 1.8, 9.4, 9.3, 9.2, 0.9, 0.7, 9.3, 9.2, 7.8, 8.8, 9.0, 8.9, 0.8, 9.1, 9.2, 9.0, 1.3, 9.3, 8.7, 8.5, 8.7, 9.4, 9.2, 8.6, 8.7, 9.2, 9.3, 9.2, 9.1, 9.2, 9.0, 9.1, 5.7, 9.1, 9.0, 9.2, 7.8, 9.3, 9.3, 9.4, 9.1, 1.0, 8.8, 9.3, 0.8, 1.2, 8.8, 1.2, 8.6, 0.8, 9.2, 9.3, 9.0, 9.0, 9.2, 8.9, 9.0, 6.1, 1.0, 8.5, 3.0, 8.8, 9.1, 1.0, 1.2, 8.3, 1.3, 9.2, 9.2, 9.3, 9.3, 9.1, 0.7, 1.0, 9.1, 9.2, 9.2, 9.1, 8.1, 9.3, 9.2, 9.1, 0.7, 1.6, 9.2, 0.8, 1.3, 8.4, 1.2, 9.0, 1.0, 9.2, 9.3, 9.0, 9.3, 8.9, 9.3, 9.2, 8.9, 8.6, 9.2, 8.4, 8.6, 9.0, 9.3, 0.9, 6.0, 7.8, 9.1, 8.9, 0.9, 8.0, 9.1, 1.5, 9.2, 1.1, 9.2, 9.2, 9.1, 9.0, 9.2, 9.2, 9.3, 9.1, 1.1, 9.2, 1.1, 9.3, 9.1, 8.8, 9.3, 0.9, 9.2, 9.2, 9.1, 1.2, 9.3, 9.1, 9.3, 8.1, 9.2, 7.3, 2.4, 8.9, 9.1, 8.8, 9.2, 9.3, 9.3, 9.2, 8.2, 9.0, 9.1, 9.1, 1.2, 0.8, 9.3, 9.2, 1.3, 9.0, 8.9, 0.7, 9.3, 9.2, 8.7, 0.9, 9.2, 8.9, 0.8, 8.5, 9.2, 9.2, 0.8, 9.3, 9.0, 9.3, 9.1, 9.3, 8.7, 9.0, 9.0, 9.3, 9.1, 8.9, 1.0, 9.0, 9.1, 8.2, 0.8, 9.1, 8.9, 8.8, 9.3, 9.3, 8.9, 8.6, 8.9, 9.3, 0.9, 1.5, 9.3, 8.4, 0.9, 8.8, 9.3, 0.7, 9.2, 9.3, 9.2, 9.3, 9.2, 0.8, 9.2, 8.9, 9.3, 9.1, 9.3, 9.0, 8.0, 9.0, 9.0, 6.8, 9.2, 8.3, 8.9, 8.1, 0.8, 9.2, 8.8, 9.1, 0.8, 1.3, 9.3, 9.4, 1.1, 9.3, 9.2, 8.6, 0.8, 0.8, 1.4, 9.0, 4.7, 7.3, 0.7, 9.2, 9.2, 9.2, 1.0, 1.3, 8.6, 8.9, 1.8, 4.0, 8.7, 9.1, 0.9, 9.1, 9.0, 1.0, 9.3, 0.9, 9.1, 1.0, 8.9, 9.3, 8.2, 9.3, 9.2, 1.1, 8.9, 9.1, 9.3, 9.3, 4.1, 8.9, 9.4, 8.6, 8.9, 9.0, 9.2, 0.8, 0.8, 9.0, 0.7, 9.1, 9.2, 9.3, 8.9, 8.4, 8.9, 0.9, 8.9, 7.7, 9.3, 0.8, 8.1, 9.0, 9.1, 2.2, 8.6, 8.5, 9.3, 1.8, 9.2, 8.7, 9.1, 1.0, 9.0, 8.9, 7.2, 8.7, 9.4, 9.3, 9.0, 0.7, 9.1, 8.8, 1.6, 9.2, 9.1, 9.1, 9.3, 9.2, 0.8, 9.0, 9.2, 9.1, 0.8, 1.8, 9.3, 9.2, 9.1, 9.3, 9.3, 0.9, 9.1, 9.1, 9.3, 9.1, 9.2, 9.1, 9.2, 9.3, 9.2, 9.0, 9.0, 1.0, 8.9, 9.3, 8.9, 7.8, 9.0, 9.1, 8.4, 9.0, 1.1, 7.5, 0.9, 8.9, 9.0, 9.2, 1.8, 0.8, 9.2, 9.0, 9.3, 9.2, 8.7, 9.1, 8.6, 5.4, 9.3, 9.1, 9.3, 0.9, 1.6, 8.2, 1.7, 9.1, 9.1, 9.3, 9.0, 9.1, 9.0, 9.1, 9.2, 8.8, 9.1, 8.0, 8.5, 9.1, 9.3, 1.9, 0.9, 1.1, 8.8, 9.2, 9.2, 9.3, 1.3, 8.8, 9.0, 9.2, 5.1, 9.2, 9.3, 9.2, 9.2, 6.7, 8.4, 2.3, 8.7, 9.2, 9.3, 8.9, 9.2, 0.8, 0.9, 1.1, 9.3, 5.6, 8.5, 9.2, 1.9, 1.1, 9.0, 0.8, 1.3, 0.9, 0.7, 9.0, 9.2, 9.1, 9.2, 9.2, 9.2, 7.9, 8.5, 9.3, 9.1, 8.5, 9.4, 1.0, 9.2, 7.5, 8.9, 2.0, 1.2, 1.4, 9.1, 9.3, 9.1, 9.2, 8.8, 1.4, 2.9, 9.0, 9.2, 9.3, 9.2, 8.4, 1.1, 0.7, 9.2, 9.3, 9.3, 9.2, 9.2, 9.2, 8.6, 8.4, 8.6, 9.2, 8.9, 9.2, 9.2, 9.4, 8.8, 8.8, 8.6, 9.3, 7.2, 9.3, 8.2, 9.1, 7.9, 9.2, 9.3, 9.2, 9.0, 8.7, 0.9, 2.1, 9.3, 9.4, 1.1, 9.0, 9.3, 9.0, 9.2, 9.0, 1.3, 9.2, 9.1, 5.3, 1.1, 6.7, 8.9, 9.2, 2.1, 9.1, 9.2, 0.7, 8.8, 8.6, 0.8, 9.1, 8.7, 9.0, 9.2, 9.2, 9.3, 8.9, 0.8, 9.3, 0.8, 9.3, 0.8, 9.2, 9.2, 1.0, 1.0, 5.4, 9.3, 8.0, 8.2, 9.1, 8.7, 9.3, 8.3, 8.9, 1.3, 9.3, 9.2, 1.2, 1.0, 9.2, 8.8, 8.6, 1.3, 9.0, 8.8, 9.4, 1.5, 9.0, 9.3, 9.1, 9.3, 8.9, 8.9, 0.8, 9.0, 9.3, 9.3, 9.2, 9.2, 9.2, 8.8, 8.6, 8.9, 9.1, 4.3, 8.6, 8.9, 9.0, 8.5, 9.2, 0.7, 9.1, 8.3, 8.7, 9.0, 9.2, 8.8, 7.1, 0.8, 9.0, 7.9, 9.2, 9.4, 9.1, 9.4, 9.3, 9.2, 9.2, 8.1, 1.3, 9.2, 0.8, 1.6, 9.3, 8.9, 9.2, 9.1, 1.6, 1.9, 9.0, 7.2, 2.0, 7.8, 9.3, 9.0, 7.1, 1.2, 1.1, 8.0, 9.2, 1.0, 9.2, 8.9, 8.7, 2.4, 8.6, 9.0, 9.1, 9.3, 9.3, 0.8, 6.7, 9.1, 9.2, 8.2, 9.3, 0.9, 8.9, 9.2, 8.6, 1.0, 9.3, 9.1, 8.9, 8.7, 8.1, 9.0, 9.2, 9.0, 9.1, 8.9, 1.0, 7.1, 9.0, 8.9, 9.2, 9.1, 9.1, 1.1, 9.1, 0.8, 9.3, 9.1, 9.3, 9.1, 7.6, 8.2, 8.3, 9.3, 9.2, 8.9, 9.2, 2.8, 0.9, 9.1, 9.1, 9.1, 7.5, 8.9, 8.8, 9.0, 9.3, 9.3, 9.3, 9.1, 9.1, 1.3, 9.2, 9.1, 9.2, 9.3, 8.7, 7.3, 0.9, 8.9, 9.0, 9.0, 9.1, 0.8, 0.7, 1.3, 1.5, 8.5, 8.9, 9.1, 9.2, 9.1, 2.6, 0.6, 0.8, 8.5, 9.2, 9.0, 9.2, 9.3, 8.9, 1.2, 9.2, 9.3, 3.0, 1.0, 8.8, 9.1, 0.8, 8.7, 7.7, 0.7, 5.8, 8.9, 0.9, 0.7, 9.3, 9.2, 1.3, 8.9, 9.4, 4.6, 9.3, 0.9, 1.3, 9.2, 8.4, 8.8, 9.3, 8.9, 9.1, 9.1, 9.1, 7.2, 9.2, 9.0, 0.8, 9.1, 9.0, 9.2, 3.1, 9.2, 9.3, 9.0, 2.5, 9.3, 8.4, 9.4, 9.2, 9.1, 4.1, 8.8, 9.2, 9.1, 9.2, 9.1, 8.2, 9.2, 9.1, 9.3, 9.0, 9.3, 9.3, 9.0, 9.0, 8.8, 9.2, 9.1, 9.2, 9.2, 9.2, 9.2, 9.3, 9.1, 8.9, 9.4, 9.1, 9.4, 9.3, 8.3, 9.3, 9.1, 9.3, 9.1, 8.9, 8.4, 8.8, 8.8, 9.1, 9.2, 9.2, 9.1, 9.2, 6.7, 9.3, 8.6, 1.1, 8.9, 0.8, 1.2, 9.3, 8.7, 9.2, 9.2, 8.9, 3.1, 8.1, 2.2, 0.9, 0.8, 8.5, 2.9, 9.1, 9.3, 1.0, 7.9, 8.8, 9.2, 1.4, 9.2, 1.1, 9.1, 0.8, 8.8, 0.7, 8.6, 9.2, 9.0, 1.0, 9.1, 9.2, 9.0, 0.9, 9.2, 1.2, 9.2, 9.3, 7.9, 9.2, 9.2, 1.0, 8.5, 9.3, 0.7, 9.3, 9.2, 8.5, 9.0, 9.2, 9.4, 9.1, 9.1, 8.3, 9.0, 8.4, 0.7, 1.8, 7.2, 9.3, 8.9, 7.8, 9.3, 1.2, 8.8, 9.2, 8.9, 9.3, 9.1, 9.3, 8.9, 8.8, 1.1, 9.2, 7.2, 8.2, 8.9, 9.1, 8.6, 9.1, 1.9, 9.3, 8.8, 1.2, 9.1, 1.5, 1.4, 9.3, 6.9, 0.9, 9.3]\n","ROC-AUC score: 0.9989\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 4 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9976\n","Average training loss: 0.0047\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[9.3, 1.0, 9.0, 9.2, 9.4, 9.0, 8.6, 1.6, 9.3, 9.4, 8.7, 0.7, 9.4, 9.4, 9.3, 9.3, 0.6, 9.3, 9.3, 9.3, 9.3, 0.6, 9.2, 9.4, 9.4, 9.1, 8.6, 7.4, 0.8, 1.2, 9.0, 7.4, 9.3, 7.6, 9.3, 9.1, 9.2, 9.3, 7.6, 0.7, 9.2, 0.8, 0.7, 1.0, 8.8, 9.3, 9.2, 9.1, 0.6, 9.5, 9.1, 9.4, 9.0, 0.7, 9.2, 6.7, 8.9, 9.4, 9.3, 3.2, 9.4, 5.1, 9.2, 9.2, 0.7, 8.8, 9.3, 0.6, 9.1, 9.4, 9.3, 9.2, 8.9, 9.2, 9.4, 9.2, 9.3, 8.6, 6.9, 9.1, 0.8, 9.3, 0.8, 0.6, 0.8, 9.0, 1.4, 9.3, 9.1, 9.2, 9.5, 9.3, 8.8, 7.6, 8.9, 8.6, 9.3, 9.2, 8.3, 9.1, 8.5, 9.3, 8.8, 7.4, 0.9, 0.7, 8.9, 9.4, 0.9, 0.8, 0.9, 9.4, 9.3, 9.3, 7.3, 9.3, 0.7, 0.7, 1.5, 0.8, 9.2, 9.4, 9.1, 0.8, 1.1, 9.1, 8.9, 0.7, 0.7, 0.8, 0.7, 7.8, 9.3, 9.2, 9.3, 8.9, 9.0, 0.6, 9.3, 8.5, 9.2, 9.4, 7.0, 9.2, 9.3, 9.3, 9.3, 9.3, 9.4, 0.8, 8.9, 0.9, 9.1, 9.0, 9.2, 9.2, 9.3, 9.2, 9.2, 9.3, 0.6, 9.2, 9.2, 9.3, 9.3, 9.2, 9.4, 0.9, 9.2, 9.2, 8.9, 9.3, 9.3, 9.3, 9.0, 7.7, 9.5, 9.3, 8.6, 9.4, 7.7, 8.0, 1.5, 1.4, 8.4, 0.6, 7.3, 0.7, 8.7, 0.8, 9.2, 9.4, 0.7, 9.4, 0.9, 0.6, 9.3, 0.8, 8.8, 7.9, 8.5, 8.3, 9.0, 9.1, 9.1, 8.7, 8.5, 8.9, 0.7, 1.5, 8.9, 8.9, 9.2, 8.9, 0.7, 0.8, 7.1, 9.4, 8.7, 1.6, 8.8, 0.6, 0.6, 9.3, 9.3, 9.3, 9.2, 8.8, 9.3, 9.1, 6.5, 8.4, 9.1, 1.7, 8.9, 0.7, 8.4, 1.4, 8.8, 0.9, 9.4, 9.3, 8.3, 9.2, 9.3, 9.0, 1.1, 7.0, 0.7, 0.7, 8.5, 9.3, 9.4, 1.0, 8.8, 0.6, 1.0, 9.0, 9.2, 9.0, 0.6, 8.8, 8.9, 9.1, 9.3, 9.2, 0.7, 0.9, 9.0, 9.2, 9.3, 8.8, 0.8, 9.4, 9.0, 1.3, 9.2, 9.4, 9.4, 9.4, 9.0, 8.9, 9.4, 8.7, 9.4, 9.2, 0.8, 1.0, 0.6, 0.9, 9.4, 7.1, 9.2, 7.1, 0.7, 9.3, 9.3, 9.2, 9.3, 9.0, 9.3, 8.3, 9.2, 9.0, 9.5, 9.4, 9.2, 1.0, 9.0, 8.8, 8.9, 9.3, 0.9, 9.4, 9.4, 0.7, 0.7, 9.3, 9.0, 9.0, 0.8, 6.0, 1.3, 9.3, 2.1, 9.3, 1.0, 9.4, 0.7, 9.3, 9.4, 8.5, 9.2, 9.3, 9.3, 8.6, 8.9, 8.8, 8.6, 1.1, 9.4, 9.4, 4.3, 9.2, 0.9, 9.3, 8.9, 9.4, 9.3, 9.4, 9.1, 9.4, 9.4, 9.4, 9.2, 9.4, 9.1, 0.7, 9.2, 8.8, 9.2, 0.9, 9.3, 9.2, 9.1, 9.0, 9.3, 9.0, 9.4, 9.3, 8.9, 9.4, 8.8, 9.1, 9.1, 9.2, 9.1, 9.3, 9.1, 6.8, 0.9, 9.2, 1.0, 9.2, 9.3, 1.3, 0.8, 9.3, 9.2, 9.3, 8.6, 1.1, 5.0, 9.2, 0.9, 8.3, 0.9, 9.4, 8.9, 9.3, 9.1, 9.4, 9.0, 0.8, 9.3, 9.2, 9.1, 0.6, 0.7, 1.1, 9.1, 9.1, 9.2, 0.9, 9.2, 9.3, 9.2, 9.4, 9.3, 9.2, 6.4, 9.3, 9.3, 9.1, 9.0, 6.4, 8.8, 0.6, 9.2, 9.2, 9.2, 4.5, 8.6, 9.3, 9.2, 9.3, 9.1, 8.9, 8.4, 9.4, 8.9, 9.4, 4.5, 9.2, 7.2, 9.4, 0.9, 8.3, 0.6, 0.7, 9.3, 9.1, 0.6, 9.3, 8.6, 9.4, 8.8, 0.8, 9.3, 1.0, 8.9, 1.1, 9.0, 9.2, 7.8, 8.8, 9.2, 0.8, 9.3, 7.6, 8.5, 9.2, 0.8, 9.2, 9.2, 9.3, 1.1, 9.4, 9.2, 9.0, 1.3, 9.3, 8.7, 0.8, 1.0, 1.0, 0.8, 9.4, 9.2, 8.9, 9.2, 9.4, 9.3, 9.4, 8.8, 1.3, 9.3, 9.3, 9.4, 9.1, 1.0, 1.2, 9.3, 0.7, 9.1, 8.3, 0.7, 9.0, 9.2, 9.0, 9.0, 9.2, 8.2, 9.1, 0.8, 9.1, 9.4, 1.1, 0.6, 8.8, 9.3, 9.1, 9.1, 9.4, 9.4, 1.2, 1.0, 9.1, 1.9, 9.3, 4.7, 8.5, 9.4, 9.1, 9.2, 9.4, 9.4, 9.4, 2.2, 1.5, 8.8, 9.3, 8.5, 9.3, 0.6, 9.3, 9.3, 8.9, 9.3, 9.4, 9.2, 9.1, 9.4, 9.3, 9.0, 2.2, 9.3, 9.3, 9.4, 9.4, 9.2, 0.7, 9.1, 9.4, 9.2, 0.8, 9.4, 9.5, 9.4, 9.1, 9.4, 9.1, 1.3, 7.9, 9.2, 0.8, 9.2, 9.3, 9.3, 9.4, 9.2, 0.6, 8.6, 0.7, 9.2, 9.3, 9.4, 9.4, 9.5, 9.1, 8.0, 9.1, 8.9, 9.3, 0.8, 9.4, 9.4, 9.3, 9.3, 0.7, 0.8, 0.8, 9.1, 9.2, 9.1, 8.9, 8.0, 9.2, 0.7, 9.3, 9.3, 7.9, 9.0, 9.2, 9.3, 9.3, 8.3, 9.3, 9.3, 8.3, 9.3, 9.2, 9.0, 8.1, 9.2, 8.9, 0.8, 9.2, 9.1, 1.2, 6.6, 9.1, 9.4, 9.2, 9.3, 2.3, 9.4, 0.9, 9.2, 9.2, 9.4, 9.1, 9.2, 9.3, 9.2, 1.1, 9.1, 8.4, 9.0, 0.6, 9.2, 8.4, 1.6, 1.2, 9.3, 9.1, 9.2, 9.3, 8.4, 0.7, 8.9, 9.1, 2.1, 9.1, 7.8, 9.3, 1.2, 0.7, 0.7, 8.9, 9.2, 9.1, 9.3, 2.1, 0.6, 9.3, 9.1, 0.6, 8.5, 9.1, 9.1, 9.3, 8.7, 0.6, 8.8, 9.2, 9.2, 9.2, 8.4, 9.4, 9.3, 9.1, 9.0, 1.1, 9.4, 8.9, 9.2, 0.8, 0.9, 9.3, 9.1, 9.1, 0.7, 0.6, 9.3, 9.0, 9.3, 9.4, 9.5, 9.3, 9.2, 8.4, 8.3, 1.0, 9.1, 9.3, 9.1, 9.4, 8.9, 9.3, 9.4, 9.2, 9.2, 8.6, 9.4, 9.0, 9.3, 9.3, 9.1, 8.5, 9.2, 9.2, 9.4, 9.0, 9.5, 8.9, 5.0, 0.6, 9.4, 5.9, 9.2, 9.4, 9.1, 0.6, 9.0, 5.9, 0.8, 9.4, 9.3, 7.1, 9.1, 9.4, 0.8, 8.0, 0.6, 7.7, 1.0, 9.2, 9.4, 9.2, 0.8, 9.2, 7.8, 9.3, 9.5, 8.0, 9.4, 9.0, 7.3, 3.0, 8.9, 0.8, 1.0, 9.4, 9.2, 9.3, 9.4, 9.3, 0.8, 9.1, 9.1, 9.2, 9.3, 9.0, 9.2, 9.3, 9.4, 9.3, 9.2, 7.9, 9.3, 8.9, 9.4, 8.0, 8.6, 9.0, 8.9, 0.6, 9.0, 9.4, 9.2, 9.1, 0.7, 9.0, 0.7, 8.9, 9.3, 9.2, 9.4, 0.5, 1.1, 9.2, 9.4, 9.1, 9.4, 7.9, 9.4, 9.3, 9.4, 2.7, 0.8, 8.9, 9.2, 8.8, 9.3, 9.2, 9.4, 8.7, 8.4, 0.7, 8.5, 9.4, 9.3, 9.2, 9.1, 5.2, 9.3, 9.1, 9.4, 0.8, 9.2, 8.9, 0.7, 9.4, 9.1, 0.7, 9.1, 9.1, 0.7, 8.7, 9.2, 8.9, 9.4, 9.2, 8.6, 9.4, 9.4, 9.2, 9.4, 0.9, 9.0, 9.2, 9.3, 9.2, 9.2, 9.1, 9.1, 9.1, 9.0, 1.4, 8.7, 9.1, 9.0, 8.6, 9.3, 9.1, 9.1, 4.9, 7.5, 7.9, 9.1, 9.2, 3.8, 9.3, 9.2, 0.9, 0.7, 9.3, 8.8, 9.1, 9.2, 1.1, 9.4, 9.1, 6.7, 9.2, 9.1, 9.0, 1.2, 9.2, 0.9, 0.7, 9.3, 0.8, 9.3, 9.4, 9.2]\n","ROC-AUC score: 0.9999\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 5 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9991\n","Average training loss: 0.0031\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[9.5, 9.6, 9.6, 0.6, 9.6, 9.6, 9.5, 9.5, 9.5, 9.3, 9.6, 9.5, 9.5, 9.6, 9.5, 0.5, 9.5, 0.6, 9.4, 9.5, 9.6, 9.5, 9.4, 9.6, 9.4, 9.4, 9.6, 9.6, 0.5, 9.2, 9.1, 0.5, 9.3, 9.6, 9.6, 9.6, 7.2, 1.3, 9.4, 9.4, 9.3, 0.5, 9.7, 0.7, 9.2, 9.6, 9.5, 9.4, 9.1, 9.4, 0.6, 0.4, 9.4, 9.1, 9.6, 9.6, 9.5, 9.5, 9.3, 9.6, 0.6, 9.5, 9.3, 9.5, 0.7, 9.4, 9.6, 9.5, 9.5, 9.3, 0.5, 9.3, 9.6, 0.6, 9.5, 9.5, 1.3, 9.4, 9.5, 0.9, 9.6, 0.6, 9.5, 8.6, 9.4, 0.9, 9.1, 9.6, 1.1, 9.5, 0.6, 9.6, 9.6, 9.6, 9.4, 9.4, 9.5, 9.5, 9.6, 9.5, 9.2, 9.4, 8.9, 0.7, 8.9, 9.3, 9.5, 1.6, 9.5, 9.5, 0.5, 9.2, 9.5, 0.7, 9.6, 0.7, 9.5, 0.6, 9.5, 9.6, 9.3, 9.5, 9.4, 3.4, 9.2, 9.5, 9.6, 9.6, 9.6, 0.5, 4.7, 9.6, 0.6, 9.6, 9.4, 9.4, 0.6, 9.4, 9.5, 9.5, 1.0, 9.5, 0.7, 9.5, 9.5, 9.4, 9.3, 9.4, 9.3, 9.1, 0.7, 9.3, 9.4, 1.1, 9.6, 9.6, 1.8, 9.4, 9.2, 9.4, 9.6, 9.6, 0.6, 9.2, 9.6, 9.6, 9.2, 9.5, 9.3, 9.3, 9.6, 8.8, 9.0, 9.6, 8.8, 8.9, 0.5, 9.5, 8.9, 9.5, 0.7, 0.8, 9.6, 9.5, 9.4, 9.6, 9.3, 9.3, 8.2, 9.3, 9.6, 9.2, 9.3, 9.1, 9.5, 9.6, 8.7, 8.9, 9.5, 1.0, 9.3, 9.6, 9.5, 0.8, 9.3, 9.5, 0.6, 9.4, 9.5, 9.5, 9.5, 9.6, 9.5, 9.1, 9.6, 9.3, 1.1, 5.2, 9.3, 9.6, 9.4, 9.5, 0.9, 9.6, 9.6, 9.6, 2.3, 9.5, 9.3, 0.5, 9.6, 0.9, 9.6, 9.4, 1.0, 9.4, 9.6, 0.9, 9.6, 0.8, 0.6, 9.5, 9.3, 9.6, 8.7, 9.5, 9.6, 9.5, 9.6, 9.6, 9.1, 9.5, 0.7, 9.5, 9.3, 9.6, 0.5, 1.5, 9.2, 1.1, 9.0, 9.4, 9.5, 9.5, 9.6, 9.5, 9.5, 9.5, 9.3, 8.5, 9.6, 8.8, 9.4, 0.7, 9.6, 9.6, 0.5, 9.6, 9.6, 0.6, 9.5, 9.5, 7.3, 9.4, 0.5, 9.5, 3.1, 8.9, 9.7, 9.5, 9.6, 0.5, 8.9, 9.5, 9.6, 9.4, 9.5, 9.6, 2.0, 9.5, 9.5, 9.4, 9.3, 9.4, 9.5, 9.5, 6.2, 0.8, 0.6, 9.6, 9.3, 0.5, 9.4, 0.5, 8.7, 9.5, 1.1, 9.3, 9.2, 1.2, 8.5, 0.6, 9.3, 9.1, 9.5, 9.6, 9.5, 9.0, 0.8, 9.4, 9.6, 9.5, 9.1, 9.5, 9.7, 9.6, 9.3, 0.7, 9.6, 8.3, 0.5, 9.5, 9.6, 0.7, 9.1, 9.5, 9.4, 1.4, 9.6, 9.2, 8.3, 0.6, 0.6, 8.7, 9.4, 9.6, 9.5, 0.8, 9.3, 9.2, 9.6, 9.4, 8.4, 9.3, 0.8, 4.0, 0.8, 0.5, 9.5, 0.7, 9.4, 0.6, 9.5, 9.6, 0.6, 9.6, 9.6, 1.6, 9.6, 9.3, 9.5, 9.4, 9.0, 9.5, 9.6, 9.6, 9.0, 9.4, 9.0, 9.6, 9.5, 0.9, 9.6, 9.3, 9.2, 9.6, 9.6, 9.4, 0.6, 9.5, 9.6, 9.6, 9.5, 9.6, 9.4, 9.6, 8.8, 9.6, 9.6, 9.3, 9.4, 9.5, 9.6, 1.0, 0.8, 9.2, 0.7, 9.6, 9.6, 1.1, 9.4, 9.3, 9.4, 9.6, 9.6, 0.7, 9.6, 9.2, 1.1, 9.5, 9.5, 9.6, 9.6, 9.5, 9.4, 0.8, 9.7, 9.5, 9.4, 0.6, 9.5, 9.6, 9.4, 9.4, 9.5, 9.4, 9.5, 0.5, 9.6, 0.7, 9.6, 8.9, 0.6, 9.5, 9.3, 9.6, 9.2, 9.4, 9.3, 1.6, 1.0, 9.6, 9.2, 9.3, 9.1, 9.2, 9.6, 9.6, 9.5, 9.6, 9.5, 9.5, 9.6, 9.6, 9.2, 9.5, 9.5, 9.5, 9.5, 9.3, 9.5, 9.5, 9.5, 9.6, 9.4, 9.4, 9.4, 9.5, 9.6, 9.6, 9.1, 9.5, 9.6, 9.4, 0.7, 0.9, 0.6, 9.2, 9.7, 9.5, 9.1, 9.5, 9.5, 9.6, 0.6, 9.6, 9.6, 9.6, 1.6, 9.5, 0.6, 9.4, 0.5, 9.5, 9.2, 9.4, 9.5, 9.4, 9.5, 9.6, 9.6, 0.8, 2.3, 9.5, 9.6, 9.5, 9.6, 1.3, 9.6, 9.4, 9.4, 9.6, 9.5, 9.5, 8.9, 9.3, 9.5, 0.6, 6.4, 9.6, 9.4, 2.1, 0.5, 9.4, 9.5, 9.5, 9.5, 9.6, 9.5, 9.6, 0.9, 9.5, 9.4, 9.4, 0.5, 9.6, 9.5, 9.5, 9.1, 9.3, 9.5, 9.6, 0.5, 0.7, 9.6, 0.8, 9.5, 9.6, 1.6, 9.6, 1.5, 9.6, 9.5, 9.4, 9.5, 0.6, 4.7, 9.1, 9.6, 9.6, 9.5, 9.5, 0.8, 9.5, 8.4, 1.0, 9.5, 9.6, 9.5, 0.8, 9.2, 9.6, 0.6, 9.3, 9.4, 9.6, 9.4, 8.5, 1.0, 0.7, 9.4, 9.6, 1.0, 0.6, 1.0, 1.0, 1.0, 9.6, 9.4, 0.9, 0.7, 9.5, 2.0, 9.6, 9.6, 9.5, 0.6, 9.5, 9.4, 9.6, 9.5, 3.2, 9.1, 1.1, 9.5, 0.5, 9.4, 9.5, 9.6, 0.5, 0.8, 9.6, 9.5, 9.6, 9.5, 9.5, 9.2, 9.6, 9.5, 9.5, 8.9, 0.7, 9.3, 1.1, 9.4, 6.7, 9.6, 0.9, 0.5, 8.8, 1.3, 9.3, 9.6, 9.1, 0.5, 0.5, 9.5, 0.5, 9.3, 9.6, 9.6, 9.6, 9.5, 9.2, 1.0, 9.4, 9.6, 9.3, 8.8, 9.6, 0.5, 9.5, 9.3, 9.2, 9.5, 9.3, 1.2, 9.6, 0.6, 1.2, 9.5, 1.0, 9.4, 9.4, 9.4, 9.3, 9.6, 9.5, 0.6, 9.6, 1.1, 9.5, 9.6, 9.4, 9.6, 9.6, 0.8, 9.5, 1.5, 9.4, 9.5, 9.5, 9.4, 9.2, 8.6, 0.6, 9.6, 9.6, 9.4, 0.6, 9.6, 9.5, 8.3, 0.5, 9.3, 1.1, 9.2, 9.4, 0.6, 0.6, 9.5, 9.5, 9.4, 9.6, 9.6, 9.3, 9.5, 9.2, 9.6, 9.6, 9.6, 9.6, 9.6, 9.6, 9.4, 9.5, 9.5, 9.4, 9.5, 9.6, 9.5, 9.5, 9.4, 9.5, 9.5, 0.5, 0.6, 9.4, 9.6, 9.4, 9.4, 9.3, 8.2, 0.5, 2.4, 9.0, 9.6, 9.0, 9.6, 0.5, 9.5, 9.6, 9.6, 9.6, 0.7, 1.3, 0.6, 9.6, 0.7, 9.4, 9.5, 9.3, 9.3, 9.5, 9.6, 0.8, 9.6, 9.4, 8.5, 9.7, 9.6, 9.5, 2.0, 1.2, 0.9, 9.6, 9.3, 9.4, 9.6, 0.6, 0.6, 9.2, 9.5, 9.3, 9.6, 9.6, 9.6, 1.1, 9.5, 9.5, 9.6, 9.5, 9.5, 9.6, 9.6, 9.4, 0.7, 0.7, 0.5, 0.5, 9.5, 2.2, 9.2, 9.6, 9.5, 9.1, 9.6, 9.5, 9.5, 9.6, 9.6, 1.4, 9.5, 1.2, 9.4, 9.3, 0.8, 8.2, 9.4, 9.6, 9.6, 9.6, 0.5, 9.6, 9.5, 9.5, 9.6, 9.6, 9.5, 9.5, 9.4, 9.6, 9.6, 9.4, 9.5, 9.4, 9.1, 9.3, 1.1, 9.5, 9.6, 9.5, 9.6, 9.5, 9.4, 9.2, 9.6, 9.4, 8.9, 9.5, 0.5, 8.3, 9.6, 9.5, 9.2, 0.9, 9.3, 9.3, 9.6, 1.5, 0.5, 9.6, 9.5, 9.6, 9.5, 9.5, 9.6, 9.5, 9.5, 9.6, 2.2, 0.8, 9.3, 9.5, 9.5, 9.6, 9.5, 9.0, 9.6, 9.5, 9.4, 0.8, 0.9, 9.4, 9.6, 9.5, 9.0, 8.6, 8.3, 9.6, 9.6, 9.5, 9.5, 9.6, 9.5, 9.2, 9.3]\n","ROC-AUC score: 0.9999\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 6 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9996\n","Average training loss: 0.0020\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[9.7, 9.7, 9.5, 9.7, 9.7, 9.7, 0.7, 9.7, 0.6, 9.0, 0.5, 9.2, 9.6, 9.7, 9.7, 9.7, 0.5, 0.4, 9.4, 9.6, 9.5, 0.8, 9.5, 9.6, 0.6, 9.6, 9.7, 9.7, 9.5, 9.6, 9.3, 9.7, 0.6, 9.3, 0.5, 7.2, 0.4, 9.4, 9.7, 9.7, 0.9, 9.7, 9.7, 9.3, 9.7, 9.6, 0.5, 9.5, 9.6, 9.7, 9.6, 9.5, 0.4, 9.5, 9.7, 9.7, 0.4, 0.4, 9.4, 9.6, 9.7, 0.6, 9.6, 9.7, 8.6, 9.7, 9.6, 8.9, 9.4, 9.6, 9.6, 9.7, 9.1, 9.7, 9.6, 9.6, 9.5, 9.7, 9.6, 9.7, 0.4, 9.7, 9.2, 7.9, 0.5, 9.4, 9.7, 9.6, 9.7, 9.6, 0.8, 9.7, 9.7, 9.2, 9.6, 0.4, 9.7, 9.3, 9.6, 9.7, 9.7, 9.7, 9.5, 9.7, 9.7, 9.6, 9.7, 9.7, 9.1, 9.5, 9.7, 9.6, 9.5, 9.6, 9.7, 2.3, 9.5, 0.7, 9.7, 9.7, 9.7, 9.6, 9.7, 0.4, 9.6, 9.5, 0.5, 9.6, 9.7, 1.0, 9.7, 0.5, 0.6, 9.6, 9.7, 9.7, 9.6, 0.3, 9.7, 9.6, 9.6, 9.5, 9.7, 9.7, 9.6, 9.7, 9.7, 9.7, 9.7, 9.5, 0.4, 9.4, 9.7, 0.6, 9.7, 9.6, 9.5, 9.7, 0.4, 0.4, 9.4, 9.7, 0.4, 9.7, 9.7, 9.0, 9.7, 9.5, 9.4, 9.7, 9.7, 9.6, 9.5, 9.6, 0.5, 9.4, 9.7, 9.7, 9.1, 9.7, 9.5, 9.5, 9.7, 9.6, 9.5, 9.7, 9.7, 9.2, 0.5, 9.4, 9.4, 9.7, 0.4, 9.7, 3.1, 9.7, 9.7, 9.5, 9.6, 9.6, 9.6, 9.7, 9.6, 9.6, 9.7, 1.0, 9.7, 9.2, 9.7, 9.6, 9.6, 0.6, 9.4, 9.7, 9.4, 9.6, 9.7, 9.7, 0.4, 9.3, 0.6, 9.2, 0.4, 0.5, 9.7, 0.4, 9.6, 0.4, 9.6, 9.5, 9.7, 9.7, 9.7, 8.7, 9.5, 9.4, 9.6, 9.7, 0.4, 9.5, 9.6, 0.6, 9.6, 9.0, 9.7, 9.7, 9.4, 9.7, 9.7, 9.7, 9.7, 9.3, 9.6, 9.6, 9.1, 0.4, 9.6, 1.1, 9.5, 9.7, 0.5, 0.7, 9.7, 9.5, 9.6, 9.6, 9.7, 9.6, 9.7, 9.7, 9.3, 0.5, 9.6, 9.5, 0.5, 2.0, 9.5, 9.7, 3.9, 9.4, 9.7, 9.7, 9.7, 0.4, 9.7, 9.6, 9.6, 9.7, 9.0, 9.5, 0.5, 9.7, 9.7, 9.6, 0.7, 7.9, 0.9, 9.7, 9.7, 9.6, 9.7, 9.6, 9.7, 9.2, 0.5, 9.6, 9.2, 0.5, 9.7, 9.7, 9.7, 9.3, 9.0, 0.4, 9.6, 9.7, 9.7, 0.4, 9.6, 9.4, 9.2, 9.2, 9.6, 9.3, 9.7, 9.6, 9.3, 0.4, 0.4, 9.6, 9.6, 9.7, 9.4, 9.3, 0.8, 0.9, 9.6, 9.7, 9.6, 9.7, 9.6, 9.5, 9.6, 9.7, 9.7, 9.7, 8.9, 9.5, 0.9, 0.9, 9.6, 9.7, 0.5, 0.4, 9.6, 1.2, 8.4, 9.7, 9.7, 9.6, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 0.6, 9.7, 9.7, 9.6, 9.6, 9.5, 9.5, 9.6, 9.7, 9.7, 0.4, 9.7, 9.6, 9.6, 9.7, 9.7, 9.7, 9.6, 9.7, 9.6, 9.6, 9.7, 9.4, 9.7, 0.4, 9.7, 0.6, 9.6, 9.7, 9.6, 0.4, 0.3, 9.6, 9.5, 7.8, 9.7, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.3, 9.6, 9.6, 9.6, 9.5, 9.7, 9.4, 9.0, 9.6, 9.5, 9.7, 9.6, 9.7, 9.6, 9.6, 9.7, 9.7, 0.5, 0.5, 9.7, 9.7, 9.7, 9.7, 9.5, 9.7, 9.6, 9.5, 8.7, 9.6, 9.7, 9.7, 9.7, 9.7, 9.6, 9.5, 9.7, 9.7, 9.7, 9.7, 0.5, 9.6, 9.7, 0.6, 9.7, 9.5, 9.7, 9.7, 0.6, 9.6, 9.7, 0.8, 9.7, 0.5, 9.2, 9.7, 9.5, 1.2, 0.4, 7.4, 0.8, 1.1, 9.7, 9.0, 9.0, 8.4, 9.6, 9.7, 9.6, 9.7, 9.7, 0.6, 9.6, 0.6, 9.6, 9.6, 9.6, 0.5, 0.6, 9.7, 9.7, 9.6, 0.7, 9.6, 9.5, 9.5, 9.5, 1.1, 9.7, 9.5, 9.6, 9.7, 9.7, 9.7, 0.7, 9.3, 9.7, 9.6, 0.4, 0.4, 9.7, 9.3, 9.3, 9.7, 9.1, 0.4, 9.6, 9.7, 9.5, 9.7, 9.7, 9.5, 9.7, 0.7, 9.7, 9.6, 9.7, 0.5, 9.6, 9.7, 0.5, 1.1, 9.7, 9.7, 0.4, 9.7, 9.7, 9.5, 0.4, 0.4, 9.6, 9.5, 9.6, 9.6, 9.6, 9.6, 9.6, 0.6, 9.6, 9.7, 9.7, 9.7, 9.5, 9.5, 9.5, 9.6, 9.5, 0.5, 0.4, 0.5, 0.6, 9.7, 9.7, 9.5, 3.9, 9.7, 9.6, 9.6, 9.6, 9.6, 9.5, 9.6, 9.6, 9.5, 9.7, 9.7, 9.5, 9.5, 0.5, 9.5, 9.6, 0.8, 0.5, 9.7, 9.7, 9.5, 9.7, 0.4, 9.6, 9.6, 9.7, 9.6, 9.6, 9.3, 9.7, 9.7, 9.7, 0.6, 9.6, 9.7, 9.7, 9.7, 0.4, 9.4, 0.6, 9.5, 9.7, 9.7, 9.7, 9.5, 9.6, 0.4, 9.6, 0.5, 0.4, 9.6, 9.6, 9.7, 0.5, 9.7, 9.7, 0.6, 0.4, 9.7, 9.6, 9.6, 0.5, 9.6, 9.7, 9.7, 9.6, 9.7, 9.7, 9.7, 0.8, 9.3, 9.7, 9.4, 0.5, 0.4, 9.7, 9.7, 0.5, 0.7, 0.6, 9.3, 9.6, 9.7, 9.6, 9.6, 0.5, 9.7, 9.4, 9.6, 9.6, 9.7, 0.4, 9.4, 9.7, 9.5, 9.6, 9.7, 9.7, 0.6, 9.7, 9.7, 9.6, 9.5, 0.4, 9.7, 9.6, 9.4, 0.4, 9.3, 9.6, 9.6, 9.7, 0.9, 9.3, 0.4, 0.6, 9.6, 9.6, 9.6, 9.6, 9.6, 1.0, 9.6, 0.4, 9.5, 9.6, 9.7, 9.6, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.6, 1.0, 0.7, 9.6, 9.6, 9.7, 9.7, 9.6, 9.5, 9.3, 9.7, 0.5, 0.5, 9.7, 9.5, 0.5, 9.6, 9.6, 0.4, 0.6, 9.7, 9.7, 9.7, 9.7, 9.6, 9.6, 9.3, 9.5, 9.6, 9.5, 0.8, 9.6, 9.6, 9.6, 9.5, 0.9, 9.6, 9.7, 9.2, 9.7, 0.4, 9.7, 9.7, 9.5, 8.9, 9.7, 9.6, 9.7, 9.7, 9.4, 0.7, 0.4, 9.5, 9.6, 0.5, 9.5, 9.7, 9.5, 9.6, 9.6, 9.7, 9.7, 9.6, 9.7, 9.6, 9.6, 9.7, 9.6, 9.7, 0.5, 9.6, 9.7, 0.4, 9.5, 9.7, 9.7, 9.6, 0.4, 9.4, 0.5, 9.7, 9.5, 9.5, 9.2, 9.7, 9.7, 0.6, 9.7, 9.7, 9.4, 1.1, 9.7, 9.7, 9.7, 9.7, 9.6, 9.7, 0.6, 9.7, 9.7, 9.7, 9.4, 9.6, 0.4, 9.4, 0.5, 9.6, 9.1, 9.6, 9.6, 9.6, 9.7, 9.7, 1.2, 9.5, 9.3, 9.6, 9.3, 9.7, 9.7, 9.6, 9.7, 9.6, 9.6, 9.7, 9.5, 9.5, 9.6, 9.5, 9.6, 9.3, 9.7, 9.6, 0.6, 9.7, 9.7, 9.7, 9.6, 0.6, 0.9, 9.5, 9.7, 9.6, 9.7, 9.7, 9.6, 9.7, 9.2, 0.5, 0.5, 3.1, 0.5, 9.7, 9.7, 9.7, 9.7, 9.3, 0.4, 9.5, 8.5, 9.7, 9.6, 9.7, 9.6, 9.7, 0.4, 9.7, 9.6, 9.7, 7.4, 0.4, 9.6, 9.6, 9.7, 9.7, 9.6, 9.6, 9.7, 0.7, 9.4, 9.7, 0.5, 9.7, 9.7, 9.6, 0.4, 9.7, 9.6, 9.5, 9.5, 9.7, 9.6, 9.7, 0.4, 0.5, 9.7, 9.7, 9.6, 9.0, 9.5, 9.6, 0.8, 0.6, 0.5, 9.5, 9.6, 0.4, 9.7]\n","ROC-AUC score: 0.9996\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 7 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9997\n","Average training loss: 0.0014\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[0.4, 0.5, 9.7, 0.5, 9.8, 9.8, 9.8, 0.5, 9.8, 0.5, 0.4, 9.8, 9.8, 9.7, 0.7, 9.7, 9.7, 9.8, 9.8, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8, 0.4, 9.8, 9.7, 9.7, 9.7, 9.7, 9.7, 0.4, 9.7, 9.7, 9.7, 9.6, 9.8, 9.5, 9.7, 9.7, 9.7, 0.4, 9.7, 9.7, 9.5, 0.4, 9.3, 9.6, 9.7, 9.7, 0.6, 9.7, 9.7, 0.6, 9.7, 0.5, 9.7, 0.7, 9.7, 9.8, 9.7, 9.7, 0.5, 9.6, 9.7, 9.8, 9.3, 9.7, 0.7, 9.3, 0.5, 9.7, 9.5, 9.7, 9.7, 0.5, 9.6, 9.7, 9.8, 9.7, 0.4, 9.8, 9.7, 9.7, 9.7, 0.5, 9.4, 9.8, 9.7, 9.4, 0.5, 0.4, 9.8, 9.8, 9.8, 8.8, 9.7, 9.8, 9.7, 9.6, 9.8, 9.7, 9.7, 9.6, 0.5, 0.8, 9.7, 9.7, 9.7, 9.7, 4.2, 9.5, 1.8, 9.7, 9.8, 9.8, 0.7, 9.8, 9.7, 9.7, 9.7, 9.8, 9.6, 9.7, 0.5, 9.7, 9.7, 9.6, 0.4, 9.8, 9.7, 9.7, 9.7, 9.7, 9.7, 0.4, 0.5, 9.7, 0.9, 9.6, 9.8, 0.7, 9.8, 9.7, 9.8, 0.4, 0.5, 9.6, 9.8, 9.7, 9.7, 9.7, 9.7, 0.5, 9.7, 0.4, 9.7, 0.4, 0.6, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.7, 0.5, 9.8, 9.7, 1.7, 9.7, 0.4, 1.3, 1.6, 9.6, 9.5, 9.8, 9.7, 9.6, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8, 9.7, 9.1, 9.7, 9.7, 0.4, 9.8, 9.7, 9.7, 9.7, 9.7, 0.5, 0.6, 0.4, 0.7, 9.8, 0.7, 9.8, 9.8, 9.7, 9.7, 0.9, 9.6, 9.7, 9.8, 9.6, 9.7, 9.8, 9.8, 9.6, 9.6, 9.8, 1.2, 9.7, 0.4, 9.7, 9.6, 0.6, 9.7, 0.5, 0.4, 0.4, 9.6, 9.7, 0.4, 0.6, 9.7, 0.8, 9.7, 0.7, 0.4, 9.6, 9.6, 9.7, 9.8, 9.7, 9.7, 9.7, 9.8, 9.5, 9.8, 9.7, 9.8, 9.5, 9.7, 9.7, 9.8, 0.7, 9.5, 9.7, 9.8, 9.8, 1.0, 9.8, 9.7, 9.7, 9.7, 0.7, 9.7, 9.7, 9.7, 9.6, 9.7, 9.6, 9.8, 0.4, 9.8, 0.4, 9.8, 9.6, 9.8, 9.8, 0.4, 9.8, 9.6, 9.8, 0.5, 0.6, 9.7, 9.7, 0.6, 0.8, 9.5, 9.6, 9.8, 9.7, 9.7, 9.7, 9.6, 9.7, 0.5, 9.7, 0.5, 9.7, 9.7, 4.0, 9.6, 0.4, 7.7, 9.6, 9.7, 9.7, 0.5, 0.6, 0.5, 9.8, 0.5, 9.7, 9.7, 9.7, 9.7, 9.7, 9.3, 9.8, 0.5, 9.7, 9.7, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 0.7, 0.4, 2.5, 9.8, 8.1, 9.5, 0.4, 9.3, 9.8, 9.7, 9.8, 9.8, 9.7, 9.5, 9.8, 9.8, 9.7, 9.6, 9.8, 9.6, 9.8, 9.7, 9.6, 9.7, 9.7, 0.4, 9.8, 9.8, 9.7, 0.6, 9.8, 9.8, 0.8, 9.7, 0.4, 9.8, 9.7, 9.7, 9.8, 9.7, 0.6, 9.6, 9.7, 9.7, 9.7, 9.6, 0.4, 9.8, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 0.6, 9.6, 9.8, 9.8, 9.7, 9.7, 9.5, 0.7, 0.8, 0.4, 9.7, 9.7, 9.7, 9.7, 9.7, 0.6, 8.8, 9.6, 0.4, 9.8, 9.7, 9.8, 9.7, 9.8, 9.6, 0.5, 9.8, 9.6, 9.7, 9.7, 9.8, 9.7, 0.4, 9.7, 9.7, 5.3, 0.9, 9.7, 9.7, 9.7, 0.4, 9.8, 9.6, 9.7, 9.6, 9.6, 9.7, 9.7, 9.7, 9.6, 9.6, 0.6, 1.0, 0.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 0.6, 0.4, 0.8, 9.5, 9.7, 9.5, 9.7, 9.7, 9.1, 9.3, 9.8, 9.3, 0.4, 0.5, 0.7, 0.4, 0.8, 9.7, 8.2, 0.6, 9.8, 9.8, 0.4, 9.7, 0.8, 9.6, 9.7, 9.7, 0.6, 0.5, 9.8, 9.6, 9.8, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.8, 9.8, 0.3, 9.7, 0.5, 0.5, 9.7, 9.7, 1.1, 0.6, 0.5, 9.8, 8.9, 9.7, 9.8, 0.4, 9.7, 9.7, 9.7, 9.7, 0.8, 0.5, 0.5, 9.8, 0.6, 9.7, 9.7, 9.7, 0.5, 9.6, 9.7, 0.4, 9.7, 9.7, 9.8, 0.6, 9.7, 9.7, 0.4, 9.5, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.6, 9.7, 9.5, 9.8, 0.4, 0.8, 9.7, 5.3, 1.1, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.8, 9.5, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8, 1.4, 9.8, 9.7, 9.7, 9.6, 0.5, 9.4, 9.8, 0.5, 9.7, 9.6, 9.7, 9.7, 9.7, 9.8, 0.7, 9.6, 9.1, 9.6, 9.8, 9.7, 9.7, 9.4, 9.8, 9.7, 0.3, 0.7, 9.7, 9.8, 9.7, 9.8, 9.6, 9.7, 9.7, 0.7, 9.7, 9.7, 9.6, 9.7, 0.5, 9.7, 9.7, 9.7, 9.7, 9.7, 9.7, 9.5, 9.8, 9.7, 9.3, 0.4, 9.8, 9.8, 9.7, 9.4, 9.8, 9.6, 0.4, 9.8, 9.7, 9.8, 0.6, 9.7, 9.5, 9.7, 9.8, 9.8, 9.8, 9.7, 9.7, 0.5, 9.5, 9.7, 9.7, 0.9, 4.2, 0.4, 9.6, 9.5, 9.7, 9.6, 9.7, 9.7, 0.7, 9.7, 9.6, 9.7, 9.6, 9.7, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.7, 9.7, 9.7, 0.6, 9.3, 9.8, 0.5, 9.6, 9.2, 9.6, 9.7, 9.7, 0.5, 0.4, 4.1, 9.7, 0.4, 0.5, 9.7, 0.6, 9.7, 9.7, 0.8, 9.8, 9.8, 9.7, 9.7, 9.7, 9.7, 9.6, 9.6, 9.7, 0.5, 9.7, 0.5, 9.7, 9.8, 9.8, 9.6, 9.7, 9.7, 9.7, 9.8, 9.8, 9.7, 9.5, 9.8, 9.8, 0.5, 9.8, 9.6, 0.4, 9.8, 9.7, 9.6, 9.8, 9.8, 0.5, 9.7, 0.5, 9.8, 9.8, 9.7, 9.8, 9.7, 0.5, 9.7, 9.8, 9.3, 0.9, 9.7, 9.7, 0.5, 9.8, 9.6, 0.5, 9.7, 9.7, 9.7, 9.7, 9.7, 9.8, 9.7, 9.7, 0.7, 9.7, 0.4, 9.7, 9.8, 9.7, 9.7, 9.8, 9.7, 9.7, 9.7, 9.7, 9.6, 0.8, 9.7, 9.7, 9.2, 9.8, 9.7, 1.0, 9.7, 0.5, 9.7, 9.7, 9.8, 0.5, 9.8, 9.7, 9.6, 9.6, 0.4, 9.4, 9.8, 0.4, 9.7, 0.5, 9.7, 9.7, 9.8, 9.8, 9.7, 0.9, 9.7, 9.8, 9.7, 9.8, 0.4, 9.8, 0.6, 9.5, 8.7, 9.7, 9.8, 9.7, 0.8, 9.8, 9.7, 9.6, 0.7, 0.4, 9.7, 9.7, 9.6, 9.8, 9.7, 9.7, 9.7, 9.8, 9.7, 0.9, 9.7, 9.7, 9.8, 0.4, 0.6, 9.7, 9.8, 9.8, 9.7, 9.7, 9.5, 9.7, 9.8, 9.7, 9.5, 9.7, 9.7, 9.7, 9.6, 9.8, 9.7, 9.8, 0.5, 0.3, 0.6, 0.4, 9.7, 9.7, 9.7, 4.2, 9.6, 9.8, 9.7, 0.6, 9.7, 9.6, 9.7, 9.7, 9.7, 9.7, 0.4, 9.8, 9.7, 9.5, 9.7, 9.7, 0.4, 9.8, 9.8, 9.7, 9.6, 9.7, 9.8, 9.7, 9.8, 9.5, 9.7, 9.7, 0.4, 9.7, 9.7, 9.1, 1.1, 9.7, 0.5, 0.4, 9.6, 9.7, 9.8, 9.7, 9.4, 0.9, 9.7, 9.7, 9.8, 9.7, 9.8, 9.6, 9.8, 0.5, 0.4, 9.1, 0.9, 9.8, 9.7, 9.8, 9.8, 9.1, 0.5, 9.8, 9.7, 9.3, 9.7, 9.7, 9.6, 9.6, 8.6, 9.4, 9.8]\n","ROC-AUC score: 0.9999\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 8 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9997\n","Average training loss: 0.0012\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 9.7, 9.6, 9.8, 9.8, 9.6, 0.6, 9.7, 9.8, 9.8, 9.7, 9.7, 9.8, 0.6, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 0.4, 9.7, 9.7, 9.8, 0.7, 9.8, 0.4, 0.4, 0.5, 8.1, 9.8, 9.8, 9.5, 9.7, 9.8, 9.7, 9.7, 9.7, 0.5, 9.8, 9.7, 0.5, 9.8, 9.7, 9.8, 9.7, 8.7, 9.8, 9.8, 0.6, 9.7, 9.8, 9.7, 9.8, 9.8, 0.5, 9.6, 0.5, 9.8, 9.8, 9.7, 9.7, 9.8, 9.0, 0.4, 0.4, 9.7, 9.7, 9.8, 9.8, 9.8, 9.7, 0.5, 9.8, 9.7, 0.4, 0.4, 9.7, 0.6, 0.5, 0.5, 9.6, 3.3, 9.3, 9.7, 9.3, 9.8, 9.8, 9.8, 0.4, 9.8, 0.5, 9.8, 9.8, 9.8, 9.7, 9.5, 9.8, 9.8, 1.1, 9.8, 9.8, 9.8, 9.5, 9.7, 9.6, 0.9, 0.6, 0.5, 9.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.4, 9.6, 0.5, 0.4, 9.8, 9.6, 9.7, 9.8, 9.7, 9.7, 0.4, 9.7, 9.8, 0.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 0.7, 9.8, 7.2, 9.6, 0.5, 0.5, 9.7, 9.7, 9.8, 9.8, 0.5, 9.7, 9.4, 9.7, 9.5, 9.8, 0.5, 9.7, 9.8, 9.8, 0.7, 9.8, 0.6, 9.7, 9.8, 9.8, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.5, 0.7, 9.8, 9.8, 0.5, 9.7, 9.8, 9.8, 9.7, 9.8, 0.5, 9.5, 9.7, 0.7, 0.4, 9.7, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.6, 0.5, 9.6, 1.0, 9.8, 0.5, 0.5, 9.8, 9.8, 9.8, 0.9, 9.8, 9.7, 9.7, 9.8, 0.4, 9.8, 0.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.7, 9.7, 9.5, 9.8, 9.8, 9.8, 9.8, 4.6, 9.8, 9.7, 9.8, 9.7, 9.6, 9.7, 9.6, 9.8, 9.8, 0.7, 9.8, 0.7, 0.4, 9.8, 0.5, 0.8, 9.7, 9.6, 9.5, 6.8, 9.7, 9.7, 9.7, 9.8, 0.6, 9.7, 9.8, 9.8, 9.7, 9.7, 9.7, 9.8, 9.7, 0.4, 9.8, 9.7, 9.7, 9.8, 0.8, 9.7, 9.7, 9.4, 9.7, 0.7, 9.7, 9.7, 9.7, 9.7, 9.8, 0.9, 0.5, 9.7, 9.8, 0.8, 9.7, 0.6, 9.7, 0.4, 0.4, 9.7, 9.8, 7.5, 9.7, 9.8, 0.7, 9.8, 9.8, 9.1, 9.8, 0.6, 9.8, 9.0, 9.6, 9.8, 0.8, 9.8, 9.8, 0.6, 4.4, 9.7, 0.5, 9.7, 1.5, 0.5, 9.7, 9.7, 9.7, 9.7, 9.2, 1.0, 9.8, 0.6, 0.4, 0.4, 9.8, 9.6, 9.8, 9.2, 8.9, 9.8, 9.7, 9.8, 9.4, 9.8, 9.7, 9.7, 9.7, 0.5, 9.7, 9.8, 9.8, 0.4, 9.7, 9.7, 9.8, 0.5, 0.5, 9.8, 9.4, 9.7, 9.8, 9.7, 0.3, 0.4, 0.5, 9.7, 9.7, 9.8, 0.5, 0.5, 2.4, 9.7, 9.7, 9.8, 9.7, 9.7, 0.5, 9.8, 9.7, 9.8, 9.7, 9.8, 1.1, 9.4, 9.7, 9.7, 9.8, 9.7, 9.7, 9.8, 9.2, 9.8, 9.4, 9.8, 0.8, 9.8, 0.5, 9.8, 9.7, 9.8, 9.8, 9.5, 9.7, 9.7, 0.5, 0.7, 0.5, 1.0, 9.6, 9.7, 9.8, 9.6, 9.8, 9.5, 0.4, 9.8, 0.9, 9.8, 0.4, 9.7, 9.8, 9.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 0.6, 0.4, 0.4, 9.7, 0.5, 9.8, 9.8, 0.6, 0.4, 0.5, 9.6, 9.7, 9.8, 9.7, 9.6, 0.4, 9.6, 9.6, 9.8, 9.8, 9.7, 9.7, 9.7, 0.5, 9.8, 9.8, 9.8, 9.8, 9.2, 9.7, 9.7, 9.6, 9.8, 9.5, 9.7, 9.8, 9.7, 9.8, 9.4, 9.7, 9.7, 0.9, 9.7, 9.8, 0.4, 0.6, 0.5, 0.6, 9.7, 9.7, 9.7, 9.6, 9.7, 9.7, 9.8, 9.8, 9.7, 9.8, 0.6, 0.6, 0.5, 9.8, 9.8, 0.4, 9.8, 9.7, 9.8, 0.6, 0.5, 9.8, 9.7, 0.6, 0.5, 9.7, 9.7, 9.7, 9.7, 9.8, 9.6, 9.8, 9.8, 3.6, 9.8, 0.6, 9.8, 9.7, 9.7, 0.4, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.6, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.6, 9.7, 9.8, 9.7, 9.5, 9.7, 9.8, 9.7, 9.7, 9.8, 0.5, 9.8, 9.7, 0.5, 9.7, 0.4, 9.7, 9.8, 9.7, 0.5, 9.7, 9.8, 9.6, 0.4, 9.8, 9.8, 9.8, 0.5, 9.7, 9.3, 9.8, 9.8, 9.8, 9.7, 0.5, 0.7, 9.8, 9.8, 9.7, 9.7, 9.7, 9.5, 9.6, 9.5, 9.7, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.6, 9.8, 9.7, 9.7, 9.8, 9.8, 9.7, 9.7, 9.6, 9.8, 9.8, 9.8, 0.4, 8.7, 9.7, 9.8, 9.7, 9.8, 9.6, 9.8, 9.8, 9.7, 9.7, 9.6, 1.4, 9.7, 0.6, 9.7, 9.8, 9.7, 9.7, 9.7, 0.6, 9.7, 9.8, 9.6, 9.7, 9.8, 9.5, 9.8, 9.7, 9.8, 9.6, 9.7, 0.5, 9.7, 9.8, 9.6, 9.7, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 0.5, 0.4, 9.7, 9.5, 9.8, 9.7, 9.8, 9.8, 9.6, 9.7, 1.1, 9.7, 9.8, 8.7, 8.1, 9.8, 9.8, 9.7, 9.7, 9.8, 0.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 0.5, 7.5, 9.8, 0.5, 9.6, 8.9, 9.8, 9.7, 9.5, 0.8, 9.8, 9.7, 9.8, 9.7, 9.8, 0.5, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 9.7, 8.6, 0.5, 9.8, 9.7, 0.5, 9.8, 9.8, 9.8, 9.7, 9.7, 0.6, 9.8, 0.6, 9.8, 0.5, 9.6, 9.8, 0.7, 9.8, 0.7, 9.8, 9.7, 9.8, 9.8, 0.6, 9.8, 9.8, 0.6, 0.5, 9.8, 9.8, 9.8, 0.6, 9.8, 9.8, 0.5, 0.6, 9.8, 9.8, 9.8, 0.4, 9.8, 9.7, 0.6, 9.7, 0.5, 9.8, 9.7, 9.7, 9.8, 9.7, 9.8, 0.7, 9.7, 1.2, 9.8, 0.5, 9.7, 0.6, 9.6, 9.7, 9.8, 9.7, 9.8, 0.4, 0.4, 9.6, 9.8, 9.8, 0.6, 9.7, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.7, 9.8, 9.8, 9.7, 9.6, 9.0, 9.8, 9.8, 8.9, 9.8, 0.6, 0.5, 9.7, 9.7, 9.7, 9.7, 9.6, 9.6, 9.8, 9.8, 9.8, 9.6, 0.4, 9.8, 9.8, 9.8, 9.6, 0.5, 1.6, 9.8, 0.8, 9.7, 0.4, 9.6, 9.8, 0.5, 9.7, 9.7, 9.8, 9.8, 9.8, 0.4, 9.7, 9.7, 9.7, 9.7, 9.7, 0.5, 0.4, 9.6, 9.8, 9.8, 9.7, 9.7, 9.7, 0.7, 9.7, 9.8, 9.7, 9.8, 0.5, 9.6, 9.6, 9.7, 9.7, 0.6, 0.7, 9.5, 9.8, 9.7, 9.8, 9.8, 9.8, 9.5, 9.8, 9.8, 9.8, 9.6, 9.8, 9.8, 9.8, 9.7, 9.7, 9.7, 9.8, 0.7, 9.7, 9.8, 9.6, 0.8, 0.5, 9.6, 9.8, 9.5, 9.8, 9.5, 9.8, 9.7, 9.7, 9.7, 9.6, 0.4, 9.7, 9.8, 9.7, 9.8, 9.7, 0.4, 0.5, 0.5, 9.8, 9.6, 9.7, 9.0, 9.6, 0.7, 9.8, 9.8, 9.8, 9.5, 9.6, 1.1, 9.8, 9.7]\n","ROC-AUC score: 1.0000\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 9 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9998\n","Average training loss: 0.0013\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[9.7, 9.8, 9.8, 9.8, 0.5, 9.7, 0.5, 9.8, 9.7, 9.8, 9.8, 9.8, 9.6, 9.7, 9.7, 9.8, 9.7, 9.6, 9.8, 9.7, 9.6, 9.8, 9.8, 9.8, 0.3, 9.3, 9.7, 9.8, 9.7, 9.8, 9.8, 0.5, 9.8, 0.4, 9.8, 9.8, 9.8, 9.6, 1.2, 9.8, 9.7, 0.4, 9.8, 9.8, 9.8, 9.7, 9.8, 0.6, 9.7, 9.8, 9.5, 9.8, 1.4, 9.8, 9.8, 0.4, 1.0, 9.8, 9.8, 9.7, 9.8, 9.8, 9.6, 9.8, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 0.4, 0.6, 9.7, 9.7, 9.7, 9.8, 0.4, 9.8, 9.8, 9.7, 9.7, 9.8, 9.8, 9.6, 9.8, 9.7, 0.3, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 0.5, 9.8, 0.4, 9.7, 9.8, 9.8, 9.6, 9.7, 9.8, 9.8, 9.8, 9.7, 9.3, 9.5, 9.8, 0.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.5, 0.4, 9.8, 9.8, 9.8, 9.8, 9.7, 0.6, 0.4, 9.7, 9.8, 9.8, 0.5, 9.7, 0.4, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 9.8, 0.6, 1.2, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.5, 9.8, 0.4, 9.7, 9.1, 9.8, 0.5, 9.7, 9.8, 9.8, 9.7, 9.7, 0.6, 9.7, 9.8, 0.7, 9.3, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.6, 9.7, 9.7, 9.8, 0.6, 9.8, 9.8, 9.7, 9.8, 0.6, 0.7, 9.8, 0.6, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 9.7, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 9.8, 9.6, 9.8, 9.8, 9.7, 0.6, 9.8, 0.4, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.7, 9.8, 9.6, 9.7, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 0.5, 9.8, 9.8, 0.4, 9.7, 9.7, 9.8, 0.5, 9.8, 0.4, 9.7, 9.5, 9.8, 0.4, 9.8, 9.6, 0.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.7, 9.8, 9.8, 9.7, 0.5, 0.4, 9.6, 9.8, 9.7, 9.7, 0.3, 0.6, 9.8, 9.8, 9.1, 9.8, 9.8, 9.8, 9.8, 0.6, 9.8, 9.6, 9.8, 0.4, 9.7, 9.7, 9.8, 9.8, 9.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 1.7, 9.8, 9.7, 9.8, 9.4, 9.8, 0.6, 9.8, 9.8, 9.8, 0.6, 9.7, 9.8, 9.8, 0.4, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 0.4, 9.8, 9.8, 9.8, 9.8, 9.8, 1.3, 9.8, 9.6, 9.7, 9.8, 9.8, 9.8, 0.6, 9.8, 9.7, 9.4, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 9.6, 9.8, 9.8, 0.6, 9.8, 9.8, 9.8, 0.4, 9.7, 0.6, 9.8, 0.5, 9.7, 0.6, 0.9, 9.3, 9.6, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.5, 0.4, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 0.4, 0.5, 9.8, 9.8, 9.8, 9.6, 0.4, 9.7, 8.1, 9.7, 9.8, 0.8, 0.5, 9.6, 9.8, 0.3, 9.8, 0.5, 9.7, 9.8, 0.4, 9.8, 0.3, 9.7, 9.7, 5.5, 9.7, 9.7, 9.8, 9.8, 9.8, 9.5, 9.7, 9.8, 9.8, 0.6, 9.7, 9.7, 0.6, 9.8, 9.8, 0.5, 9.8, 9.8, 9.8, 9.6, 9.7, 9.6, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.3, 9.7, 9.7, 9.8, 9.7, 0.5, 9.7, 9.7, 1.0, 9.7, 9.8, 9.8, 0.4, 0.5, 9.7, 9.7, 0.4, 9.8, 0.4, 9.7, 9.7, 9.8, 9.8, 0.4, 9.7, 0.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.6, 9.7, 9.8, 9.8, 9.7, 9.7, 9.3, 9.8, 9.8, 0.5, 0.7, 9.8, 0.4, 9.8, 0.3, 9.7, 9.8, 1.0, 9.7, 9.8, 0.5, 9.7, 9.8, 9.8, 9.8, 9.8, 0.3, 9.7, 9.8, 9.8, 9.7, 9.8, 0.4, 9.8, 9.5, 9.8, 9.6, 9.7, 9.8, 9.7, 9.7, 9.7, 9.7, 0.6, 0.3, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 0.4, 1.1, 0.9, 9.8, 9.7, 9.8, 0.5, 0.4, 0.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.3, 0.5, 9.8, 9.8, 0.4, 9.6, 9.8, 9.8, 9.7, 9.6, 9.8, 9.8, 0.5, 9.8, 9.8, 9.4, 9.8, 9.8, 0.4, 9.7, 4.8, 3.9, 0.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 9.8, 0.5, 9.7, 9.8, 9.8, 9.7, 0.4, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.5, 9.8, 9.7, 9.6, 9.7, 9.4, 9.8, 0.5, 9.8, 9.8, 0.7, 9.8, 9.8, 9.8, 9.1, 9.7, 9.7, 9.5, 0.4, 0.5, 9.7, 9.8, 9.8, 9.8, 9.7, 9.7, 9.7, 0.9, 0.8, 9.8, 9.8, 9.7, 0.6, 9.7, 9.8, 9.8, 9.6, 9.7, 9.7, 9.8, 9.8, 9.7, 9.7, 9.8, 9.7, 9.6, 9.8, 9.8, 0.9, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.4, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 0.4, 9.8, 9.5, 9.8, 9.7, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.3, 0.4, 9.8, 8.8, 9.8, 0.4, 9.7, 9.7, 0.5, 9.8, 0.4, 9.5, 0.4, 9.8, 9.7, 9.8, 9.8, 0.6, 9.7, 9.8, 9.8, 9.8, 9.8, 9.6, 9.8, 4.1, 9.7, 9.7, 9.8, 9.8, 0.7, 9.8, 0.4, 0.5, 9.8, 9.7, 0.6, 9.7, 9.8, 9.8, 0.7, 9.5, 8.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 0.3, 0.5, 9.8, 9.5, 9.8, 9.5, 9.8, 9.8, 0.5, 9.7, 0.5, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 0.6, 0.4, 9.7, 9.0, 9.8, 3.8, 9.7, 0.5, 0.4, 2.2, 0.8, 9.8, 9.8, 9.8, 9.7, 9.7, 0.6, 9.8, 9.8, 0.8, 9.8, 9.7, 9.8, 9.8, 9.5, 9.8, 9.7, 9.8, 9.8, 9.6, 9.7, 9.8, 9.7, 9.8, 9.7, 9.8, 9.7, 9.7, 9.8, 9.7, 9.8, 9.8, 0.4, 9.8, 9.8, 0.4, 0.8, 0.9, 9.7, 9.8, 9.6, 9.8, 9.8, 9.6, 9.7, 9.8, 9.4, 0.3, 9.7, 9.8, 9.8, 9.6, 9.8, 9.7, 0.8, 9.8, 9.8, 9.7, 0.4, 9.7, 9.6, 9.7, 9.8, 0.5, 9.8, 9.6, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 0.5, 9.8, 9.8, 0.4, 9.8, 9.7, 9.8, 0.4, 9.8, 0.6, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.7, 9.7, 9.7, 9.8, 9.8, 9.8, 0.5, 9.7, 9.8, 1.1, 8.1, 9.7, 9.7, 0.8, 9.8, 9.4, 9.8, 9.8, 9.8, 9.4, 0.4, 0.4, 9.8, 9.7, 9.6, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.7, 9.8, 9.8, 9.8, 0.7, 9.8, 0.4, 9.7, 9.8, 9.8, 9.8, 9.7, 0.6, 9.6, 0.5, 9.6, 9.8, 9.8, 9.8, 9.8, 9.4, 9.8, 9.8, 9.8, 0.6, 0.5, 9.8]\n","ROC-AUC score: 0.9998\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["======== Partition 10 / 10 ========\n","Training...\n"]},{"name":"stderr","output_type":"stream","text":["Training:: 100%|██████████| 256/256 [03:09<00:00,  1.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["ROC-AUC Score: 0.9999\n","Average training loss: 0.0014\n","#\n","Running Validation...\n"]},{"name":"stderr","output_type":"stream","text":["Validating:: 100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(907,)\n","[9.8, 9.8, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.2, 0.4, 0.4, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.9, 9.8, 9.6, 9.8, 0.3, 9.8, 0.4, 9.8, 9.8, 9.8, 9.6, 9.8, 9.3, 0.4, 9.8, 9.7, 9.5, 0.5, 9.7, 9.8, 0.4, 0.4, 9.8, 9.4, 9.8, 9.6, 0.5, 9.8, 9.7, 9.8, 0.3, 0.4, 9.8, 9.8, 9.8, 9.8, 0.6, 9.7, 9.7, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 0.6, 9.8, 0.4, 9.8, 0.4, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 0.4, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.7, 0.6, 0.4, 9.8, 0.6, 9.8, 0.4, 9.8, 0.4, 9.8, 9.8, 0.7, 0.5, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.6, 9.6, 9.8, 9.7, 0.3, 0.5, 9.8, 0.3, 9.7, 9.7, 9.6, 0.6, 9.8, 9.8, 0.5, 9.8, 9.8, 9.8, 9.8, 9.8, 9.6, 9.8, 0.9, 9.8, 9.8, 9.8, 9.6, 9.8, 0.4, 0.5, 9.7, 9.7, 9.7, 0.3, 0.7, 9.8, 9.8, 9.8, 9.5, 9.8, 9.8, 9.8, 0.4, 9.8, 0.4, 0.4, 9.8, 9.8, 0.5, 9.7, 9.8, 9.8, 0.7, 0.5, 9.8, 9.1, 9.8, 9.7, 9.7, 9.7, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 9.7, 9.7, 0.3, 9.8, 9.8, 9.8, 9.8, 9.7, 9.7, 9.8, 0.5, 9.8, 9.8, 0.4, 9.8, 9.8, 0.5, 0.3, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 7.9, 0.4, 9.8, 9.8, 0.3, 9.8, 9.8, 9.7, 9.8, 0.7, 9.8, 9.8, 9.7, 9.8, 0.6, 9.8, 9.8, 9.8, 9.8, 9.8, 0.5, 0.6, 9.8, 0.5, 9.8, 0.5, 9.8, 9.8, 9.8, 9.7, 9.7, 9.6, 8.5, 9.8, 0.3, 9.8, 9.8, 9.8, 9.1, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.6, 9.4, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 9.4, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.4, 0.8, 9.7, 0.7, 9.8, 9.8, 9.8, 0.7, 9.8, 9.8, 9.8, 9.8, 9.4, 0.9, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 0.4, 0.3, 0.5, 9.3, 9.8, 9.6, 9.8, 9.8, 9.7, 0.6, 9.8, 9.8, 9.8, 0.3, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 0.5, 9.8, 0.4, 9.8, 9.8, 0.3, 0.6, 9.8, 9.7, 9.7, 9.3, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 0.3, 9.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.6, 9.8, 9.8, 0.3, 0.5, 9.8, 9.8, 9.7, 9.8, 9.7, 0.5, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 5.0, 0.4, 0.6, 9.8, 0.5, 9.8, 0.4, 0.7, 0.6, 9.7, 9.7, 9.8, 9.8, 0.4, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 0.6, 9.8, 0.4, 9.8, 0.4, 9.8, 9.6, 0.4, 9.7, 9.8, 9.8, 9.8, 9.8, 8.9, 9.8, 9.8, 9.8, 9.8, 9.6, 9.8, 9.6, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.7, 9.8, 9.8, 9.7, 9.8, 9.7, 0.4, 9.6, 9.8, 0.6, 1.2, 9.1, 9.8, 9.8, 9.8, 9.6, 9.8, 9.8, 9.7, 9.8, 0.4, 9.6, 9.8, 9.8, 9.7, 9.8, 9.8, 9.7, 9.7, 9.7, 0.4, 9.8, 0.4, 9.8, 9.8, 0.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.7, 0.4, 0.3, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 0.6, 9.8, 9.8, 0.5, 9.8, 0.4, 9.8, 9.8, 9.8, 9.8, 9.8, 0.3, 9.8, 9.8, 9.8, 0.6, 9.8, 9.8, 9.8, 0.3, 9.3, 9.8, 9.8, 9.8, 9.8, 0.3, 9.8, 9.8, 9.8, 9.6, 9.8, 0.5, 9.8, 0.5, 9.8, 9.8, 9.7, 9.7, 9.8, 9.7, 9.7, 9.6, 0.3, 9.8, 9.8, 1.0, 9.8, 9.8, 9.8, 0.5, 9.7, 0.3, 9.8, 9.8, 9.6, 9.6, 9.8, 9.7, 9.8, 7.6, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.4, 9.8, 9.8, 9.8, 9.5, 9.8, 0.6, 9.7, 0.8, 0.3, 9.6, 9.8, 9.8, 9.8, 0.8, 0.6, 0.3, 0.5, 0.7, 9.8, 9.7, 9.8, 9.8, 9.7, 9.8, 0.7, 0.5, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 0.6, 0.4, 9.4, 0.3, 9.7, 0.3, 9.8, 9.8, 9.1, 9.8, 9.8, 9.7, 9.8, 9.4, 9.8, 1.2, 9.8, 9.8, 9.8, 0.5, 9.7, 9.8, 0.3, 0.7, 9.8, 9.8, 0.4, 9.8, 9.8, 9.8, 0.3, 9.7, 7.1, 9.5, 9.8, 9.8, 9.8, 0.3, 9.8, 0.4, 9.8, 0.5, 9.3, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 0.3, 0.3, 0.3, 9.8, 8.4, 0.7, 9.8, 9.8, 9.6, 9.7, 9.8, 9.6, 0.6, 9.8, 9.8, 9.8, 1.0, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.6, 9.8, 9.7, 9.7, 9.6, 9.8, 9.7, 9.2, 1.1, 9.8, 9.7, 0.6, 9.8, 9.8, 9.7, 9.8, 0.4, 9.8, 0.4, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 0.4, 9.8, 0.5, 9.8, 9.8, 9.8, 9.6, 9.8, 9.8, 9.8, 0.4, 9.8, 9.1, 9.6, 9.8, 0.5, 0.4, 9.7, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 0.4, 9.8, 0.3, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 0.6, 9.7, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 0.6, 0.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 0.6, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.6, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 9.8, 9.8, 9.6, 9.6, 0.5, 9.8, 9.8, 9.8, 9.8, 0.5, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.6, 0.5, 9.6, 0.4, 9.8, 9.8, 9.8, 9.7, 9.0, 9.8, 9.7, 9.7, 0.4, 9.8, 9.5, 9.8, 9.7, 9.8, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 9.8, 9.6, 0.5, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 0.4, 9.8, 0.3, 9.8, 0.7, 9.8, 0.4, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 9.8, 0.4, 9.8, 9.8, 9.8, 9.8, 9.8, 9.3, 0.4, 9.6, 9.8, 9.7, 8.2, 0.3, 9.8, 0.5, 0.3, 0.3, 0.3, 9.8, 9.8, 9.8, 9.7, 9.8, 9.7, 9.7, 9.8, 9.7, 9.7, 9.8, 9.8, 9.8, 9.7, 9.8, 9.8, 0.4, 9.7, 0.4, 9.8, 9.8, 9.8]\n","ROC-AUC score: 1.0000\n","#\n","Running Test...\n"]},{"name":"stderr","output_type":"stream","text":["Testing...: 100%|██████████| 160/160 [00:39<00:00,  4.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Training complete!\n"]}],"source":["device = 'cuda'\n","epochs = 10\n","BERT_SA.to(device)\n","print('Done')\n","param_optimizer = list(BERT_SA.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\n","\n","\n","for epoch_i, (tid, vid) in enumerate(kf.split(full_dataset)):\n","    print('======== Partition {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    total_loss = 0\n","    BERT_SA.train()\n","    train_logits, train_lbls = 0, 0\n","    nb_train_steps = 0\n","    train_f1 = 0\n","    train_dataloader, val_dataloader = build_loader(full_dataset, tid, vid)\n","    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Training:\"):\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2]\n","        b_labels = b_labels.to(device)\n","\n","        BERT_SA.zero_grad()\n","        outputs = BERT_SA(b_input_ids, \n","            token_type_ids=None, \n","            attention_mask=b_input_mask, \n","            labels=b_labels)\n","\n","        loss = sigmoid_focal_loss(outputs[1].squeeze(1), b_labels.float())\n","        total_loss += loss.item()\n","        \n","        logits = outputs[1].detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        # tmp_train_roc_auc_score = flat_roc_auc_score(label_ids, logits)\n","        if step == 0:\n","            train_logits = logits.flatten()\n","            train_lbls = label_ids.flatten()\n","        else:\n","            train_logits = np.concatenate([train_logits, logits.flatten()])\n","            train_lbls = np.concatenate([train_lbls, label_ids.flatten()])\n","        nb_train_steps += 1\n","        \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(BERT_SA.parameters(), 1.0)\n","        optimizer.step()\n","        \n","    avg_train_loss = total_loss / len(train_dataloader)\n","    print(\"ROC-AUC Score: {0:.4f}\".format(roc_auc_score(train_lbls, train_logits, average='macro')))\n","    print(\"Average training loss: {0:.4f}\".format(avg_train_loss))\n","    print(\"#\")\n","    print(\"Running Validation...\")\n","    BERT_SA.eval()\n","    eval_loss, eval_logits, eval_lbls = 0, 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=\"Validating:\"):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        with torch.no_grad():\n","            outputs = BERT_SA(b_input_ids, \n","            token_type_ids=None, \n","            attention_mask=b_input_mask)\n","            logits = outputs[0]\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","\n","            if step == 0:\n","                eval_logits = logits.flatten()\n","                eval_lbls = label_ids.flatten()\n","            else:\n","                eval_logits = np.concatenate([eval_logits, logits.flatten()])\n","                eval_lbls = np.concatenate([eval_lbls, label_ids.flatten()])\n","            nb_eval_steps += 1\n","    print(eval_logits.shape)\n","    print([round(float(rate) * 10, 1) for rate in np_sigmoid(eval_logits)])\n","    print(\"ROC-AUC score: {0:.4f}\".format(roc_auc_score(eval_lbls, eval_logits, average='macro')))\n","    print(\"#\")\n","    print(\"Running Test...\")\n","    test_revid, test_logits = 0, 0\n","    BERT_SA.eval()\n","    for step, batch in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing...\"):\n","        b_revids = batch[0]\n","        b_input_ids = batch[1].to(device)\n","        b_input_mask = batch[2].to(device)\n","       \n","        with torch.no_grad():\n","            outputs = BERT_SA(b_input_ids, \n","            token_type_ids=None, \n","            attention_mask=b_input_mask)\n","            logits = outputs[0]\n","            logits = logits.detach().cpu().numpy()\n","            if step == 0:\n","                test_logits = logits.flatten()\n","                test_revids = b_revids.flatten()\n","            else:\n","                test_logits = np.concatenate([test_logits, logits.flatten()])\n","                test_revids = np.concatenate([test_revids, b_revids.flatten()])\n","        results = {\n","            \"RevId\": [int(id) for id in test_revids],\n","            \"Rating\": [round(float(rate)*10, 1) for rate in np_sigmoid(test_logits)]\n","        }\n","        df = pd.DataFrame(results)\n","        df.to_csv(f\"/kaggle/working/submit_{epoch_i}.csv\")\n","    save_model(BERT_SA, optimizer, f\"/kaggle/working/state_dict_{epoch_i}.pth\")\n","print(\"Training complete!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-12T12:56:21.225760Z","iopub.status.idle":"2022-12-12T12:56:21.226977Z","shell.execute_reply":"2022-12-12T12:56:21.226701Z","shell.execute_reply.started":"2022-12-12T12:56:21.226667Z"},"id":"o1XQSMKJDop5","outputId":"6306209e-0952-42e4-b9a9-96d7d2c7b3cc","trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2022-12-12T12:56:21.228957Z","iopub.status.idle":"2022-12-12T12:56:21.229525Z","shell.execute_reply":"2022-12-12T12:56:21.229241Z","shell.execute_reply.started":"2022-12-12T12:56:21.229214Z"},"id":"EOX8uiYTDpnz","outputId":"ddb2d7fd-1cf9-4db9-d6ed-24c496ae680b","trusted":true},"outputs":[],"source":["!pip install numba"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-12-12T12:56:21.231691Z","iopub.status.idle":"2022-12-12T12:56:21.232244Z","shell.execute_reply":"2022-12-12T12:56:21.231977Z","shell.execute_reply.started":"2022-12-12T12:56:21.231949Z"},"id":"VEqJPtCCDsUc","trusted":true},"outputs":[],"source":["from numba import cuda\n","\n","device = cuda.get_current_device() \n","device.reset()\n","cuda.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"3528abe4b7d5d7367bced2ad483373fde28fb1b6e6471f1cde7e019cf2e88391"}}},"nbformat":4,"nbformat_minor":4}
