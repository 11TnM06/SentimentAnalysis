{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nos.chdir('/kaggle/')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T19:11:48.878536Z","iopub.execute_input":"2022-12-11T19:11:48.879122Z","iopub.status.idle":"2022-12-11T19:11:48.929176Z","shell.execute_reply.started":"2022-12-11T19:11:48.879018Z","shell.execute_reply":"2022-12-11T19:11:48.928351Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir -p vncorenlp/models/wordsegmenter\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n!mv vi-vocab vncorenlp/models/wordsegmenter/\n!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:11:48.931195Z","iopub.execute_input":"2022-12-11T19:11:48.931611Z","iopub.status.idle":"2022-12-11T19:11:58.447452Z","shell.execute_reply.started":"2022-12-11T19:11:48.931576Z","shell.execute_reply":"2022-12-11T19:11:58.446064Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2022-12-11 19:11:51--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 27412575 (26M) [application/octet-stream]\nSaving to: ‘VnCoreNLP-1.1.1.jar’\n\nVnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   147MB/s    in 0.2s    \n\n2022-12-11 19:11:52 (147 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n\n--2022-12-11 19:11:53--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 526544 (514K) [application/octet-stream]\nSaving to: ‘vi-vocab’\n\nvi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.05s   \n\n2022-12-11 19:11:53 (11.1 MB/s) - ‘vi-vocab’ saved [526544/526544]\n\n--2022-12-11 19:11:54--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 128508 (125K) [text/plain]\nSaving to: ‘wordsegmenter.rdr’\n\nwordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.02s   \n\n2022-12-11 19:11:55 (5.48 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n!tar -xzvf PhoBERT_base_transformers.tar.gz\n!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n!tar -xzvf PhoBERT_base_fairseq.tar.gz","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:11:58.449615Z","iopub.execute_input":"2022-12-11T19:11:58.450001Z","iopub.status.idle":"2022-12-11T19:12:42.918750Z","shell.execute_reply.started":"2022-12-11T19:11:58.449959Z","shell.execute_reply":"2022-12-11T19:12:42.917497Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-12-11 19:11:59--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\nResolving public.vinai.io (public.vinai.io)... 54.230.31.74, 54.230.31.76, 54.230.31.104, ...\nConnecting to public.vinai.io (public.vinai.io)|54.230.31.74|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 322405979 (307M) [application/x-tar]\nSaving to: ‘PhoBERT_base_transformers.tar.gz’\n\nPhoBERT_base_transf 100%[===================>] 307.47M  82.5MB/s    in 3.8s    \n\n2022-12-11 19:12:03 (81.1 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n\nPhoBERT_base_transformers/\nPhoBERT_base_transformers/config.json\nPhoBERT_base_transformers/bpe.codes\nPhoBERT_base_transformers/model.bin\nPhoBERT_base_transformers/dict.txt\n--2022-12-11 19:12:12--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\nResolving public.vinai.io (public.vinai.io)... 54.230.31.104, 54.230.31.76, 54.230.31.108, ...\nConnecting to public.vinai.io (public.vinai.io)|54.230.31.104|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1243308020 (1.2G) [application/x-tar]\nSaving to: ‘PhoBERT_base_fairseq.tar.gz’\n\nPhoBERT_base_fairse 100%[===================>]   1.16G  86.9MB/s    in 14s     \n\n2022-12-11 19:12:26 (82.5 MB/s) - ‘PhoBERT_base_fairseq.tar.gz’ saved [1243308020/1243308020]\n\nPhoBERT_base_fairseq/\nPhoBERT_base_fairseq/bpe.codes\nPhoBERT_base_fairseq/model.pt\nPhoBERT_base_fairseq/dict.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install fastBPE\n!pip install fairseq\n!pip install vncorenlp","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:12:42.921980Z","iopub.execute_input":"2022-12-11T19:12:42.923477Z","iopub.status.idle":"2022-12-11T19:13:45.209694Z","shell.execute_reply.started":"2022-12-11T19:12:42.923436Z","shell.execute_reply":"2022-12-11T19:13:45.208480Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fastBPE\n  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fastBPE\n  Building wheel for fastBPE (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=746401 sha256=b135d4dba60dd6799f3c3254925157981c638165293042f541d2a79c58964823\n  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\nSuccessfully built fastBPE\nInstalling collected packages: fastBPE\nSuccessfully installed fastBPE-0.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fairseq\n  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting bitarray\n  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.11.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from fairseq) (2021.11.10)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.21.6)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.15.0)\nCollecting hydra-core<1.1,>=1.0.7\n  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting omegaconf<2.1\n  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nCollecting sacrebleu>=1.4.12\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fairseq) (4.64.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.29.32)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.11.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.8.0)\nCollecting antlr4-python3-runtime==4.8\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (4.1.1)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.5)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->fairseq) (2.21)\nRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.8.0)\nBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=31a9581bc1af7f410a37bb61a7e90c2439149d9996996c90360f5ac2cca7ef22\n  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: bitarray, antlr4-python3-runtime, sacrebleu, omegaconf, hydra-core, fairseq\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 sacrebleu-2.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting vncorenlp\n  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vncorenlp) (2.28.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (3.3)\nBuilding wheels for collected packages: vncorenlp\n  Building wheel for vncorenlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=194f2a4e05fd30427037ac3c4c13243fc4817ad7c80feaca20baf5a88332d000\n  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\nSuccessfully built vncorenlp\nInstalling collected packages: vncorenlp\nSuccessfully installed vncorenlp-1.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def chunk_text(encoded_text, max_len, max_chunk):\n  res = []\n  if len(encoded_text) > max_chunk*max_len:\n    encoded_text = encoded_text[:max_len*max_chunk] \n  for i in range(0, len(encoded_text), max_len):\n    res.append(encoded_text[i:i+max_len])\n  k = len(res)\n  for i in range(max_chunk-k):\n    res.append(torch.zeros(1).long().tolist())\n  if len(res) != max_chunk:\n    print('value of k:', k)\n    print('len(res) in chunk_text:', len(res))\n    print('len(encoded_text', len(encoded_text))\n  assert len(res) == max_chunk\n  return res\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:13:45.211592Z","iopub.execute_input":"2022-12-11T19:13:45.212366Z","iopub.status.idle":"2022-12-11T19:13:45.220950Z","shell.execute_reply.started":"2022-12-11T19:13:45.212324Z","shell.execute_reply":"2022-12-11T19:13:45.219874Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from vncorenlp import VnCoreNLP\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom fairseq.data.encoders.fastbpe import fastBPE\nfrom fairseq.data import Dictionary\nfrom torchvision import  transforms\nimport json\nimport random\nimport argparse\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport cv2\n\nMAX_LEN = 256\nMAX_CHUNKS = 8\n\nclass FoodyDataset(Dataset):\n  def __init__(self, data_dir, path, test=False):\n    self.data_dir = data_dir\n    self.path = path\n    self.test = test\n    if not test:\n      self.data_list = self._load_json()\n    else:\n      self.data_list = self._load_csv()\n    self.rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m') \n    parser = argparse.ArgumentParser()\n    parser.add_argument('--bpe-codes', \n                        default=\"./PhoBERT_base_transformers/bpe.codes\",\n                        required=False,\n                        type=str,\n                        help='path to fastBPE BPE')\n    args, unknown = parser.parse_known_args()\n    self.bpe = fastBPE(args)\n    self.vocab = Dictionary()\n    self.vocab.add_from_file(\"./PhoBERT_base_transformers/dict.txt\")\n\n    self.transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n                                                                                                                                                                \n  def __len__(self):\n    return len(self.data_list)\n\n  def __getitem__(self, idx):\n    s = self.data_list[idx]\n    \n    revid = s['RevId']\n    text = str(s['Comment'])\n    text = self.rdrsegmenter.tokenize(text)\n    text = ' '.join([' '.join(x) for x in text])\n    subwords = '<s> ' + self.bpe.encode(text) + ' </s>'\n    encoded_text = self.vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n    encoded_text = chunk_text(encoded_text, MAX_LEN, MAX_CHUNKS)\n    chunked_tokens = pad_sequences(encoded_text, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n    masks = [[int(token_id > 0) for token_id in sentence] for sentence in chunked_tokens]\n    if not self.test:\n      img_path = os.path.join(self.data_dir, 'image', str(revid))\n    else:\n      img_path = os.path.join(self.data_dir, 'image_test', str(revid))\n\n    img_path = os.path.join(img_path, '0.jpg')\n    img = self._load_image(img_path)\n    if not self.test:\n      label = int(s['Rating'] >= 6.0)\n      return torch.tensor(chunked_tokens).long(), torch.tensor(masks).long(), img, torch.tensor(label).long()\n    return revid, torch.tensor(chunked_tokens).long(), torch.tensor(masks).long(), img\n\n  def _load_json(self):\n    with open(self.path, 'r') as f:\n      dataset = json.load(f)\n    return dataset\n\n  def _load_csv(self):\n    df = pd.read_csv(self.path)\n    dataset = []\n    for _, row in df[['RevId', 'Comment']].iterrows():\n      dataset.append({'RevId': row['RevId'], \n                      'Comment': row['Comment']})\n    return dataset\n  \n  def _load_image(self, path):\n    img = cv2.imread(path)\n    if img is None:\n      print(path)\n      img = np.zeros((1000,1000,3))\n    img = Image.fromarray(img.astype('uint8'), 'RGB')\n\n    img_tensor = self.transform(img)\n    return img_tensor\n\ndef build_dataloader(dataset,\n                      train_ids=None,\n                      val_ids=None,\n                      batch_size=4,\n                      num_workers=1,\n                      device='cuda',\n                      test=False,\n                    ):\n  if not test:\n    train_set = Subset(dataset, list(train_ids))\n    val_set = Subset(dataset, list(val_ids))\n\n    train_loader = DataLoader(train_set, \n                              batch_size=batch_size,\n                              num_workers=num_workers,\n                              shuffle=True)\n    val_loader = DataLoader(val_set, \n                            batch_size=batch_size,\n                            num_workers=num_workers,\n                            shuffle=False)\n    dataloader = (train_loader, val_loader)\n  else:\n    dataloader = DataLoader(dataset, \n                            batch_size=batch_size,\n                            num_workers=num_workers,\n                            shuffle=False)\n  return dataloader\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:13:45.222773Z","iopub.execute_input":"2022-12-11T19:13:45.223127Z","iopub.status.idle":"2022-12-11T19:14:01.249575Z","shell.execute_reply.started":"2022-12-11T19:13:45.223092Z","shell.execute_reply":"2022-12-11T19:14:01.248548Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n\nclass FoodyPhoBERTEncoder(nn.Module):\n  def __init__(self, out_features=1):\n    super(FoodyPhoBERTEncoder, self).__init__()\n    self.out_features = out_features\n    self.bert_config = RobertaConfig.from_pretrained(\"./PhoBERT_base_transformers/config.json\", \n                                                      from_tf=False, \n                                                      num_labels = out_features, \n                                                     output_hidden_states=False)\n    self.bert = RobertaForSequenceClassification.from_pretrained(\"./PhoBERT_base_transformers/model.bin\", \n                                                                 config=self.bert_config)\n    self.lstm = nn.LSTM(MAX_CHUNKS*out_features, out_features, batch_first=True)\n  def forward(self, tokens, mask, labels, train=True):\n    x = 0\n    for i in range(MAX_CHUNKS):\n      out = self.bert(\n          tokens[:,i,:].squeeze().long(),\n          token_type_ids=None,\n          attention_mask=mask[:,i,:].squeeze().long()\n      )\n      if i==0:\n        x = out[0]\n      else:\n        x = torch.cat((x, out[0]), dim=-1)\n    x = x.unsqueeze(1)\n    x, _ = self.lstm(x)\n    x = x.squeeze()\n    return x\n\nclass FoodyConvEncoder(nn.Module):\n  def __init__(self, out_features=1, img_model='resnet', dropout=0.1):\n    super(FoodyConvEncoder, self).__init__()\n    self.out_features = out_features\n    self.img_model = img_model\n    self.dropout = dropout\n    if img_model == 'resnet':\n      self.convnet = models.resnet18(pretrained=True)\n      n_fts = self.convnet.fc.in_features\n      self.convnet.fc = nn.Linear(n_fts, out_features)\n    elif img_model == 'vgg':\n      self.convnet = models.vgg11(pretrained=True)\n      self.convnet.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(p=dropout),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(p=dropout),\n            nn.Linear(4096, out_features),\n        )\n  def forward(self, x):\n    x = self.convnet(x)\n    return x\n\nclass FoodyJointModel(nn.Module):\n  def __init__(self, out_features=1, img_model='vgg', dropout=0.1, coef=0.2):\n    super(FoodyJointModel, self).__init__()\n    self.out_features = out_features\n    self.coef = coef\n    self.img_model = img_model\n    self.dropout = dropout\n    \n    self.bert_encode = FoodyPhoBERTEncoder(out_features)\n    self.conv_encode = FoodyConvEncoder(out_features=out_features, img_model=img_model, dropout=0.1)\n    self.linear = nn.Linear(out_features, 1)\n    \n\n  def forward(self, x_img, x_tokens, mask, labels=None, train=True):\n    out_bert = self.bert_encode(x_tokens, mask, labels, train)\n    out_conv = self.conv_encode(x_img)\n    out = self.coef * out_conv + (1 - self.coef) * out_bert\n    out = self.linear(out)\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:14:01.251252Z","iopub.execute_input":"2022-12-11T19:14:01.251999Z","iopub.status.idle":"2022-12-11T19:14:02.271305Z","shell.execute_reply.started":"2022-12-11T19:14:01.251963Z","shell.execute_reply":"2022-12-11T19:14:02.270383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef sigmoid_focal_loss(\n    inputs: torch.Tensor,\n    targets: torch.Tensor,\n    alpha: float = 0.25,\n    gamma: float = 2,\n    reduction: str = \"mean\",\n):\n    p = torch.sigmoid(inputs)\n    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n    p_t = p * targets + (1 - p) * (1 - targets)\n    loss = ce_loss * ((1 - p_t) ** gamma)\n\n    if alpha >= 0:\n        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n        loss = alpha_t * loss\n\n    if reduction == \"mean\":\n        loss = loss.mean()\n    elif reduction == \"sum\":\n        loss = loss.sum()\n\n    return loss\n\ndef np_sigmoid(x):\n  return 1/(1 + np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:14:02.272754Z","iopub.execute_input":"2022-12-11T19:14:02.273230Z","iopub.status.idle":"2022-12-11T19:14:02.281453Z","shell.execute_reply.started":"2022-12-11T19:14:02.273192Z","shell.execute_reply":"2022-12-11T19:14:02.280403Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train and Test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm, tqdm_notebook\nimport pandas as pd \nimport numpy as np\n\n\n# config\n\ndevice = 'cuda'\nbatch_size = 4\nout_features = 8\nimg_model='vgg'\ndropout=0.1\ncoef=0.2\nepochs = 10\nstate_dict_max = 0\n\nmodel = FoodyJointModel(out_features, \n                        img_model, \n                        dropout,\n                        coef)\nmodel.to(device)\n\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n]\n\noptimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\n\nkf = KFold(n_splits=10, shuffle=True)\nfull_dataset = FoodyDataset('./input/foodyvnu/Data','./input/foodyvnu/Data/train.json')\nprint(len(full_dataset))\ntest_dataset = FoodyDataset('./input/foodyvnu/Data', './input/foodyvnu/Data/test.csv', test=True)\ntest_dataloader = build_dataloader(test_dataset,\n                                    batch_size=batch_size,\n                                    num_workers=1,\n                                    device=device,\n                                    test=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:14:02.282946Z","iopub.execute_input":"2022-12-11T19:14:02.284463Z","iopub.status.idle":"2022-12-11T19:15:14.346243Z","shell.execute_reply.started":"2022-12-11T19:14:02.284424Z","shell.execute_reply":"2022-12-11T19:15:14.343844Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\nSome weights of the model checkpoint at ./PhoBERT_base_transformers/model.bin were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./PhoBERT_base_transformers/model.bin and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nDownloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /root/.cache/torch/hub/checkpoints/vgg11-8a719046.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/507M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972dc3deefc541869c3c83815df437d3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\nLoading codes from ./PhoBERT_base_transformers/bpe.codes ...\nRead 64000 codes from the codes file.\n","output_type":"stream"},{"name":"stdout","text":"9071\n","output_type":"stream"},{"name":"stderr","text":"Loading codes from ./PhoBERT_base_transformers/bpe.codes ...\nRead 64000 codes from the codes file.\n","output_type":"stream"}]},{"cell_type":"code","source":"def save_model(model, optimizer, path):\n    state_dict = {\n        \"optimizer\": optimizer.state_dict(),\n        \"model\": model.state_dict()\n    }\n    torch.save(state_dict, path)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:15:14.350265Z","iopub.execute_input":"2022-12-11T19:15:14.350591Z","iopub.status.idle":"2022-12-11T19:15:14.358234Z","shell.execute_reply.started":"2022-12-11T19:15:14.350561Z","shell.execute_reply":"2022-12-11T19:15:14.354998Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for epoch_i, (tid, vid) in enumerate(kf.split(full_dataset)):\n  print('======== Partition {:} / {:} ========'.format(epoch_i + 1, epochs))\n  train_dataloader, val_dataloader = build_dataloader(full_dataset,\n                                                      train_ids=tid,\n                                                      val_ids=vid,\n                                                      batch_size=batch_size,\n                                                      num_workers=1,\n                                                      device=device,\n                                                      test=False)\n  print(len(train_dataloader))\n  print(len(val_dataloader))\n  print('Training...')\n  \n  total_loss = 0\n  train_logits, train_labels = 0, 0\n  print(model.img_model)\n  model.train()\n\n  for step, batch in tqdm_notebook(enumerate(train_dataloader), total=len(train_dataloader), desc='Training'):\n    batch = tuple(b.to(device).float() for b in batch)\n    tokens, masks, img, labels = batch\n    \n    model.zero_grad()\n    outputs = model(\n        img,\n        tokens,\n        masks,\n        labels,\n        train=True\n    )    \n\n    loss = sigmoid_focal_loss(outputs.squeeze(), labels)\n    total_loss += loss.item()\n\n    logits = outputs.detach().cpu().numpy()\n    labels = labels.to('cpu').numpy()\n    if step == 0:\n      train_logits = logits.flatten()\n      train_labels = labels.flatten()\n    else:\n      train_logits = np.concatenate([train_logits, logits.flatten()])\n      train_labels = np.concatenate([train_labels, labels.flatten()])\n    \n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    optimizer.step()\n\n  avg_train_loss = total_loss / len(train_dataloader)\n  print(\" ROC-AUC Socre: {0:.4f}\".format(roc_auc_score(train_labels, train_labels, average='macro')))\n  print(\" Average training loss: {0:.4f}\".format(avg_train_loss))\n\n  print('Running validation ...')\n  model.eval()\n  eval_logits, eval_labels = 0, 0\n\n  for step, batch in tqdm_notebook(enumerate(val_dataloader), total=len(val_dataloader), desc='Validation'):\n\n      batch = tuple(t.to(device) for t in batch)\n\n      tokens, masks, img, labels = batch\n\n      with torch.no_grad():\n          outputs = model(\n              img,\n              tokens,\n              masks,\n              labels,\n              train=False\n          )\n          logits = outputs.detach().cpu().numpy()\n          labels = labels.to('cpu').numpy()\n\n          if step == 0:\n            eval_logits = logits.flatten()\n            eval_labels = labels.flatten()\n          else:\n            eval_logits = np.concatenate([eval_logits, logits.flatten()])\n            eval_labels = np.concatenate([eval_labels, labels.flatten()])\n  print([round(float(rate)*10, 1) for rate in np_sigmoid(eval_logits)])\n  print(\" ROC-AUC score: {0:.4f}\".format(roc_auc_score(eval_labels, np_sigmoid(eval_logits), average='macro')))\n\n  print(\"Running test....\")\n  model.eval()\n  test_rid, test_logits = 0, 0\n  for step, batch in tqdm_notebook(enumerate(test_dataloader), total=len(test_dataloader), desc=\"Testing: \"):\n      batch = tuple(t.to(device) for t in batch)\n\n      revids, tokens, masks, img = batch\n\n      with torch.no_grad():\n          outputs = model(\n              img,\n              tokens,\n              masks,\n              train=False\n          )    \n          logits = outputs.detach().cpu().numpy()\n          revids = revids.detach().cpu().numpy()\n          if step == 0:\n            test_logits = logits.flatten()\n            test_rid = revids.flatten()\n          else:\n            test_logits = np.concatenate([test_logits, logits.flatten()])\n            test_rid = np.concatenate([test_rid, revids.flatten()])\n  results = {\n      'RevId': [int(id) for id in test_rid],\n      'Rating': [round(float(rate)*10, 1) for rate in np_sigmoid(test_logits)]\n  }\n  df = pd.DataFrame(results)\n  save_model(model, optimizer, f\"./working/state_dict_{epoch_i}.pth\")\n  df.to_csv(f'./working/submit_joint_{epoch_i}.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T19:15:14.360103Z","iopub.execute_input":"2022-12-11T19:15:14.360675Z","iopub.status.idle":"2022-12-12T02:58:17.795713Z","shell.execute_reply.started":"2022-12-11T19:15:14.360639Z","shell.execute_reply":"2022-12-12T02:58:17.789319Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"======== Partition 1 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6176b1afdfa42b6af63dd7c82c4d1b0"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0422\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7f03dcfd1e4a52aa7c15ac6b9b1b2e"}},"metadata":{}},{"name":"stdout","text":"[6.7, 6.0, 6.2, 6.5, 6.7, 6.6, 2.8, 6.5, 6.4, 5.4, 6.8, 6.1, 7.0, 5.2, 2.3, 5.6, 5.6, 5.7, 3.8, 4.9, 5.2, 3.8, 4.9, 6.0, 3.2, 5.3, 6.7, 4.3, 5.3, 5.4, 6.3, 5.9, 6.8, 6.7, 5.8, 5.2, 4.9, 5.0, 5.7, 6.3, 7.0, 4.9, 6.6, 5.9, 4.1, 6.3, 4.4, 5.1, 2.0, 4.9, 6.6, 5.7, 5.2, 5.5, 4.4, 3.9, 3.1, 4.9, 6.3, 5.6, 6.6, 5.0, 5.1, 5.7, 5.8, 6.0, 2.3, 6.5, 3.1, 6.4, 6.3, 7.0, 6.3, 3.0, 6.2, 3.4, 6.0, 5.3, 6.4, 6.7, 2.4, 7.0, 5.0, 6.9, 6.3, 3.9, 6.4, 7.1, 6.3, 6.2, 6.7, 6.9, 6.8, 6.6, 2.5, 6.4, 5.7, 5.2, 7.4, 7.3, 6.2, 6.4, 2.9, 6.2, 7.1, 5.9, 7.1, 6.5, 6.2, 6.2, 4.0, 3.2, 6.1, 4.3, 6.4, 6.4, 6.3, 4.7, 6.6, 6.6, 6.5, 6.9, 3.6, 6.4, 6.3, 6.3, 6.6, 6.6, 6.0, 4.1, 2.8, 7.3, 4.6, 4.2, 6.4, 6.5, 3.2, 3.8, 2.8, 5.5, 5.9, 4.9, 5.9, 2.3, 5.0, 6.8, 6.3, 6.0, 5.7, 6.4, 6.6, 4.9, 6.2, 3.4, 5.6, 6.3, 6.6, 6.4, 3.0, 6.1, 3.3, 6.0, 2.2, 5.3, 3.7, 5.0, 7.1, 6.5, 2.3, 7.1, 6.1, 5.4, 2.9, 2.9, 5.6, 5.0, 4.1, 3.8, 2.8, 6.6, 4.5, 3.2, 6.2, 6.6, 6.7, 6.2, 2.2, 6.5, 3.2, 6.0, 6.1, 5.4, 6.3, 6.1, 3.9, 5.6, 6.5, 6.2, 6.6, 6.7, 7.1, 5.5, 3.7, 3.4, 3.1, 3.5, 5.3, 4.3, 4.1, 6.5, 6.0, 7.1, 5.7, 7.4, 2.4, 6.9, 6.5, 6.8, 5.0, 5.2, 6.3, 6.3, 2.5, 2.9, 6.8, 6.0, 7.1, 4.5, 5.5, 5.1, 3.8, 2.5, 7.1, 5.4, 4.2, 5.2, 5.5, 5.4, 6.1, 5.9, 5.6, 6.1, 6.3, 5.2, 7.5, 6.2, 4.2, 5.5, 4.7, 6.4, 5.7, 3.8, 5.0, 6.5, 3.6, 2.6, 6.8, 6.9, 7.2, 6.3, 4.9, 2.3, 6.2, 6.1, 4.5, 6.5, 6.6, 5.6, 6.5, 6.8, 6.0, 7.0, 4.1, 3.3, 2.8, 6.0, 6.6, 4.9, 6.3, 4.6, 2.3, 7.0, 5.2, 6.7, 6.2, 6.3, 4.5, 6.5, 3.5, 2.5, 3.2, 4.7, 4.2, 2.7, 5.5, 6.8, 5.4, 6.5, 6.7, 3.8, 6.5, 5.8, 5.6, 6.6, 6.3, 4.4, 6.1, 6.5, 6.1, 3.2, 6.1, 6.1, 5.8, 6.5, 4.8, 4.9, 6.8, 4.9, 6.7, 4.2, 6.6, 6.5, 4.5, 3.6, 5.7, 3.9, 5.1, 6.4, 6.7, 5.6, 5.6, 6.3, 5.0, 5.5, 3.2, 3.7, 6.7, 6.1, 3.4, 6.5, 5.5, 6.6, 6.3, 7.1, 5.9, 7.0, 3.5, 5.4, 6.2, 5.7, 6.5, 6.0, 5.7, 6.3, 6.4, 6.8, 6.9, 5.9, 6.0, 6.9, 6.6, 7.0, 7.0, 6.2, 6.4, 4.1, 2.7, 3.8, 5.3, 7.1, 6.6, 6.6, 6.5, 5.2, 5.3, 4.6, 5.9, 6.4, 3.2, 6.9, 6.1, 4.2, 5.1, 4.0, 2.9, 5.2, 6.5, 6.4, 6.4, 6.8, 6.4, 6.6, 6.9, 6.6, 6.0, 5.5, 5.0, 2.8, 6.8, 6.6, 2.9, 5.6, 6.6, 5.5, 6.2, 2.1, 4.6, 5.1, 5.4, 4.9, 6.6, 6.6, 6.0, 4.2, 6.1, 6.5, 5.2, 6.3, 6.4, 4.5, 4.5, 6.3, 5.9, 6.2, 6.4, 6.7, 2.3, 5.9, 5.6, 6.2, 3.7, 6.2, 5.1, 6.5, 5.7, 6.6, 6.5, 6.2, 6.3, 6.2, 6.2, 6.1, 5.7, 5.3, 6.3, 6.4, 6.6, 3.8, 4.0, 3.8, 5.5, 6.9, 4.3, 5.9, 6.8, 5.1, 5.3, 7.0, 3.2, 5.7, 5.9, 6.9, 6.1, 3.1, 4.9, 6.1, 6.2, 6.3, 5.3, 5.9, 6.8, 6.5, 6.5, 5.4, 7.4, 7.4, 5.5, 6.6, 7.3, 7.0, 5.2, 6.2, 5.2, 6.0, 2.7, 6.4, 5.7, 5.7, 6.5, 6.6, 6.0, 7.1, 6.0, 7.4, 6.2, 2.7, 6.8, 7.1, 6.1, 5.6, 3.0, 6.9, 5.8, 6.0, 4.8, 6.1, 5.2, 5.4, 2.6, 6.4, 7.5, 6.9, 6.1, 6.6, 6.0, 6.5, 6.6, 6.9, 3.3, 6.4, 6.2, 4.5, 6.1, 6.2, 4.5, 4.1, 3.9, 7.0, 6.4, 5.5, 6.5, 5.4, 6.6, 5.9, 5.5, 6.5, 6.6, 5.7, 6.1, 7.2, 5.9, 6.6, 5.0, 3.0, 6.8, 6.2, 2.5, 2.1, 6.6, 6.4, 7.2, 6.5, 6.3, 3.1, 3.4, 4.9, 6.1, 3.2, 4.8, 6.0, 6.7, 6.5, 6.4, 6.5, 6.7, 6.3, 7.1, 6.4, 3.0, 6.6, 6.1, 6.4, 5.5, 6.6, 5.6, 5.0, 5.0, 7.2, 6.0, 6.0, 6.2, 5.0, 5.6, 6.0, 5.5, 7.1, 5.6, 6.3, 6.2, 3.6, 6.8, 2.6, 6.3, 5.0, 6.5, 7.2, 3.3, 3.4, 7.2, 6.7, 3.3, 6.9, 6.6, 6.3, 6.9, 2.5, 3.9, 6.2, 5.0, 3.2, 6.2, 6.7, 5.2, 2.9, 5.0, 2.6, 5.6, 6.5, 7.1, 6.8, 5.6, 6.8, 4.7, 5.2, 5.4, 6.7, 6.0, 5.8, 2.7, 6.8, 4.7, 2.7, 6.2, 6.4, 5.2, 6.0, 4.9, 5.2, 2.5, 6.7, 6.4, 3.6, 6.3, 6.8, 6.3, 6.9, 4.6, 6.6, 3.1, 6.4, 6.3, 6.9, 5.4, 6.8, 4.2, 6.4, 5.4, 6.5, 6.6, 5.2, 3.3, 2.7, 6.9, 6.4, 6.0, 6.3, 5.2, 6.4, 6.9, 6.7, 6.4, 6.2, 5.5, 6.3, 6.7, 6.9, 7.1, 3.0, 6.9, 3.0, 6.0, 6.4, 3.3, 6.6, 6.8, 5.5, 6.6, 5.6, 4.8, 3.1, 5.1, 2.7, 6.0, 6.0, 6.2, 6.0, 3.7, 7.2, 6.3, 5.2, 6.8, 5.5, 2.8, 6.4, 6.9, 6.1, 3.3, 6.2, 2.5, 5.3, 4.9, 3.4, 6.7, 5.3, 6.6, 3.0, 5.9, 5.7, 5.4, 5.7, 6.6, 5.4, 5.9, 6.8, 4.8, 6.6, 5.6, 7.4, 6.4, 6.5, 6.0, 5.9, 2.5, 7.1, 6.5, 2.8, 5.9, 7.1, 6.7, 4.7, 3.3, 6.8, 7.1, 6.9, 6.7, 6.6, 6.9, 7.6, 5.8, 3.5, 6.7, 5.1, 6.1, 5.2, 6.5, 6.8, 3.0, 2.7, 5.3, 4.7, 7.3, 6.4, 3.9, 2.1, 5.6, 4.5, 5.8, 6.7, 6.5, 5.6, 6.5, 6.4, 7.1, 6.7, 6.2, 5.0, 6.3, 6.9, 5.0, 6.0, 7.0, 2.0, 6.9, 5.4, 5.6, 5.3, 6.7, 7.3, 6.7, 5.7, 6.7, 5.7, 4.7, 6.1, 6.3, 6.4, 4.8, 6.0, 6.8, 7.0, 6.8, 6.6, 6.3, 7.0, 6.7, 6.5, 6.4, 6.0, 2.7, 5.6, 5.3, 5.8, 4.8, 6.8, 4.2, 5.0, 5.7, 6.2, 6.0, 6.8, 6.6, 6.3, 4.6, 6.1, 6.3, 7.3, 6.6, 7.2, 2.8, 6.5, 7.3, 5.4, 6.7, 5.9, 6.0, 6.6, 3.3, 5.4, 3.5, 4.9, 6.2, 4.7, 6.2, 6.5, 6.3, 6.2, 5.9, 6.7, 6.5, 6.7, 6.6, 6.4, 2.8, 6.7, 6.4, 6.7, 5.4, 7.0, 6.4, 5.3, 6.7, 5.3, 7.3, 6.5, 6.5, 6.4, 6.8, 5.9, 6.3, 2.4, 6.5, 6.6, 3.4, 6.3, 5.3, 6.2, 5.1, 7.2, 6.7, 6.7, 5.4, 7.0, 4.6, 6.4, 6.6, 3.1, 6.6, 4.9, 5.6, 7.3, 2.8, 5.8, 6.0, 4.1, 5.3, 6.7, 5.4, 5.9, 2.8, 5.4, 6.7, 6.6, 2.5, 5.2, 5.5, 3.5, 5.8, 5.8]\n ROC-AUC score: 0.8909\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2f078fa2d7e4431942a4aeb27514d4e"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 2 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e74a1e8a5f460ab29bbbb4014df13f"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0324\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe3e4e1e72c04ede8a2f4be6e58da358"}},"metadata":{}},{"name":"stdout","text":"[6.4, 5.9, 6.9, 6.2, 7.4, 6.2, 5.3, 7.2, 5.9, 6.8, 6.5, 5.7, 6.6, 2.4, 7.1, 8.7, 5.9, 7.3, 2.3, 6.4, 6.2, 6.5, 3.2, 5.9, 6.2, 4.3, 7.6, 5.7, 7.4, 6.3, 6.4, 6.9, 7.2, 6.6, 5.0, 6.0, 4.9, 4.4, 4.7, 5.0, 4.9, 2.3, 7.1, 6.1, 5.0, 7.6, 5.4, 6.6, 7.0, 2.1, 4.6, 2.2, 7.4, 5.7, 7.8, 7.3, 6.5, 6.3, 3.3, 2.5, 6.7, 5.6, 2.5, 2.6, 5.5, 2.2, 5.5, 6.2, 6.9, 5.8, 3.3, 6.7, 6.6, 3.6, 6.1, 6.2, 6.9, 3.5, 7.0, 7.0, 4.4, 6.6, 6.5, 7.1, 6.8, 8.3, 5.5, 7.0, 6.7, 3.2, 7.6, 7.2, 6.7, 6.3, 3.8, 2.7, 7.3, 6.8, 6.0, 8.7, 7.0, 6.9, 7.2, 5.7, 7.0, 4.9, 6.3, 6.6, 7.1, 4.7, 4.9, 7.0, 8.2, 7.5, 7.2, 6.5, 4.1, 6.9, 5.4, 6.8, 7.4, 7.4, 6.6, 8.1, 7.1, 6.3, 5.8, 7.3, 6.1, 3.5, 6.0, 7.1, 5.4, 5.6, 5.3, 2.4, 6.7, 6.9, 5.7, 7.2, 7.1, 2.5, 2.7, 6.7, 6.7, 6.4, 6.2, 6.6, 6.6, 7.4, 3.1, 6.0, 6.6, 6.7, 2.3, 6.8, 4.2, 2.6, 2.6, 7.0, 7.4, 7.5, 6.7, 4.8, 3.6, 6.9, 3.8, 6.8, 7.2, 6.4, 6.8, 6.3, 7.5, 7.2, 7.2, 5.8, 5.6, 3.1, 6.5, 6.8, 3.1, 5.7, 7.0, 2.6, 5.2, 4.7, 7.4, 5.3, 6.7, 6.2, 8.4, 7.5, 5.2, 3.5, 7.3, 8.0, 6.7, 6.4, 2.2, 6.6, 7.0, 6.3, 6.7, 7.3, 2.9, 5.7, 6.9, 5.6, 6.3, 7.8, 7.4, 6.9, 6.7, 7.0, 6.9, 3.1, 6.5, 4.8, 2.7, 2.2, 3.3, 6.4, 2.7, 6.5, 2.5, 5.6, 2.7, 3.0, 7.3, 6.0, 7.3, 4.3, 3.2, 7.2, 7.2, 5.6, 6.7, 6.2, 4.2, 5.8, 6.4, 3.2, 2.8, 6.8, 5.9, 3.1, 2.8, 6.7, 7.4, 6.2, 7.9, 5.6, 8.3, 6.9, 7.4, 7.8, 2.5, 2.9, 7.0, 6.1, 7.9, 6.8, 6.0, 7.4, 7.6, 2.5, 8.9, 3.1, 4.7, 7.1, 6.8, 5.7, 7.3, 6.9, 2.8, 2.6, 7.3, 6.6, 6.8, 6.4, 6.4, 6.5, 6.1, 5.3, 6.6, 3.9, 6.8, 7.3, 4.4, 6.7, 6.4, 7.8, 5.5, 5.1, 7.3, 7.3, 6.1, 6.1, 7.5, 6.6, 6.8, 5.5, 7.3, 3.4, 5.8, 2.9, 5.8, 6.2, 3.5, 6.0, 5.8, 7.8, 5.9, 6.2, 6.6, 5.0, 3.1, 7.1, 7.7, 8.4, 6.9, 6.4, 4.9, 3.1, 6.8, 5.0, 6.5, 7.2, 2.0, 4.8, 4.3, 5.9, 6.9, 3.6, 2.6, 3.4, 8.2, 5.2, 6.3, 6.7, 7.2, 7.1, 5.6, 7.1, 7.5, 5.6, 7.5, 6.4, 3.9, 3.7, 2.8, 6.7, 6.9, 5.9, 7.4, 6.7, 6.5, 4.8, 6.4, 2.5, 6.8, 6.7, 7.7, 6.8, 6.3, 7.4, 3.7, 7.2, 6.2, 8.4, 7.1, 6.9, 4.6, 5.9, 7.8, 6.8, 7.3, 7.1, 6.4, 5.6, 6.6, 2.6, 4.5, 7.8, 7.0, 2.6, 4.8, 6.2, 6.5, 7.0, 6.5, 5.2, 5.6, 6.4, 3.1, 5.9, 4.6, 4.1, 7.7, 5.2, 7.0, 3.1, 4.6, 5.5, 6.9, 6.7, 6.2, 5.7, 6.5, 4.3, 3.4, 6.0, 5.0, 6.4, 6.7, 5.6, 7.2, 7.1, 6.7, 6.9, 3.1, 2.1, 7.2, 6.6, 5.9, 5.3, 6.2, 2.8, 6.3, 5.8, 5.1, 5.9, 6.9, 4.5, 3.1, 2.5, 7.7, 6.4, 7.7, 3.0, 5.3, 8.7, 2.5, 6.6, 4.6, 3.5, 7.0, 6.2, 6.6, 5.9, 7.0, 5.6, 7.5, 5.0, 2.2, 6.8, 4.0, 6.9, 5.3, 6.9, 7.0, 2.5, 5.4, 6.0, 5.9, 6.0, 7.4, 6.2, 5.9, 7.2, 2.5, 7.1, 7.5, 6.8, 7.5, 6.4, 6.3, 6.1, 6.2, 8.1, 6.8, 5.7, 7.0, 6.5, 7.7, 6.5, 5.9, 5.6, 7.0, 5.6, 5.3, 2.7, 2.5, 5.4, 6.5, 3.4, 4.0, 2.7, 6.3, 7.0, 4.1, 6.4, 3.4, 4.1, 6.7, 6.6, 6.4, 6.3, 5.0, 3.8, 5.8, 7.0, 5.7, 4.9, 6.8, 6.4, 6.5, 4.2, 5.6, 5.6, 5.5, 6.0, 5.1, 5.2, 6.2, 2.8, 7.9, 7.8, 6.8, 4.3, 4.7, 3.7, 6.5, 5.6, 2.8, 8.7, 2.8, 7.1, 7.0, 7.2, 5.6, 6.9, 7.4, 5.6, 5.3, 7.9, 5.0, 6.7, 6.2, 4.9, 7.0, 6.9, 7.6, 6.2, 7.2, 5.5, 5.8, 5.9, 3.1, 6.4, 5.3, 4.5, 8.1, 6.1, 5.7, 5.8, 6.9, 6.4, 6.1, 7.0, 2.5, 5.0, 6.0, 3.0, 5.2, 7.1, 2.4, 2.3, 2.2, 6.9, 5.4, 7.6, 6.1, 6.0, 6.1, 5.6, 5.8, 5.7, 5.5, 7.9, 6.6, 5.8, 5.9, 7.4, 7.9, 5.5, 5.9, 6.0, 7.1, 4.9, 7.4, 7.2, 6.0, 5.9, 6.3, 7.6, 6.8, 4.1, 6.7, 7.3, 6.4, 7.0, 6.5, 5.4, 6.9, 5.4, 7.2, 2.8, 6.3, 6.5, 7.5, 6.1, 4.5, 7.0, 7.3, 6.6, 7.2, 7.6, 4.6, 7.1, 3.9, 6.4, 7.0, 6.1, 3.9, 6.9, 7.2, 6.8, 6.4, 5.8, 3.8, 6.4, 5.9, 3.5, 4.4, 3.7, 4.7, 7.3, 6.6, 5.8, 6.3, 5.4, 7.8, 6.0, 7.4, 4.3, 7.0, 7.7, 6.2, 7.6, 7.0, 6.4, 6.0, 2.7, 5.9, 6.0, 7.1, 2.4, 6.5, 5.5, 6.4, 6.7, 5.3, 4.2, 6.9, 6.5, 6.4, 6.7, 6.4, 7.7, 5.1, 2.4, 5.8, 6.8, 2.6, 4.8, 8.1, 7.4, 5.5, 4.5, 6.5, 6.5, 3.0, 4.7, 2.6, 4.9, 7.0, 4.1, 7.6, 6.1, 6.8, 5.5, 6.4, 6.0, 2.8, 3.8, 2.6, 6.1, 7.3, 2.5, 8.5, 7.1, 4.3, 7.1, 7.3, 7.8, 5.2, 4.1, 6.3, 3.3, 5.7, 6.3, 6.0, 7.7, 5.1, 6.3, 6.2, 2.4, 6.7, 5.1, 7.0, 6.8, 5.4, 6.0, 6.0, 6.7, 6.7, 6.5, 7.5, 6.7, 2.6, 5.0, 8.1, 7.2, 2.2, 6.8, 7.1, 6.8, 5.6, 2.7, 4.8, 2.0, 6.4, 6.9, 5.0, 7.1, 2.6, 3.4, 5.9, 6.8, 3.3, 6.9, 2.1, 7.9, 7.1, 6.4, 6.0, 6.2, 5.6, 5.4, 6.5, 6.2, 6.9, 6.4, 7.1, 3.1, 7.2, 7.8, 3.5, 7.3, 4.0, 7.6, 4.9, 6.8, 7.9, 6.8, 7.8, 5.6, 6.9, 5.6, 6.6, 6.6, 3.8, 6.8, 6.4, 6.3, 2.8, 5.5, 7.0, 6.4, 6.5, 6.9, 7.5, 7.3, 5.8, 7.4, 6.8, 5.4, 4.6, 7.2, 5.6, 7.3, 5.8, 6.6, 6.4, 5.8, 6.0, 5.5, 5.1, 2.6, 6.7, 2.3, 4.9, 6.3, 6.3, 7.3, 3.3, 4.6, 3.8, 6.1, 2.9, 6.2, 7.6, 3.0, 6.3, 7.3, 4.6, 6.8, 7.5, 2.6, 5.3, 5.9, 2.5, 6.0, 6.3, 6.5, 5.0, 5.8, 6.5, 5.5, 7.5, 6.2, 4.6, 6.6, 6.2, 8.1, 6.7, 3.4, 6.5, 5.1, 2.6, 5.4, 7.5, 3.2, 7.5, 7.1, 4.9, 2.1, 7.5, 7.2, 6.8, 7.1, 7.5, 4.5, 6.0, 2.4, 7.3, 6.5, 4.6, 6.4, 7.0, 5.7, 4.9, 6.1, 6.3, 7.5, 8.3, 5.4, 4.9, 7.4, 3.1, 5.9, 6.6, 7.7, 6.8, 4.9, 6.5, 5.8, 4.2, 5.9, 6.1, 3.9, 5.4, 7.2, 6.6, 6.0, 4.2]\n ROC-AUC score: 0.9296\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438d748fa9b04b85a7a58b90f0fd3184"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 3 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3a41269c21f4d70ac405e3989f9a5d7"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0221\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"213a1d9ac20d4c5d96eee65dbfe53a06"}},"metadata":{}},{"name":"stdout","text":"[2.7, 8.5, 3.5, 1.3, 5.6, 7.8, 5.0, 8.7, 2.7, 6.4, 6.5, 9.2, 7.8, 6.5, 7.1, 3.6, 1.2, 9.1, 4.4, 8.1, 7.9, 7.3, 7.1, 5.1, 1.7, 9.3, 4.7, 3.0, 8.4, 3.7, 5.2, 5.9, 8.2, 8.5, 9.0, 2.9, 9.1, 2.8, 8.0, 3.6, 8.0, 6.4, 3.3, 2.4, 1.5, 2.4, 4.9, 8.5, 7.6, 9.0, 6.8, 1.9, 8.3, 5.9, 4.8, 6.9, 4.3, 8.6, 1.9, 8.5, 6.4, 6.0, 9.0, 9.7, 5.7, 5.0, 7.2, 8.9, 9.7, 7.2, 8.3, 2.8, 6.3, 2.6, 7.7, 8.0, 4.0, 6.7, 8.9, 7.4, 2.6, 3.9, 8.0, 7.3, 8.9, 6.2, 1.6, 5.4, 8.2, 7.9, 3.5, 8.7, 6.0, 7.7, 2.9, 7.5, 5.4, 3.5, 9.0, 6.7, 7.9, 4.8, 6.1, 6.2, 4.0, 1.7, 9.3, 6.6, 4.6, 4.0, 9.3, 6.0, 8.6, 9.3, 1.8, 6.7, 5.4, 9.4, 6.3, 8.9, 5.3, 9.9, 4.4, 6.1, 7.2, 1.8, 2.5, 9.2, 6.5, 2.0, 7.2, 8.1, 5.9, 9.1, 2.7, 7.2, 7.5, 8.6, 9.9, 4.0, 8.4, 4.6, 8.2, 8.3, 3.1, 3.4, 2.8, 7.2, 6.1, 8.8, 8.8, 9.4, 6.9, 6.1, 2.0, 1.7, 5.1, 2.4, 7.7, 9.2, 1.7, 1.6, 5.1, 5.8, 5.9, 6.8, 3.5, 1.6, 8.7, 7.6, 5.2, 8.7, 9.0, 8.4, 9.2, 5.4, 7.7, 6.1, 6.9, 8.2, 7.0, 5.7, 6.2, 9.2, 7.6, 9.4, 6.4, 1.8, 8.4, 7.5, 3.4, 6.0, 7.9, 6.7, 8.9, 6.9, 8.4, 5.7, 2.2, 2.5, 5.0, 2.0, 7.6, 7.5, 9.5, 9.3, 7.7, 8.5, 9.2, 7.4, 7.2, 6.5, 2.4, 9.2, 7.5, 7.6, 4.4, 6.7, 8.5, 2.3, 8.3, 7.0, 9.2, 8.7, 6.5, 6.9, 8.2, 7.3, 8.3, 8.2, 2.2, 2.3, 8.4, 7.2, 5.3, 4.8, 6.8, 2.3, 5.8, 1.8, 2.4, 8.8, 4.2, 7.6, 5.6, 2.2, 8.6, 9.7, 7.0, 5.3, 8.0, 3.5, 9.4, 7.1, 8.5, 7.3, 8.6, 6.0, 8.9, 5.0, 1.6, 7.7, 6.5, 7.2, 1.9, 9.2, 7.8, 1.8, 7.7, 6.4, 7.8, 9.0, 6.1, 7.8, 9.5, 9.1, 1.4, 3.4, 8.9, 2.7, 9.6, 1.6, 7.9, 6.5, 6.0, 8.5, 6.0, 9.0, 1.7, 8.0, 7.4, 4.9, 2.5, 7.7, 8.5, 2.2, 5.8, 6.3, 8.3, 8.6, 1.2, 4.2, 7.0, 8.6, 9.4, 8.3, 1.7, 8.1, 8.4, 6.3, 8.1, 2.0, 8.6, 2.4, 6.7, 8.4, 4.9, 5.9, 6.0, 1.8, 9.4, 7.8, 7.2, 9.2, 3.4, 6.1, 3.6, 8.3, 5.2, 8.3, 6.1, 1.6, 5.9, 7.9, 9.0, 2.0, 7.6, 8.2, 5.6, 4.6, 8.9, 6.1, 3.9, 1.9, 2.7, 1.8, 7.9, 6.7, 7.5, 8.5, 8.3, 6.3, 8.0, 7.4, 5.2, 8.7, 4.2, 1.9, 3.0, 5.0, 8.5, 5.3, 1.7, 7.8, 7.9, 8.6, 7.3, 5.3, 6.6, 2.2, 6.7, 7.1, 5.7, 8.7, 8.3, 6.4, 5.6, 8.3, 7.4, 7.2, 9.4, 8.2, 8.4, 7.1, 2.4, 7.1, 5.8, 8.0, 2.2, 6.2, 8.0, 8.7, 7.4, 1.6, 8.7, 7.8, 8.3, 1.5, 7.2, 7.3, 8.3, 4.1, 8.6, 7.7, 8.5, 1.4, 6.9, 3.2, 5.3, 8.6, 9.7, 9.4, 8.1, 8.5, 1.8, 7.1, 2.0, 7.2, 7.8, 7.5, 2.2, 2.2, 8.3, 8.9, 6.1, 7.6, 4.7, 7.7, 8.1, 7.5, 5.4, 7.0, 5.9, 9.1, 2.2, 7.0, 1.1, 5.7, 7.0, 7.7, 4.3, 5.7, 7.1, 7.7, 5.1, 7.8, 8.5, 4.4, 5.8, 9.0, 3.6, 3.7, 2.1, 8.7, 6.9, 9.2, 2.4, 6.0, 7.5, 9.2, 8.8, 8.9, 2.5, 2.4, 7.0, 8.2, 6.2, 7.8, 8.8, 7.6, 6.2, 7.9, 8.4, 6.2, 5.5, 2.3, 8.8, 6.2, 2.7, 4.8, 6.9, 6.0, 8.3, 7.8, 3.4, 2.1, 6.6, 4.3, 7.2, 8.6, 6.9, 7.5, 9.6, 8.1, 9.7, 9.2, 4.8, 1.6, 5.7, 5.4, 7.4, 6.7, 2.1, 7.5, 9.2, 5.9, 6.4, 8.7, 2.7, 5.8, 3.7, 1.6, 1.1, 6.1, 8.2, 8.3, 2.7, 1.8, 3.0, 9.8, 8.5, 9.4, 9.5, 6.9, 6.6, 3.2, 8.4, 3.8, 8.9, 8.5, 5.3, 7.9, 9.6, 2.0, 7.3, 1.2, 6.6, 2.5, 9.1, 7.4, 5.8, 8.0, 5.6, 9.7, 6.4, 8.6, 8.4, 9.1, 5.7, 6.4, 5.9, 8.8, 3.6, 8.0, 7.2, 7.3, 8.2, 6.2, 5.1, 6.7, 6.8, 9.6, 3.5, 8.8, 7.9, 2.1, 9.6, 7.8, 7.1, 6.4, 6.1, 6.7, 6.4, 9.5, 7.8, 4.2, 9.5, 8.6, 8.7, 7.0, 3.8, 3.9, 8.6, 1.9, 3.4, 5.7, 7.0, 4.4, 8.1, 9.4, 8.8, 4.1, 9.2, 8.0, 7.2, 6.0, 2.3, 6.5, 8.6, 1.7, 6.9, 3.9, 8.9, 9.1, 8.8, 6.9, 7.2, 7.7, 8.6, 8.4, 8.0, 5.8, 2.6, 9.3, 8.1, 2.9, 8.4, 7.1, 2.1, 3.4, 8.6, 8.9, 7.9, 6.4, 4.3, 9.5, 7.9, 2.3, 8.0, 4.9, 9.4, 7.3, 4.8, 8.2, 2.0, 4.8, 8.7, 8.9, 6.7, 6.3, 4.6, 3.4, 7.6, 6.9, 3.1, 8.1, 9.2, 8.0, 6.9, 6.8, 3.4, 8.7, 8.5, 6.8, 9.0, 7.9, 8.6, 7.3, 7.5, 9.1, 6.8, 7.2, 8.7, 5.3, 8.7, 7.3, 6.9, 3.0, 1.4, 8.2, 8.8, 8.0, 8.0, 6.0, 3.9, 6.6, 2.0, 8.1, 7.4, 8.9, 6.0, 8.2, 8.9, 8.7, 9.6, 6.7, 2.2, 9.0, 2.6, 8.0, 7.1, 9.0, 8.1, 9.0, 4.0, 6.8, 8.6, 8.2, 3.4, 2.9, 3.1, 8.4, 7.0, 6.0, 7.3, 7.5, 7.3, 8.0, 9.1, 9.3, 8.8, 6.4, 6.2, 9.6, 6.0, 1.8, 2.2, 8.2, 7.9, 6.5, 6.1, 7.7, 1.8, 7.2, 7.7, 7.8, 6.7, 2.5, 6.3, 4.9, 1.6, 8.1, 7.6, 5.4, 6.0, 6.0, 8.8, 6.5, 8.8, 7.2, 6.2, 4.5, 2.2, 8.9, 1.9, 8.1, 8.6, 7.8, 5.1, 6.7, 8.6, 2.1, 6.9, 3.5, 8.0, 3.4, 9.2, 8.2, 7.9, 2.8, 2.0, 8.6, 6.5, 9.4, 7.2, 5.4, 2.1, 5.8, 8.5, 7.0, 7.4, 1.7, 3.2, 5.2, 8.5, 5.0, 6.8, 8.4, 9.0, 3.8, 3.6, 3.6, 7.4, 9.1, 3.3, 8.0, 4.7, 2.4, 7.8, 6.0, 9.4, 6.3, 8.8, 7.3, 7.6, 7.7, 8.5, 7.3, 7.4, 8.1, 8.2, 5.6, 9.1, 7.7, 1.7, 2.9, 3.0, 9.3, 5.5, 7.0, 7.2, 9.1, 6.3, 4.6, 8.9, 7.5, 8.1, 6.2, 5.2, 9.3, 9.4, 8.6, 9.4, 1.7, 1.9, 2.3, 2.4, 8.6, 5.9, 5.0, 8.2, 1.4, 7.0, 2.1, 7.2, 8.2, 7.4, 8.5, 8.3, 5.7, 8.4, 6.7, 8.5, 9.4, 6.8, 8.8, 7.4, 8.6, 8.8, 9.6, 9.1, 7.4, 8.7, 6.3, 8.7, 7.5, 5.8, 1.9, 5.3, 7.0, 2.5, 5.8, 6.3, 7.0, 7.8, 6.2, 1.4, 7.2, 8.4, 7.9, 8.5, 6.7, 8.6, 8.7, 6.2, 6.9, 2.8, 2.6, 6.7, 9.5, 8.1, 1.9, 2.5, 6.7, 8.3, 7.5, 7.8, 1.4, 2.0, 8.3, 3.9, 4.8, 4.1, 7.2, 8.5, 8.8, 6.9, 8.1, 8.8, 7.1, 6.2, 8.5, 4.3, 3.5, 8.5, 6.3, 6.5]\n ROC-AUC score: 0.9863\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f7de09ea0c4d88922f07d00a146322"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 4 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1bf53b623e4e0b91d5133f5d52a920"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0082\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abaca0c1b6f4f27986e3d576bd9cbba"}},"metadata":{}},{"name":"stdout","text":"[10.0, 10.0, 9.8, 9.0, 9.8, 9.8, 9.7, 4.6, 7.2, 9.0, 8.3, 9.1, 8.0, 0.6, 9.6, 9.7, 6.4, 10.0, 9.9, 8.0, 9.8, 3.7, 8.1, 7.7, 9.3, 9.9, 9.3, 9.6, 6.6, 8.6, 10.0, 9.5, 9.5, 1.1, 9.9, 4.8, 9.6, 0.3, 9.6, 9.5, 9.8, 8.4, 0.8, 9.8, 3.6, 8.9, 8.2, 5.1, 9.9, 8.6, 8.7, 9.3, 8.6, 8.8, 0.7, 9.8, 8.5, 7.9, 2.3, 8.3, 9.9, 8.9, 8.5, 7.5, 9.5, 0.5, 9.9, 5.2, 9.2, 8.6, 9.4, 6.2, 7.1, 1.2, 9.2, 8.2, 7.8, 8.9, 8.9, 0.2, 2.5, 8.9, 8.7, 9.9, 1.4, 8.7, 7.9, 7.0, 6.8, 9.4, 0.2, 9.9, 8.9, 0.7, 0.7, 8.0, 3.7, 0.5, 9.9, 7.5, 10.0, 0.4, 9.0, 8.2, 8.9, 9.5, 8.2, 9.9, 9.8, 8.4, 1.8, 9.6, 8.8, 9.2, 3.5, 9.9, 9.9, 9.8, 9.6, 1.0, 8.8, 1.5, 9.8, 9.2, 7.3, 0.4, 1.1, 9.0, 8.1, 1.6, 9.7, 3.9, 9.7, 5.7, 8.5, 9.4, 8.4, 8.5, 1.1, 9.1, 1.9, 8.2, 5.6, 9.1, 9.7, 0.1, 9.1, 1.7, 10.0, 9.8, 9.3, 6.9, 9.5, 9.5, 9.9, 9.7, 8.7, 9.5, 9.9, 8.8, 3.6, 9.8, 6.1, 9.5, 8.6, 0.8, 9.5, 9.3, 9.9, 1.0, 6.0, 0.6, 9.1, 9.9, 8.4, 2.1, 10.0, 7.6, 9.5, 1.1, 9.9, 9.9, 9.5, 0.3, 8.9, 9.2, 7.2, 8.7, 9.5, 9.2, 0.7, 8.0, 7.2, 5.8, 9.1, 8.6, 7.8, 7.0, 0.7, 9.8, 9.5, 0.5, 7.5, 6.3, 1.9, 9.8, 8.7, 9.3, 2.8, 7.6, 8.2, 8.1, 2.8, 7.9, 0.5, 10.0, 9.8, 9.6, 9.3, 9.4, 9.1, 9.8, 9.6, 0.2, 8.8, 9.5, 9.6, 2.0, 8.5, 9.1, 9.9, 9.8, 9.9, 9.9, 9.0, 0.8, 7.3, 1.2, 4.3, 9.8, 9.9, 8.7, 9.2, 9.9, 1.7, 9.4, 8.2, 9.5, 9.8, 7.2, 1.1, 9.9, 6.4, 8.9, 6.9, 0.3, 10.0, 0.2, 5.8, 9.3, 9.6, 9.0, 7.5, 4.7, 9.9, 9.9, 9.9, 8.8, 0.4, 8.9, 7.3, 8.1, 9.5, 8.2, 10.0, 7.9, 9.5, 9.0, 9.3, 9.2, 8.3, 9.4, 10.0, 1.2, 8.2, 1.3, 9.4, 9.5, 0.7, 1.5, 9.8, 8.5, 8.0, 9.2, 1.3, 6.4, 1.9, 9.9, 5.3, 8.7, 9.4, 9.8, 9.9, 9.9, 7.5, 8.4, 6.9, 3.5, 9.5, 7.2, 0.2, 9.9, 10.0, 9.7, 9.1, 1.3, 9.1, 7.9, 8.8, 9.9, 9.1, 9.8, 8.0, 7.8, 3.1, 9.7, 9.0, 6.9, 1.0, 1.8, 9.8, 8.4, 6.1, 8.3, 9.9, 9.4, 8.0, 8.7, 8.4, 8.3, 9.0, 9.7, 8.6, 8.9, 0.3, 8.7, 9.5, 9.3, 0.1, 1.2, 8.7, 1.9, 9.2, 8.3, 9.9, 7.3, 9.6, 9.3, 9.9, 9.7, 0.6, 0.6, 9.9, 9.0, 2.2, 0.5, 9.9, 9.9, 4.8, 9.5, 3.3, 9.5, 9.2, 9.5, 9.9, 9.0, 9.4, 8.2, 0.7, 9.3, 9.5, 1.4, 9.4, 9.9, 9.9, 1.1, 1.1, 7.8, 9.7, 9.9, 9.6, 3.8, 6.5, 0.8, 8.8, 9.6, 7.4, 8.0, 8.7, 9.8, 9.9, 0.5, 9.9, 10.0, 9.7, 8.9, 10.0, 8.3, 9.5, 1.0, 9.4, 9.7, 9.4, 8.8, 8.9, 9.4, 8.9, 8.1, 9.7, 9.8, 2.5, 9.3, 0.5, 9.8, 0.8, 9.4, 9.6, 5.5, 9.8, 9.5, 9.3, 0.7, 9.8, 10.0, 6.7, 9.4, 9.5, 9.9, 7.9, 8.0, 9.2, 9.8, 1.4, 9.6, 0.7, 9.3, 1.3, 9.2, 9.6, 9.5, 8.1, 9.9, 0.4, 9.8, 8.1, 8.9, 6.5, 9.3, 9.1, 7.5, 8.9, 2.1, 9.2, 9.1, 0.5, 9.9, 10.0, 7.7, 8.9, 0.2, 4.0, 5.6, 7.5, 7.1, 7.9, 0.4, 0.7, 8.2, 10.0, 9.2, 5.6, 9.4, 9.7, 8.9, 7.9, 9.4, 9.7, 7.4, 9.5, 9.2, 9.3, 1.4, 9.7, 0.7, 9.8, 1.1, 1.3, 9.3, 9.5, 9.3, 9.6, 8.9, 9.6, 9.7, 8.6, 10.0, 8.3, 7.5, 10.0, 9.4, 9.2, 9.4, 9.0, 9.6, 8.4, 10.0, 9.6, 9.8, 9.2, 7.6, 8.0, 1.2, 9.7, 3.0, 7.5, 7.7, 9.8, 5.7, 8.9, 9.3, 6.9, 9.0, 9.8, 5.8, 0.2, 9.6, 9.5, 9.9, 9.5, 8.9, 9.7, 10.0, 9.8, 8.9, 1.7, 9.7, 9.3, 9.2, 7.8, 9.9, 9.2, 9.9, 9.2, 3.7, 1.3, 10.0, 7.0, 1.8, 0.8, 2.3, 8.1, 9.0, 7.9, 2.7, 8.9, 9.6, 9.9, 7.4, 4.4, 9.9, 9.0, 0.3, 8.2, 9.8, 9.7, 9.7, 9.6, 9.6, 7.5, 8.4, 6.4, 9.9, 0.3, 0.8, 0.3, 10.0, 9.8, 7.0, 8.2, 10.0, 9.9, 9.0, 8.8, 8.8, 9.2, 9.7, 9.7, 8.8, 9.0, 8.8, 9.5, 9.6, 0.1, 9.6, 2.0, 6.5, 6.3, 9.6, 9.8, 8.4, 7.7, 9.8, 9.4, 6.7, 9.6, 9.9, 4.8, 8.5, 0.9, 9.8, 9.1, 9.4, 8.7, 9.7, 9.5, 9.8, 2.8, 2.9, 0.9, 9.8, 9.2, 7.8, 8.8, 7.2, 9.5, 2.8, 7.3, 8.7, 9.2, 0.4, 7.8, 0.2, 8.8, 0.3, 9.8, 9.2, 5.6, 8.7, 9.2, 9.4, 8.8, 9.6, 9.4, 10.0, 9.9, 9.6, 9.6, 9.6, 9.9, 0.7, 2.4, 9.6, 9.1, 9.7, 0.7, 9.9, 8.8, 0.6, 9.9, 10.0, 9.7, 9.9, 7.4, 4.0, 5.6, 8.4, 8.5, 8.3, 0.8, 8.8, 9.6, 0.3, 9.6, 2.4, 1.5, 9.2, 7.0, 9.4, 7.6, 9.1, 9.5, 9.6, 9.0, 9.7, 9.9, 6.5, 9.4, 1.6, 9.9, 0.6, 9.7, 9.7, 9.5, 0.7, 9.9, 9.9, 5.3, 9.7, 9.3, 6.7, 8.4, 6.9, 9.8, 9.7, 1.1, 9.4, 7.5, 9.4, 8.7, 10.0, 6.4, 9.9, 9.6, 0.4, 8.1, 9.3, 1.5, 9.9, 9.8, 7.2, 2.7, 0.7, 0.1, 9.9, 4.5, 9.5, 9.4, 9.9, 9.2, 9.2, 9.9, 9.9, 9.7, 9.5, 8.3, 9.8, 8.8, 0.8, 9.3, 9.9, 0.7, 9.5, 1.0, 9.2, 10.0, 8.0, 1.1, 8.8, 6.8, 9.8, 9.2, 6.8, 4.6, 9.9, 1.4, 9.4, 9.3, 0.5, 0.5, 9.8, 9.0, 9.0, 9.9, 8.1, 8.5, 9.8, 9.7, 8.9, 0.3, 9.9, 9.6, 9.7, 9.6, 8.2, 9.9, 6.5, 8.5, 8.3, 7.5, 9.6, 9.2, 9.3, 2.5, 9.9, 8.4, 9.4, 0.8, 8.9, 9.4, 10.0, 7.7, 9.8, 9.4, 2.9, 2.6, 8.4, 9.9, 2.0, 8.4, 1.7, 1.3, 9.9, 9.9, 9.8, 0.4, 9.5, 9.8, 9.8, 2.2, 2.3, 8.4, 7.4, 1.4, 6.9, 9.7, 9.6, 8.6, 9.7, 9.2, 9.4, 10.0, 8.8, 9.8, 4.8, 8.4, 9.6, 9.8, 9.4, 9.3, 8.6, 9.0, 9.8, 9.2, 4.4, 7.6, 2.2, 10.0, 2.3, 7.8, 9.8, 9.2, 2.3, 9.9, 9.7, 9.9, 9.1, 10.0, 9.9, 8.7, 10.0, 3.1, 7.9, 8.5, 8.4, 9.7, 3.5, 0.3, 9.9, 1.4, 9.1, 9.2, 8.6, 1.2, 8.6, 9.5, 9.7, 9.2, 9.9, 0.7, 9.4, 8.8, 9.8, 9.2, 8.1, 9.9, 8.7, 9.2, 8.0, 10.0, 9.5, 1.7, 9.9, 7.4, 2.8, 6.2, 0.8, 3.0, 0.3, 9.7, 9.8, 0.2, 9.6, 2.0, 9.8, 0.4, 9.7, 10.0]\n ROC-AUC score: 0.9973\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b62093a774a743de8aa1ba2ff624f985"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 5 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e38542b64a8b4fc783672094a4de6278"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0028\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192c72cfcc054cf38eae9b3060e4ebef"}},"metadata":{}},{"name":"stdout","text":"[8.9, 10.0, 9.5, 9.6, 9.7, 0.1, 10.0, 0.3, 9.9, 9.9, 9.9, 10.0, 9.6, 9.1, 9.8, 9.7, 9.9, 9.8, 0.1, 9.4, 9.8, 9.7, 10.0, 9.4, 10.0, 7.6, 0.1, 0.3, 2.9, 0.8, 9.9, 9.1, 9.4, 9.6, 9.2, 1.9, 0.1, 9.9, 1.3, 9.1, 6.8, 9.9, 9.9, 9.6, 9.9, 8.4, 9.7, 0.4, 10.0, 9.6, 10.0, 9.4, 0.5, 8.8, 10.0, 9.8, 9.7, 0.0, 9.7, 2.8, 9.9, 0.2, 10.0, 0.7, 9.4, 9.5, 10.0, 10.0, 9.8, 9.8, 0.7, 0.8, 7.1, 0.4, 0.0, 8.0, 9.8, 9.5, 10.0, 10.0, 8.2, 9.9, 9.4, 9.8, 9.9, 9.7, 10.0, 9.4, 0.4, 9.9, 2.5, 9.5, 8.0, 8.7, 10.0, 0.4, 0.1, 10.0, 9.7, 5.6, 6.1, 9.9, 8.9, 9.8, 9.7, 0.3, 9.2, 9.9, 9.9, 6.9, 8.4, 9.9, 10.0, 9.2, 8.2, 9.8, 9.1, 9.1, 8.2, 6.9, 10.0, 0.1, 10.0, 9.7, 10.0, 0.1, 9.3, 10.0, 8.3, 0.1, 0.0, 2.8, 9.8, 9.9, 9.2, 8.2, 0.6, 9.8, 9.9, 10.0, 10.0, 0.4, 9.7, 0.0, 9.4, 8.5, 7.5, 10.0, 9.3, 9.4, 0.5, 9.8, 0.3, 10.0, 9.9, 9.7, 9.9, 9.5, 10.0, 10.0, 9.9, 8.3, 10.0, 8.2, 6.7, 0.1, 10.0, 9.9, 10.0, 9.9, 0.0, 9.7, 9.8, 1.0, 9.6, 0.5, 10.0, 9.9, 0.0, 7.9, 9.5, 9.9, 9.5, 10.0, 9.0, 10.0, 6.1, 0.1, 7.5, 10.0, 9.0, 9.9, 8.1, 10.0, 9.7, 9.7, 0.1, 9.5, 2.2, 0.0, 9.9, 9.2, 9.3, 0.0, 9.8, 9.9, 9.9, 8.9, 6.4, 0.7, 10.0, 9.3, 0.0, 9.2, 0.4, 8.8, 9.7, 8.6, 9.7, 9.8, 10.0, 0.0, 9.9, 10.0, 9.9, 1.1, 0.4, 9.9, 9.6, 9.9, 9.6, 10.0, 9.3, 9.8, 10.0, 10.0, 0.3, 9.4, 7.8, 9.4, 9.1, 10.0, 9.7, 0.4, 9.5, 9.9, 0.1, 6.7, 9.8, 0.2, 0.2, 0.0, 10.0, 1.0, 10.0, 8.3, 10.0, 6.8, 6.7, 9.5, 0.2, 0.1, 10.0, 9.9, 9.8, 0.0, 10.0, 5.5, 9.7, 7.8, 9.6, 9.6, 9.9, 8.0, 8.8, 10.0, 9.6, 8.9, 0.4, 10.0, 9.9, 10.0, 9.8, 0.3, 9.5, 9.9, 10.0, 9.5, 8.2, 0.1, 10.0, 0.2, 9.7, 10.0, 10.0, 9.6, 9.5, 9.9, 9.9, 10.0, 9.2, 9.7, 10.0, 9.8, 9.8, 0.2, 10.0, 9.5, 0.3, 10.0, 8.5, 6.5, 7.8, 0.0, 9.8, 9.6, 9.9, 9.4, 9.8, 8.7, 10.0, 9.7, 9.2, 9.7, 8.6, 9.9, 10.0, 10.0, 10.0, 9.4, 9.7, 9.7, 6.8, 9.9, 9.7, 0.6, 10.0, 10.0, 1.9, 8.7, 9.0, 9.9, 9.2, 10.0, 10.0, 10.0, 8.3, 0.7, 10.0, 9.9, 10.0, 0.0, 9.9, 9.7, 0.2, 9.1, 0.1, 9.9, 8.2, 0.1, 9.7, 7.9, 9.6, 9.9, 9.9, 0.5, 8.1, 6.3, 10.0, 10.0, 7.8, 8.3, 10.0, 10.0, 9.8, 9.7, 10.0, 0.5, 0.1, 9.6, 9.7, 9.7, 8.2, 9.8, 8.6, 7.8, 10.0, 10.0, 6.6, 9.8, 10.0, 8.9, 8.8, 10.0, 7.2, 0.0, 9.8, 0.2, 10.0, 3.3, 7.4, 9.5, 9.3, 8.4, 0.1, 9.6, 8.6, 0.1, 10.0, 8.8, 9.9, 0.0, 0.2, 9.9, 0.1, 10.0, 10.0, 0.7, 8.7, 7.9, 10.0, 7.0, 0.9, 0.7, 0.2, 0.2, 0.2, 9.3, 9.9, 8.9, 9.8, 9.6, 9.4, 9.7, 0.0, 9.9, 9.7, 9.8, 9.1, 8.5, 6.7, 5.4, 9.9, 9.9, 9.7, 0.0, 8.4, 9.6, 0.0, 0.1, 10.0, 3.9, 0.7, 6.1, 9.4, 0.2, 5.5, 9.2, 0.3, 9.8, 9.8, 0.0, 9.8, 9.9, 10.0, 10.0, 10.0, 9.9, 7.9, 8.2, 10.0, 9.6, 10.0, 2.9, 5.2, 10.0, 9.9, 9.6, 9.2, 9.3, 0.0, 8.3, 10.0, 9.3, 0.1, 0.4, 9.9, 9.8, 0.0, 8.2, 10.0, 9.9, 0.0, 10.0, 9.5, 0.1, 8.9, 10.0, 0.9, 0.2, 8.3, 9.7, 9.6, 1.3, 10.0, 9.6, 8.9, 10.0, 9.2, 7.0, 8.8, 9.9, 9.9, 9.9, 9.9, 9.1, 9.6, 9.9, 9.9, 9.8, 9.8, 9.8, 10.0, 9.9, 9.4, 10.0, 10.0, 9.8, 5.4, 10.0, 0.0, 9.7, 10.0, 9.9, 10.0, 0.1, 9.4, 10.0, 10.0, 9.9, 10.0, 9.7, 0.2, 10.0, 9.9, 8.0, 9.9, 10.0, 9.8, 9.4, 0.1, 9.1, 9.9, 9.7, 9.8, 9.6, 8.9, 10.0, 0.2, 10.0, 9.9, 9.5, 10.0, 0.2, 10.0, 7.1, 10.0, 9.7, 10.0, 10.0, 9.6, 8.7, 0.0, 0.1, 9.8, 0.1, 8.9, 9.9, 9.5, 9.5, 8.3, 0.1, 0.0, 10.0, 10.0, 9.5, 1.0, 10.0, 9.9, 0.2, 8.6, 10.0, 10.0, 9.9, 9.8, 6.4, 9.7, 9.4, 9.9, 9.9, 9.9, 0.8, 9.8, 10.0, 9.9, 9.9, 9.4, 10.0, 9.9, 9.8, 0.3, 0.0, 9.0, 10.0, 0.0, 7.7, 0.4, 10.0, 10.0, 9.1, 9.8, 9.6, 7.7, 9.8, 8.9, 10.0, 10.0, 9.7, 0.3, 9.6, 10.0, 9.9, 10.0, 10.0, 9.8, 0.0, 10.0, 9.9, 0.2, 8.2, 9.9, 0.2, 8.2, 10.0, 10.0, 0.2, 9.5, 0.4, 0.0, 9.9, 10.0, 9.9, 9.7, 9.7, 0.5, 1.7, 9.7, 9.7, 10.0, 0.1, 9.9, 9.9, 0.0, 9.9, 9.6, 9.4, 1.2, 8.5, 9.7, 10.0, 0.1, 0.2, 1.1, 9.7, 9.9, 9.5, 8.3, 10.0, 10.0, 9.6, 9.7, 1.3, 10.0, 10.0, 8.9, 0.0, 10.0, 9.8, 0.1, 9.9, 0.2, 9.9, 10.0, 8.4, 9.1, 8.7, 9.6, 9.8, 10.0, 10.0, 9.9, 10.0, 9.3, 9.9, 0.1, 9.8, 9.9, 0.3, 9.6, 10.0, 9.7, 10.0, 9.5, 1.0, 9.6, 9.9, 9.9, 10.0, 9.8, 10.0, 9.9, 9.8, 9.6, 10.0, 9.9, 9.8, 7.7, 9.6, 9.6, 0.0, 10.0, 0.2, 9.5, 9.8, 9.7, 10.0, 1.5, 9.2, 9.9, 10.0, 9.8, 0.3, 9.8, 10.0, 10.0, 0.1, 9.5, 10.0, 0.0, 9.5, 9.5, 6.8, 10.0, 0.6, 0.2, 9.7, 9.7, 8.4, 9.4, 5.8, 9.9, 10.0, 10.0, 0.0, 10.0, 9.5, 0.2, 9.1, 9.9, 8.9, 10.0, 9.9, 9.8, 10.0, 8.5, 10.0, 9.9, 9.6, 9.9, 10.0, 8.8, 10.0, 2.7, 1.2, 9.3, 9.8, 9.9, 9.9, 9.7, 9.8, 0.1, 10.0, 8.9, 9.6, 9.7, 1.9, 10.0, 0.3, 9.9, 9.9, 0.5, 10.0, 8.8, 8.5, 2.6, 7.8, 5.9, 9.7, 9.2, 0.3, 0.3, 10.0, 0.2, 0.2, 0.3, 10.0, 9.9, 10.0, 0.0, 9.8, 7.4, 9.2, 10.0, 9.8, 9.8, 0.1, 10.0, 0.1, 9.9, 9.9, 0.1, 0.7, 9.4, 9.6, 0.0, 10.0, 9.6, 9.5, 9.7, 0.5, 9.9, 9.2, 9.5, 10.0, 10.0, 0.2, 9.7, 8.6, 8.5, 6.3, 9.0, 9.9, 9.9, 9.1, 10.0, 0.4, 10.0, 10.0, 0.0, 4.2, 10.0, 0.0, 9.9, 9.6, 0.3, 9.9, 9.8, 0.3, 9.9, 9.1, 9.6, 10.0, 10.0, 9.8, 0.5, 8.8, 9.8, 10.0, 9.2, 9.7, 8.3, 9.7, 9.9, 9.8, 9.8, 10.0, 0.0, 0.3, 10.0, 9.8, 0.1, 2.5, 9.8, 10.0, 8.4, 9.3, 9.6, 0.3, 9.9, 10.0, 9.9, 0.1, 9.9, 10.0, 0.0, 9.9, 9.8]\n ROC-AUC score: 0.9998\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a693d3e28d5493796cb3c5cc9e91efb"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 6 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ab300ef4664a578d13b7618eccfe01"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0016\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baeb02f6c3364427ae7e3bce00ac39a4"}},"metadata":{}},{"name":"stdout","text":"[0.3, 1.1, 10.0, 9.9, 0.6, 10.0, 1.1, 0.5, 10.0, 9.5, 0.1, 9.7, 10.0, 9.8, 1.4, 7.9, 9.9, 9.9, 0.1, 10.0, 9.9, 9.5, 10.0, 0.1, 9.8, 10.0, 10.0, 10.0, 10.0, 0.7, 9.9, 0.6, 10.0, 10.0, 10.0, 9.9, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.9, 8.4, 0.8, 10.0, 10.0, 10.0, 0.1, 9.1, 9.5, 7.1, 8.5, 10.0, 10.0, 0.8, 0.0, 10.0, 10.0, 9.8, 10.0, 9.9, 10.0, 10.0, 0.1, 9.8, 0.6, 10.0, 8.8, 9.9, 9.8, 10.0, 9.5, 1.0, 10.0, 9.9, 10.0, 10.0, 9.9, 10.0, 9.9, 0.6, 1.5, 9.6, 9.9, 10.0, 2.5, 0.0, 10.0, 9.8, 0.2, 9.6, 9.7, 10.0, 10.0, 9.9, 9.9, 10.0, 10.0, 10.0, 9.8, 10.0, 10.0, 0.4, 10.0, 10.0, 8.9, 0.1, 10.0, 10.0, 0.3, 9.9, 9.9, 9.9, 1.5, 0.3, 0.0, 10.0, 0.3, 9.9, 9.9, 1.2, 10.0, 9.5, 10.0, 10.0, 9.9, 0.1, 0.1, 8.7, 10.0, 10.0, 10.0, 0.2, 10.0, 9.9, 9.2, 0.1, 9.4, 9.9, 1.0, 0.0, 0.9, 10.0, 10.0, 10.0, 10.0, 0.4, 10.0, 9.9, 0.6, 0.7, 10.0, 8.9, 10.0, 10.0, 9.8, 0.2, 9.9, 10.0, 9.9, 10.0, 9.8, 0.3, 10.0, 9.9, 0.6, 9.8, 9.9, 0.9, 10.0, 8.7, 10.0, 10.0, 2.7, 10.0, 10.0, 10.0, 9.4, 9.9, 10.0, 10.0, 9.9, 9.9, 9.5, 10.0, 10.0, 10.0, 9.9, 10.0, 0.4, 10.0, 10.0, 9.9, 9.5, 0.1, 9.7, 10.0, 7.3, 9.7, 0.1, 9.9, 9.9, 8.8, 9.8, 0.0, 9.5, 9.8, 9.8, 9.5, 0.1, 0.2, 10.0, 9.4, 9.9, 9.6, 9.0, 9.9, 9.8, 0.2, 9.9, 9.6, 10.0, 10.0, 9.5, 0.0, 9.9, 10.0, 2.2, 9.9, 9.8, 10.0, 10.0, 10.0, 10.0, 9.5, 6.8, 9.9, 8.9, 10.0, 0.3, 9.8, 9.5, 0.0, 10.0, 9.4, 10.0, 9.8, 9.6, 0.0, 9.4, 0.7, 0.3, 10.0, 0.2, 10.0, 9.3, 0.6, 10.0, 9.9, 5.9, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 9.9, 0.1, 9.7, 8.4, 10.0, 9.9, 0.2, 10.0, 10.0, 9.8, 10.0, 10.0, 9.6, 10.0, 9.6, 1.0, 10.0, 10.0, 9.8, 9.9, 10.0, 9.6, 0.0, 9.9, 9.9, 10.0, 10.0, 10.0, 10.0, 1.2, 0.3, 10.0, 9.7, 9.9, 10.0, 0.2, 9.5, 0.5, 10.0, 9.4, 10.0, 0.3, 0.1, 10.0, 9.9, 10.0, 9.9, 9.6, 1.4, 10.0, 9.9, 0.0, 9.8, 9.9, 0.0, 0.0, 0.0, 10.0, 10.0, 2.6, 10.0, 9.7, 9.9, 9.9, 9.9, 9.9, 10.0, 10.0, 0.0, 10.0, 10.0, 9.9, 10.0, 10.0, 9.3, 10.0, 9.9, 10.0, 9.9, 0.1, 9.9, 9.9, 0.2, 0.2, 9.6, 10.0, 10.0, 10.0, 10.0, 0.0, 8.5, 10.0, 9.9, 9.6, 9.5, 10.0, 0.0, 0.0, 10.0, 9.4, 10.0, 10.0, 9.8, 10.0, 10.0, 9.1, 10.0, 10.0, 9.7, 10.0, 0.1, 9.9, 9.9, 0.1, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.4, 10.0, 10.0, 10.0, 0.1, 9.5, 10.0, 0.7, 9.9, 10.0, 10.0, 10.0, 10.0, 9.9, 9.5, 0.1, 9.9, 9.9, 9.9, 8.8, 9.2, 9.8, 9.9, 9.8, 0.1, 10.0, 10.0, 10.0, 10.0, 9.8, 9.9, 10.0, 10.0, 9.9, 0.1, 10.0, 9.9, 8.7, 9.9, 0.8, 9.9, 10.0, 10.0, 9.0, 10.0, 10.0, 10.0, 9.9, 9.9, 0.0, 0.5, 10.0, 1.5, 9.9, 0.2, 9.9, 0.1, 9.8, 9.0, 10.0, 8.6, 9.8, 10.0, 9.2, 0.8, 10.0, 10.0, 0.3, 10.0, 9.9, 0.1, 8.2, 9.2, 10.0, 9.8, 10.0, 8.9, 10.0, 0.0, 0.7, 10.0, 9.9, 0.1, 9.7, 9.4, 10.0, 9.9, 10.0, 0.0, 0.8, 10.0, 9.7, 9.8, 9.9, 10.0, 10.0, 9.2, 0.2, 0.5, 9.9, 9.6, 10.0, 9.5, 0.7, 10.0, 0.2, 10.0, 10.0, 10.0, 0.5, 9.9, 10.0, 10.0, 9.9, 9.9, 0.1, 10.0, 9.9, 9.9, 0.8, 9.9, 9.9, 0.6, 9.6, 9.7, 9.8, 9.7, 10.0, 10.0, 10.0, 9.8, 9.9, 0.7, 0.9, 9.2, 10.0, 10.0, 9.8, 9.3, 10.0, 10.0, 0.5, 10.0, 0.0, 0.3, 10.0, 9.8, 10.0, 9.5, 10.0, 10.0, 10.0, 0.7, 10.0, 10.0, 10.0, 10.0, 0.8, 9.8, 10.0, 9.9, 10.0, 9.8, 1.2, 10.0, 10.0, 10.0, 9.3, 9.9, 9.9, 9.9, 10.0, 10.0, 1.3, 10.0, 0.4, 10.0, 10.0, 10.0, 9.3, 9.7, 10.0, 9.9, 10.0, 9.9, 1.3, 9.8, 8.4, 9.9, 0.0, 0.1, 10.0, 9.9, 10.0, 0.0, 9.7, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 9.8, 9.9, 10.0, 0.4, 10.0, 10.0, 9.9, 10.0, 0.2, 10.0, 10.0, 8.6, 9.7, 10.0, 10.0, 10.0, 7.3, 10.0, 9.4, 0.4, 7.2, 9.9, 10.0, 9.4, 10.0, 10.0, 10.0, 9.7, 9.9, 0.6, 0.1, 10.0, 9.9, 9.7, 9.1, 9.9, 9.6, 0.1, 9.9, 10.0, 10.0, 10.0, 9.5, 0.5, 10.0, 10.0, 0.2, 0.3, 0.7, 0.6, 9.9, 9.8, 9.9, 10.0, 10.0, 9.6, 10.0, 10.0, 9.9, 10.0, 10.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.9, 9.9, 9.2, 10.0, 10.0, 0.7, 1.2, 8.9, 9.9, 9.8, 9.8, 0.5, 10.0, 0.3, 9.9, 10.0, 10.0, 0.7, 0.0, 9.8, 0.6, 9.7, 0.2, 10.0, 0.1, 10.0, 10.0, 10.0, 0.6, 10.0, 9.7, 10.0, 9.8, 0.1, 10.0, 9.7, 9.7, 8.7, 9.9, 10.0, 10.0, 10.0, 9.9, 10.0, 9.8, 10.0, 9.9, 9.9, 10.0, 0.0, 10.0, 10.0, 9.9, 0.0, 9.6, 1.5, 10.0, 9.9, 0.1, 9.7, 10.0, 9.0, 9.9, 10.0, 10.0, 10.0, 9.6, 0.2, 10.0, 9.9, 9.8, 10.0, 9.9, 10.0, 0.2, 10.0, 10.0, 10.0, 1.1, 9.9, 10.0, 9.5, 9.7, 10.0, 9.1, 10.0, 0.4, 9.7, 10.0, 10.0, 10.0, 10.0, 9.6, 9.5, 7.5, 10.0, 10.0, 9.3, 10.0, 10.0, 2.0, 9.6, 0.8, 9.7, 9.9, 10.0, 10.0, 9.9, 9.8, 10.0, 10.0, 0.3, 9.9, 9.9, 10.0, 10.0, 9.6, 10.0, 10.0, 9.9, 10.0, 9.8, 10.0, 10.0, 0.9, 0.8, 10.0, 0.1, 10.0, 9.4, 9.5, 9.9, 10.0, 9.8, 10.0, 10.0, 0.8, 10.0, 9.9, 10.0, 10.0, 0.0, 9.8, 0.0, 9.9, 9.8, 9.9, 10.0, 9.9, 10.0, 10.0, 9.0, 10.0, 10.0, 9.9, 0.5, 0.2, 10.0, 9.9, 9.8, 10.0, 9.9, 9.1, 10.0, 10.0, 10.0, 10.0, 0.3, 9.8, 9.9, 10.0, 9.7, 10.0, 10.0, 0.1, 10.0, 9.2, 9.9, 10.0, 10.0, 9.6, 10.0, 9.9, 10.0, 9.9, 9.6, 10.0, 10.0, 9.6, 10.0, 10.0, 10.0, 9.9, 0.1, 0.2, 10.0, 10.0, 0.0, 10.0, 9.9, 9.7, 9.2, 10.0, 0.1, 8.1, 1.0, 0.9, 0.9, 10.0, 9.7, 10.0, 10.0, 10.0, 9.9, 9.9, 9.9, 0.6, 10.0, 10.0, 0.0, 9.8, 9.9, 10.0, 1.0, 0.4, 10.0, 9.9, 9.6, 0.1, 10.0, 10.0, 10.0, 10.0, 10.0, 0.6, 0.3, 9.9, 9.9, 0.2, 9.8, 0.0, 10.0, 9.0, 9.9, 9.8, 9.7, 10.0]\n ROC-AUC score: 1.0000\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07c6936ce7be4e81be7fd214d5b026ed"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n======== Partition 7 / 10 ========\n2041\n227\nTraining...\nvgg\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/2041 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fea25075b63445c903fa3ddb05342eb"}},"metadata":{}},{"name":"stdout","text":" ROC-AUC Socre: 1.0000\n Average training loss: 0.0012\nRunning validation ...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/227 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec888c682234ee392d4bc0236af45d0"}},"metadata":{}},{"name":"stdout","text":"[9.2, 9.4, 10.0, 10.0, 10.0, 9.9, 9.4, 9.5, 7.2, 9.3, 10.0, 9.9, 10.0, 9.3, 0.4, 10.0, 8.4, 9.6, 0.1, 9.8, 9.2, 9.8, 9.7, 9.9, 9.5, 10.0, 10.0, 10.0, 0.0, 10.0, 9.9, 7.6, 10.0, 9.9, 10.0, 9.9, 0.2, 10.0, 9.8, 10.0, 9.3, 10.0, 9.8, 10.0, 9.9, 10.0, 9.8, 8.8, 0.2, 10.0, 10.0, 9.5, 9.9, 8.8, 0.1, 10.0, 0.0, 0.2, 10.0, 10.0, 9.7, 0.2, 9.8, 0.0, 0.0, 10.0, 8.4, 9.3, 9.9, 7.9, 9.9, 10.0, 10.0, 9.5, 8.9, 9.3, 10.0, 9.7, 0.0, 9.9, 0.2, 10.0, 10.0, 10.0, 8.7, 9.8, 10.0, 10.0, 0.0, 10.0, 10.0, 9.7, 10.0, 8.4, 9.8, 10.0, 8.4, 9.7, 9.9, 10.0, 10.0, 9.6, 10.0, 9.8, 0.1, 10.0, 0.0, 0.0, 10.0, 9.8, 10.0, 10.0, 9.7, 9.9, 10.0, 10.0, 10.0, 9.2, 10.0, 10.0, 0.3, 10.0, 9.8, 9.7, 9.8, 10.0, 0.0, 9.7, 10.0, 9.9, 8.0, 9.6, 0.1, 0.2, 0.0, 10.0, 10.0, 10.0, 0.2, 0.0, 10.0, 10.0, 10.0, 10.0, 9.9, 1.5, 9.7, 10.0, 9.7, 0.2, 9.6, 9.9, 10.0, 9.8, 10.0, 10.0, 10.0, 10.0, 10.0, 9.9, 9.8, 10.0, 9.6, 9.9, 10.0, 9.6, 10.0, 9.7, 10.0, 10.0, 10.0, 9.9, 10.0, 10.0, 9.6, 0.1, 6.6, 10.0, 9.9, 10.0, 0.0, 0.2, 9.9, 10.0, 9.9, 9.3, 10.0, 7.4, 0.1, 0.0, 10.0, 9.9, 10.0, 10.0, 10.0, 10.0, 9.3, 9.5, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 0.1, 0.0, 9.9, 10.0, 9.9, 10.0, 9.5, 0.1, 10.0, 9.6, 10.0, 9.9, 9.9, 9.9, 0.2, 9.9, 9.6, 8.8, 0.1, 0.0, 4.9, 8.4, 10.0, 0.1, 10.0, 0.2, 9.9, 9.9, 10.0, 10.0, 8.6, 9.9, 9.9, 7.5, 0.0, 0.1, 10.0, 10.0, 7.4, 10.0, 9.8, 0.7, 9.8, 10.0, 10.0, 10.0, 9.1, 10.0, 10.0, 0.1, 0.0, 9.9, 9.8, 9.6, 10.0, 9.9, 9.0, 0.1, 6.2, 10.0, 10.0, 10.0, 10.0, 10.0, 9.9, 9.8, 10.0, 7.1, 8.9, 9.8, 0.2, 9.8, 9.8, 9.9, 0.0, 9.7, 0.0, 10.0, 0.0, 9.2, 9.4, 7.4, 0.0, 9.9, 9.5, 10.0, 10.0, 10.0, 10.0, 4.4, 9.2, 0.0, 0.0, 10.0, 0.3, 9.9, 10.0, 10.0, 9.0, 9.9, 10.0, 0.1, 0.1, 9.6, 9.6, 10.0, 9.5, 9.6, 9.6, 10.0, 0.5, 10.0, 9.9, 10.0, 0.1, 8.8, 0.2, 10.0, 9.3, 9.2, 9.9, 10.0, 10.0, 0.0, 8.7, 9.9, 0.0, 7.5, 10.0, 0.3, 9.9, 0.0, 9.9, 0.2, 10.0, 0.0, 0.0, 8.2, 0.1, 0.0, 9.9, 9.9, 10.0, 9.9, 10.0, 10.0, 9.8, 0.1, 8.3, 9.6, 10.0, 9.9, 10.0, 9.4, 8.8, 10.0, 9.6, 9.6, 8.7, 0.1, 10.0, 10.0, 9.9, 0.0, 0.0, 9.9, 9.8, 9.9, 8.2, 10.0, 10.0, 0.1, 10.0, 10.0, 9.5, 10.0, 9.5, 10.0, 9.9, 10.0, 9.7, 9.9, 10.0, 8.9, 10.0, 9.9, 9.1, 9.8, 0.0, 2.0, 9.5, 10.0, 9.8, 10.0, 0.3, 0.0, 0.1, 0.0, 10.0, 8.2, 0.1, 10.0, 0.0, 10.0, 9.7, 0.1, 5.9, 0.0, 10.0, 0.2, 0.2, 9.4, 0.4, 10.0, 10.0, 9.7, 9.9, 10.0, 0.1, 10.0, 0.2, 10.0, 10.0, 0.0, 10.0, 9.9, 10.0, 10.0, 10.0, 10.0, 9.4, 0.2, 10.0, 10.0, 9.6, 0.2, 0.0, 9.8, 2.9, 8.9, 10.0, 0.0, 0.0, 10.0, 0.3, 9.9, 9.7, 10.0, 10.0, 0.4, 10.0, 9.7, 10.0, 9.9, 10.0, 0.0, 10.0, 9.9, 9.8, 10.0, 0.0, 0.4, 10.0, 9.6, 10.0, 9.2, 10.0, 10.0, 0.0, 9.9, 8.2, 10.0, 10.0, 10.0, 9.6, 0.0, 7.2, 0.1, 10.0, 10.0, 9.8, 0.1, 10.0, 0.7, 10.0, 10.0, 7.7, 0.0, 0.1, 8.5, 9.9, 10.0, 9.9, 0.0, 9.7, 0.3, 0.0, 10.0, 0.2, 10.0, 0.0, 0.9, 10.0, 10.0, 9.9, 9.9, 10.0, 9.6, 9.9, 8.7, 10.0, 0.1, 10.0, 10.0, 0.0, 9.7, 9.3, 10.0, 9.9, 0.0, 9.9, 10.0, 0.0, 9.9, 8.8, 10.0, 9.0, 10.0, 7.1, 9.9, 10.0, 0.0, 9.8, 7.5, 9.9, 10.0, 9.7, 10.0, 10.0, 8.6, 0.4, 10.0, 10.0, 10.0, 9.2, 9.9, 0.0, 0.1, 8.2, 0.0, 10.0, 10.0, 0.0, 10.0, 0.3, 9.3, 10.0, 7.0, 10.0, 0.5, 10.0, 9.8, 10.0, 10.0, 10.0, 0.5, 9.8, 9.7, 9.9, 10.0, 9.6, 9.4, 10.0, 10.0, 9.8, 0.4, 9.2, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 9.7, 9.9, 10.0, 9.8, 9.6, 10.0, 9.8, 9.9, 0.1, 10.0, 8.7, 9.8, 10.0, 9.7, 8.9, 9.4, 0.1, 0.0, 0.1, 0.1, 0.1, 0.0, 0.2, 10.0, 9.9, 10.0, 0.0, 0.2, 0.0, 10.0, 9.1, 9.9, 0.5, 10.0, 10.0, 9.9, 9.8, 0.0, 0.1, 10.0, 10.0, 10.0, 10.0, 10.0, 7.9, 10.0, 7.6, 10.0, 10.0, 0.1, 10.0, 0.1, 0.0, 0.1, 10.0, 9.9, 10.0, 0.0, 9.7, 10.0, 10.0, 9.6, 8.4, 9.9, 9.8, 10.0, 0.0, 10.0, 9.6, 9.9, 9.9, 0.0, 7.8, 0.3, 0.0, 9.6, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 9.1, 9.8, 0.4, 10.0, 9.2, 0.2, 10.0, 9.9, 10.0, 9.1, 9.3, 0.0, 10.0, 9.9, 9.6, 9.8, 10.0, 0.1, 9.9, 0.1, 9.3, 9.8, 0.0, 2.1, 0.0, 10.0, 10.0, 0.1, 9.8, 9.8, 10.0, 0.4, 10.0, 9.4, 10.0, 10.0, 9.9, 8.4, 10.0, 9.9, 9.8, 10.0, 0.6, 10.0, 0.0, 0.3, 10.0, 10.0, 10.0, 10.0, 9.4, 9.9, 9.6, 10.0, 10.0, 9.4, 0.1, 0.4, 10.0, 10.0, 9.9, 0.2, 10.0, 0.1, 10.0, 9.9, 10.0, 9.7, 9.9, 9.9, 0.2, 10.0, 0.1, 9.2, 0.0, 10.0, 9.1, 0.0, 10.0, 9.9, 10.0, 10.0, 9.5, 10.0, 8.0, 10.0, 0.4, 9.7, 0.0, 10.0, 9.7, 10.0, 9.3, 10.0, 10.0, 10.0, 10.0, 7.3, 9.4, 0.0, 10.0, 9.7, 0.0, 10.0, 10.0, 9.8, 9.7, 10.0, 10.0, 0.1, 9.4, 10.0, 0.0, 10.0, 1.1, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 5.1, 8.2, 8.8, 9.8, 7.5, 9.8, 10.0, 7.6, 9.8, 0.4, 10.0, 7.4, 9.8, 10.0, 10.0, 10.0, 8.3, 9.9, 10.0, 9.9, 0.0, 10.0, 9.9, 10.0, 10.0, 0.0, 0.1, 9.9, 10.0, 10.0, 0.1, 10.0, 10.0, 9.0, 0.0, 9.9, 10.0, 10.0, 9.2, 9.9, 9.9, 9.8, 0.5, 9.8, 9.9, 10.0, 9.8, 10.0, 9.5, 10.0, 9.9, 0.1, 10.0, 10.0, 10.0, 0.0, 10.0, 0.2, 10.0, 9.6, 0.1, 10.0, 10.0, 0.3, 0.0, 9.9, 0.4, 10.0, 10.0, 10.0, 10.0, 9.9, 9.0, 10.0, 10.0, 0.2, 9.3, 10.0, 10.0, 9.8, 10.0, 10.0, 10.0, 0.1, 10.0, 9.7, 10.0, 0.1, 5.8, 7.8, 0.0, 10.0, 0.0, 9.9, 9.3, 10.0, 10.0, 9.6, 9.3, 10.0, 10.0, 10.0, 10.0, 0.1, 9.2, 9.9, 0.1, 0.1, 0.0, 9.8, 0.1, 10.0]\n ROC-AUC score: 1.0000\nRunning test....\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:85: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/1276 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f64306b50893400b82c4ff937132d59c"}},"metadata":{}},{"name":"stdout","text":"./input/foodyvnu/Data/image_test/1672433/0.jpg\n./input/foodyvnu/Data/image_test/6279731/0.jpg\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/115041291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m   }\n\u001b[1;32m    109\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m   \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"./working/state_dict_{epoch_i}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./working/submit_joint_{epoch_i}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/75797930.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, optimizer, path)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     }\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:300] . unexpected pos 1846360256 vs 1846360160"],"ename":"RuntimeError","evalue":"[enforce fail at inline_container.cc:300] . unexpected pos 1846360256 vs 1846360160","output_type":"error"}]}]}